
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/2.0/tutorials/advanced/torch_script_custom_ops/">
      
      
        <link rel="prev" href="../cpp_extension/">
      
      
        <link rel="next" href="../torch_script_custom_classes/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>Extending TorchScript with Custom C++ Operators - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.d7758b05.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.75 1.75 0 0 1 1 7.775m1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2"/></svg>');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.5 1.75v11.5c0 .138.112.25.25.25h3.17a.75.75 0 0 1 0 1.5H2.75A1.75 1.75 0 0 1 1 13.25V1.75C1 .784 1.784 0 2.75 0h8.5C12.216 0 13 .784 13 1.75v7.736a.75.75 0 0 1-1.5 0V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25m13.274 9.537zl-4.557 4.45a.75.75 0 0 1-1.055-.008l-1.943-1.95a.75.75 0 0 1 1.062-1.058l1.419 1.425 4.026-3.932a.75.75 0 1 1 1.048 1.074M4.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5M4 7.75A.75.75 0 0 1 4.75 7h2a.75.75 0 0 1 0 1.5h-2A.75.75 0 0 1 4 7.75"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75M8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2"/></svg>');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M3.499.75a.75.75 0 0 1 1.5 0v.996C5.9 2.903 6.793 3.65 7.662 4.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873 10.794-.045 12.622.26 14.408.558 16 1.94 16 4.25c0 1.278-.954 2.575-2.44 2.734l.146.508.065.22c.203.701.412 1.455.476 2.226.142 1.707-.4 3.03-1.487 3.898C11.714 14.671 10.27 15 8.75 15h-6a.75.75 0 0 1 0-1.5h1.376a4.5 4.5 0 0 1-.563-1.191 3.84 3.84 0 0 1-.05-2.063 4.65 4.65 0 0 1-2.025-.293.75.75 0 0 1 .525-1.406c1.357.507 2.376-.006 2.698-.318l.009-.01a.747.747 0 0 1 1.06 0 .75.75 0 0 1-.012 1.074c-.912.92-.992 1.835-.768 2.586.221.74.745 1.337 1.196 1.621H8.75c1.343 0 2.398-.296 3.074-.836.635-.507 1.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4 2.4 0 0 1-.507-.441 3.1 3.1 0 0 1-.633-1.248.75.75 0 0 1 1.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738 0 1.25-.615 1.25-1.25 0-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706 1.345-.46.92-.27 1.774.019 3.062l.042.19.01.05c.348.443.666.949.94 1.553a.75.75 0 1 1-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7 5.527c-.814-.68-1.75-1.462-2.692-2.619a3.7 3.7 0 0 0-1.023.88c-.406.495-.663 1.036-.722 1.508.116.122.306.21.591.239.388.038.797-.06 1.032-.19a.75.75 0 0 1 .728 1.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75 5.677V5.5c0-.984.48-1.94 1.077-2.664.46-.559 1.05-1.055 1.673-1.353z"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0"/></svg>');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.92 6.085h.001a.749.749 0 1 1-1.342-.67c.169-.339.436-.701.849-.977C6.845 4.16 7.369 4 8 4a2.76 2.76 0 0 1 1.637.525c.503.377.863.965.863 1.725 0 .448-.115.83-.329 1.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6 6 0 0 0-.26.16 1 1 0 0 0-.276.245.75.75 0 0 1-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1 1 0 0 0 .277-.245C8.96 6.514 9 6.427 9 6.25a.61.61 0 0 0-.262-.525A1.27 1.27 0 0 0 8 5.5c-.369 0-.595.09-.74.187a1 1 0 0 0-.34.398M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.344 2.343za8 8 0 0 1 11.314 11.314A8.002 8.002 0 0 1 .234 10.089a8 8 0 0 1 2.11-7.746m1.06 10.253a6.5 6.5 0 1 0 9.108-9.275 6.5 6.5 0 0 0-9.108 9.275M6.03 4.97 8 6.94l1.97-1.97a.749.749 0 0 1 1.275.326.75.75 0 0 1-.215.734L9.06 8l1.97 1.97a.749.749 0 0 1-.326 1.275.75.75 0 0 1-.734-.215L8 9.06l-1.97 1.97a.749.749 0 0 1-1.275-.326.75.75 0 0 1 .215-.734L6.94 8 4.97 6.03a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018"/></svg>');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M9.504.43a1.516 1.516 0 0 1 2.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 0 1-.871.354h-.302a1.25 1.25 0 0 1-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004zm1.047 1.074L3.286 8.571A.25.25 0 0 0 3.462 9H6.75a.75.75 0 0 1 .694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0 0 12.538 7H9.25a.75.75 0 0 1-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005 0-.009.004"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M5 5.782V2.5h-.25a.75.75 0 0 1 0-1.5h6.5a.75.75 0 0 1 0 1.5H11v3.282l3.666 5.76C15.619 13.04 14.543 15 12.767 15H3.233c-1.776 0-2.852-1.96-1.899-3.458Zm-2.4 6.565a.75.75 0 0 0 .633 1.153h9.534a.75.75 0 0 0 .633-1.153L12.225 10.5h-8.45ZM9.5 2.5h-3V6c0 .143-.04.283-.117.403L4.73 9h6.54L9.617 6.403A.75.75 0 0 1 9.5 6Z"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 2.5h10.5a.75.75 0 0 1 0 1.5H1.75a.75.75 0 0 1 0-1.5m4 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5m0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5M2.5 7.75v6a.75.75 0 0 1-1.5 0v-6a.75.75 0 0 1 1.5 0"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#c-torchscript" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.dafeiyang.cn/images/logo/logo_green.webp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Extending TorchScript with Custom C++ Operators
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.dafeiyang.cn/images/logo/logo_green.webp" alt="logo">

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 新特性
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 新特性
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.13
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.12
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.11
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.10
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.8
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.7
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 2.x 中文文档 & 教程
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 2.x 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch Recipes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch Recipes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../recipes/recipes_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Recipes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prototype/prototype_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Prototype Recipes
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learn the Basics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/quickstart_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/tensorqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/data_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets & DataLoaders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/transforms_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transforms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/buildmodel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build the Neural Network
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/autogradqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Differentiation with torch.autograd
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/optimization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Model Parameters
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/saveloadrun_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Save and Load the Model
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" >
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch on YouTube
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch on YouTube
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch - YouTube Series
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/introyt1_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/tensors_deeper_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch Tensors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/autogradyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Fundamentals of Autograd
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/modelsyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Models with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/tensorboardyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch TensorBoard Support
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/trainingyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/captumyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Understanding with Captum
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_4" >
        
          
          <label class="md-nav__link" for="__nav_3_1_4" id="__nav_3_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Learning PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_4">
            <span class="md-nav__icon md-icon"></span>
            Learning PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning with PyTorch: A 60 Minute Blitz
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning PyTorch with Examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/tensorboard_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualizing Models, Data, and Training with TensorBoard
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_5" >
        
          
          <label class="md-nav__link" for="__nav_3_1_5" id="__nav_3_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Image and Video
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_5">
            <span class="md-nav__icon md-icon"></span>
            Image and Video
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/torchvision_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision Object Detection Finetuning Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transfer Learning for Computer Vision Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adversarial Example Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial Transformer Networks Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/tiatoolbox_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Whole Slide Image Classification Using PyTorch and TIAToolbox
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_6" >
        
          
          <label class="md-nav__link" for="__nav_3_1_6" id="__nav_3_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Audio
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_6">
            <span class="md-nav__icon md-icon"></span>
            Audio
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_io_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio I/O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_resampling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Resampling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_data_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Data Augmentation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_feature_extractions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Extractions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_feature_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Augmentation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_datasets_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Datasets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/speech_recognition_pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speech Recognition with Wav2Vec2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/text_to_speech_with_torchaudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-speech with Tacotron2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/forced_alignment_with_torchaudio_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forced Alignment with Wav2Vec2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_7" >
        
          
          <label class="md-nav__link" for="__nav_3_1_7" id="__nav_3_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_7">
            <span class="md-nav__icon md-icon"></span>
            Text
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/bettertransformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fast Transformer Inference with Better Transformer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Classifying Names with a Character-Level RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Generating Names with a Character-Level RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Translation with a Sequence to Sequence Network and Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/text_sentiment_ngrams_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text classification with the torchtext library
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/translation_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Translation with nn.Transformer and torchtext
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/torchtext_custom_dataset_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocess custom text dataset using Torchtext
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_8" >
        
          
          <label class="md-nav__link" for="__nav_3_1_8" id="__nav_3_1_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Backends
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_8">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_9" >
        
          
          <label class="md-nav__link" for="__nav_3_1_9" id="__nav_3_1_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_9">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/reinforcement_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (PPO) with TorchRL Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/mario_rl_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a Mario-playing RL Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pendulum/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pendulum: Writing your environment and transforms with TorchRL
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_10" >
        
          
          <label class="md-nav__link" for="__nav_3_1_10" id="__nav_3_1_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deploying PyTorch Models in Production
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_10">
            <span class="md-nav__icon md-icon"></span>
            Deploying PyTorch Models in Production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/flask_rest_api_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying PyTorch in Python via a REST API with Flask
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/Intro_to_TorchScript_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchScript
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loading a TorchScript Model in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../super_resolution_with_onnxruntime/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/realtime_rpi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Real Time Inference on Raspberry Pi 4 (30 fps!)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_11" >
        
          
          <label class="md-nav__link" for="__nav_3_1_11" id="__nav_3_1_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Profiling PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_11">
            <span class="md-nav__icon md-icon"></span>
            Profiling PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/hta_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Holistic Trace Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/hta_trace_diff_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Trace Diff using Holistic Trace Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_12" >
        
          
          <label class="md-nav__link" for="__nav_3_1_12" id="__nav_3_1_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code Transforms with FX
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_12">
            <span class="md-nav__icon md-icon"></span>
            Code Transforms with FX
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/fx_conv_bn_fuser/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Convolution/Batch Norm fuser in FX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/fx_profiling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Simple CPU Performance Profiler with FX
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_13" >
        
          
          <label class="md-nav__link" for="__nav_3_1_13" id="__nav_3_1_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Frontend APIs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_13">
            <span class="md-nav__icon md-icon"></span>
            Frontend APIs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/memory_format_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Channels Last Memory Format in PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/forward_ad_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forward-mode Automatic Differentiation (Beta)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/jacobians_hessians/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Jacobians, Hessians, hvp, vhp, and more: composing function transforms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/ensembling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model ensembling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/per_sample_grads/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Per-sample-gradients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the PyTorch C++ Frontend
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch-script-parallelism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Parallelism in TorchScript
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd in C++ Frontend
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_14" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1_14" id="__nav_3_1_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Extending PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_14_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_14">
            <span class="md-nav__icon md-icon"></span>
            Extending PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/custom_function_double_backward_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Double Backward with Custom Functions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/custom_function_conv_bn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fusing Convolution and Batch Norm using Custom Function
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#c" class="md-nav__link">
    <span class="md-ellipsis">
      在 C++ 中实现自定义运算符 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchscript" class="md-nav__link">
    <span class="md-ellipsis">
      使用 TorchScript 注册自定义运算符 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      构建自定义运算符 ¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="构建自定义运算符 ¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      环境设置 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cmake" class="md-nav__link">
    <span class="md-ellipsis">
      使用 CMake 构建 ¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#python-torchscript" class="md-nav__link">
    <span class="md-ellipsis">
      在 Python 中使用 TorchScript 自定义运算符 ¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="在 Python 中使用 TorchScript 自定义运算符 ¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      使用自定义运算符进行跟踪 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      将自定义运算符与脚本一起使用 ¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#c-torchscript_1" class="md-nav__link">
    <span class="md-ellipsis">
      在 C++ 中使用 TorchScript 自定义运算符 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      结论 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a" class="md-nav__link">
    <span class="md-ellipsis">
      附录 A：构建自定义运算符的更多方法 ¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="附录 A：构建自定义运算符的更多方法 ¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#jit" class="md-nav__link">
    <span class="md-ellipsis">
      使用 JIT 编译进行构建 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      使用安装工具构建 ¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_script_custom_classes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Classes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Registering a Dispatched Operator in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../extend_dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending dispatcher for a new backend in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../privateuseone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Facilitating New Backend Integration by PrivateUse1
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_15" >
        
          
          <label class="md-nav__link" for="__nav_3_1_15" id="__nav_3_1_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Optimization
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_15">
            <span class="md-nav__icon md-icon"></span>
            Model Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/tensorboard_profiler_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Profiler With TensorBoard
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/hyperparameter_tuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter tuning with Ray Tune
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/parametrizations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametrizations Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/pruning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pruning Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamic_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on an LSTM Word Language Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/dynamic_quantization_bert_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on BERT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/quantized_transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Quantized Transfer Learning for Computer Vision Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../static_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Static Quantization with Eager Mode in PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/torchserve_with_ipex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/torchserve_with_ipex_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles (Part 2)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/nvfuser_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started - Accelerate Your Scripts with nvFuser
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/ax_multiobjective_nas_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Objective NAS with Ax
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/torch_compile_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to torch.compile
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/inductor_debug_cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inductor CPU backend debugging and profiling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/knowledge_distillation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge Distillation Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_16" >
        
          
          <label class="md-nav__link" for="__nav_3_1_16" id="__nav_3_1_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Parallel and Distributed Training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_16">
            <span class="md-nav__icon md-icon"></span>
            Parallel and Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributed/home/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed and Parallel Training Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/dist_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Distributed Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/ddp_series_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Data Parallel in PyTorch - Video Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/model_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single-Machine Model Parallel Best Practices
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed Data Parallel
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/FSDP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Fully Sharded Data Parallel(FSDP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/FSDP_adavnced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced Model Training with Fully Sharded Data Parallel (FSDP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/TP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Large Scale Transformer model training with Tensor Parallel (TP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/process_group_cpp_extension_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Process Group Backends Using Cpp Extensions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/rpc_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/rpc_param_server_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing a Parameter Server Using Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/dist_pipeline_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Pipeline Parallelism Using RPC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/rpc_async_execution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing Batch RPC Processing Using Asynchronous Executions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rpc_ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Combining Distributed DataParallel with Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ddp_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Distributed Data Parallel and Pipeline Parallelism
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../generic_join/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Training with Uneven Inputs Using the Join Context Manager
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_17" >
        
          
          <label class="md-nav__link" for="__nav_3_1_17" id="__nav_3_1_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Edge with ExecuTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_17">
            <span class="md-nav__icon md-icon"></span>
            Edge with ExecuTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exporting to ExecuTorch Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/running-a-model-cpp-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Running an ExecuTorch Model in C++ Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/tutorials/sdk-integration-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the ExecuTorch SDK to Profile a Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/demo-apps-ios.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building an ExecuTorch iOS Demo App
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/demo-apps-android.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building an ExecuTorch Android Demo App
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/examples-end-to-end-to-lower-model-to-delegate.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lowering a Model as a Delegate
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_18" >
        
          
          <label class="md-nav__link" for="__nav_3_1_18" id="__nav_3_1_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Recommendation Systems
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_18">
            <span class="md-nav__icon md-icon"></span>
            Recommendation Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intermediate/torchrec_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchRec
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sharding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exploring TorchRec sharding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_19" >
        
          
          <label class="md-nav__link" for="__nav_3_1_19" id="__nav_3_1_19_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Multimodality
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_19">
            <span class="md-nav__icon md-icon"></span>
            Multimodality
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/flava_finetuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchMultimodal Tutorial: Finetuning FLAVA
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/docs/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pytorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/audio/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torchaudio
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/text/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchText
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/vision/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torcharrow/beta/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchArrow
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torchrec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchRec
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/serve/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchServe
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torchx/latest/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/xla/release/2.3/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch on XLA Devices
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.7 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.4 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.0 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.4 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.3 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.2 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../contrib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贡献指南
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于我们
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/join" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加入我们
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中文资源合集
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#c" class="md-nav__link">
    <span class="md-ellipsis">
      在 C++ 中实现自定义运算符 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchscript" class="md-nav__link">
    <span class="md-ellipsis">
      使用 TorchScript 注册自定义运算符 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      构建自定义运算符 ¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="构建自定义运算符 ¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      环境设置 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cmake" class="md-nav__link">
    <span class="md-ellipsis">
      使用 CMake 构建 ¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#python-torchscript" class="md-nav__link">
    <span class="md-ellipsis">
      在 Python 中使用 TorchScript 自定义运算符 ¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="在 Python 中使用 TorchScript 自定义运算符 ¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      使用自定义运算符进行跟踪 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      将自定义运算符与脚本一起使用 ¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#c-torchscript_1" class="md-nav__link">
    <span class="md-ellipsis">
      在 C++ 中使用 TorchScript 自定义运算符 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      结论 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a" class="md-nav__link">
    <span class="md-ellipsis">
      附录 A：构建自定义运算符的更多方法 ¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="附录 A：构建自定义运算符的更多方法 ¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#jit" class="md-nav__link">
    <span class="md-ellipsis">
      使用 JIT 编译进行构建 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      使用安装工具构建 ¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/2.0/tutorials/advanced/torch_script_custom_ops.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/2.0/tutorials/advanced/torch_script_custom_ops.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="c-torchscript">使用自定义 C++ 运算符扩展 TorchScript <a href="#extending-torchscript-with-custom-c-operators" title="固定链接到此标题">¶</a></h1>
<blockquote>
<p>译者：<a href="https://github.com/jiangzhonglian">片刻小哥哥</a></p>
<p>项目地址：<a href="https://pytorch.apachecn.org/2.0/tutorials/advanced/torch_script_custom_ops">https://pytorch.apachecn.org/2.0/tutorials/advanced/torch_script_custom_ops</a></p>
<p>原始地址：<a href="https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html">https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html</a></p>
</blockquote>
<p>PyTorch 1.0 版本为 PyTorch 引入了一种新的编程模型，称为
 <a href="https://pytorch.org/docs/master/jit.html">TorchScript</a> 
 。 TorchScript 是 Python 编程语言的子集，可以由 TorchScript 编译器解析、编译和优化。此外，已编译的 TorchScript 模型
可以选择序列化为磁盘文件格式，
您随后可以从纯 C++(以及 Python)加载并运行该文件格式以进行推理。</p>
<p>TorchScript 支持 <code>torch</code>
 包提供的大量操作子集，允许您将多种复杂模型纯粹表达为 PyTorch</p>
<p>一系列tensor操作\xe2\x80\x99s \xe2\x80 \x9c标准库\xe2\x80\x9d。尽管如此，有时您可能会发现自己需要使用自定义 C++ 或 CUDA 函数来扩展 TorchScript。虽然我们建议您仅在
您的想法无法(足够有效)表达为简单的 Python 函数时才使用此选项，
我们确实提供了一个非常友好且简单的界面，用于使用
[ATen]定义自定义 C++ 和
CUDA 内核](https://pytorch.org/cppdocs/#aten) 
 ，PyTorch\xe2\x80\x99s 高性能 C++ tensor库。绑定到 TorchScript 后，您可以将这些
自定义内核(或 \xe2\x80\x9cops\xe2\x80\x9d)嵌入到您的 TorchScript 模型中，并在
Python 中执行它们，并直接在 C++ 中以序列化形式执行它们。</p>
<p>以下段落给出了编写 TorchScript 自定义操作以调用 
 <a href="https://www.opencv.org">OpenCV</a> 
 的示例，这是一个用 C++ 编写的计算机视觉库。我们将讨论如何在 C++ 中使用tensor、如何有效
将它们转换为第三方tensor格式(在本例中为 OpenCV
 <code>Mat</code>
 )、
如何向 TorchScript 运行时注册您的运算符以及最后如何
编译该运算符并在 Python 和 C++ 中使用它。</p>
<h2 id="c">在 C++ 中实现自定义运算符 <a href="#implementing-the-custom-operator-in-c" title="固定链接到此标题">¶</a></h2>
<p>对于本教程，我们’ 将公开
 <a href="https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#warpperspective">warpPerspective</a> 
 函数，它将透视变换应用于图像，从 OpenCV 到
TorchScript 作为自定义运算符。第一步是用 C++ 编写自定义运算符的实现。让’s 调用此实现的文件
 <code>op.cpp</code>
 并使其如下所示：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>torch::Tensor warp_perspective(torch::Tensor image, torch::Tensor warp) {
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a> // BEGIN image_mat
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a> cv::Mat image_mat(/*rows=*/image.size(0),
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a> /*cols=*/image.size(1),
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a> /*type=*/CV_32FC1,
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a> /*data=*/image.data_ptr&lt;float&gt;());
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a> // END image_mat
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a> // BEGIN warp_mat
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a> cv::Mat warp_mat(/*rows=*/warp.size(0),
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a> /*cols=*/warp.size(1),
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a> /*type=*/CV_32FC1,
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a> /*data=*/warp.data_ptr&lt;float&gt;());
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a> // END warp_mat
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a> // BEGIN output_mat
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a> cv::Mat output_mat;
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a> cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{8, 8});
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a> // END output_mat
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a> // BEGIN output_tensor
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a> torch::Tensor output = torch::from_blob(output_mat.ptr&lt;float&gt;(), /*sizes=*/{8, 8});
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a> return output.clone();
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a> // END output_tensor
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>}
</code></pre></div>
<p>该运算符的代码非常短。在文件的顶部，我们包含 OpenCV 头文件，
 <code>opencv2/opencv.hpp</code>
 ，以及
 <code>torch/script.h</code>
 头文件，它公开了 PyTorch 中所有必要的功能\ xe2\x80\x99s C++ API，我们需要编写自定义 TorchScript 运算符。我们的函数
 <code>warp_perspective</code>
 有两个参数：一个输入
 <code>image</code>
 和
 我们希望应用于图像的
 <code>warp</code>
 变换矩阵。这些输入的类型是
 <code>torch::Tensor</code>
 、
PyTorch\xe2\x80\x99s C++ 中的tensor类型(这也是 Python 中所有tensor的基础类型)。我们的
 <code>warp_perspective</code>
 函数的Return type也将是
 <code>torch::Tensor</code>
 。</p>
<p>提示</p>
<p>请参阅
 <a href="https://pytorch.org/cppdocs/notes/tensor_basics.html">本说明</a> 
 了解有关 ATen 的更多信息，该库提供
 <code>Tensor</code>
 类
 nPyTorch。此外，
 <a href="https://pytorch.org/cppdocs/notes/tensor_creation.html">本教程</a>
 描述了如何在 C++ 中
分配和初始化新的tensor对象(此运算符
不需要)。</p>
<p>注意</p>
<p>TorchScript 编译器可以识别固定数量的类型。只有这些类型
可以用作自定义运算符的参数。目前这些类型是：
 <code>torch::Tensor</code>
 、
 <code>torch::Scalar</code>
 、
 <code>double</code>
 、
 <code>int64_t</code>
 和
 <code>std ::vector</code>
 这些类型。请注意，
 <em>仅</em> 
<code>double</code>
 和
 <em>不</em> 
<code>float</code>
 和
 <em>仅</em> 
<code>int64_t</code>
 和
 <em>不</em> 
 支持其他整型，例如
 <code>int</code>
 、
 <code>short</code>
 或
 <code>long</code>
。</p>
<p>在我们的函数内部，我们需要做的第一件事是将 PyTorch
tensor转换为 OpenCV 矩阵，如 OpenCV’s
 <code>warpPerspective</code>
 需要 
 <code>cv::Mat</code> 
 对象作为输入。幸运的是，有一种方法可以做到这一点
 <strong>无需复制
任何</strong> 
 数据。在前几行中，</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a> cv::Mat image_mat(/*rows=*/image.size(0),
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a> /*cols=*/image.size(1),
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a> /*type=*/CV_32FC1,
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a> /*data=*/image.data_ptr&lt;float&gt;());
</code></pre></div>
<p>我们正在调用 OpenCV
 <code>Mat</code>
 类的
 <a href="https://docs.opencv.org/trunk/d3/d63/classcv_1_1Mat.html#a922de793eabcec705b3579c5f95a643e">此构造函数</a>将我们的tensor转换为
 <code>Mat</code>
 对象。我们传递
原始
 <code>image</code>
tensor的行数和列数、数据类型
(我们’将在本例中将其修复为
 <code>float32</code>
)，以及最后是指向底层数据 – a
 <code>float*</code>
 的原始指针。 <code>Mat</code> 类的这个构造函数的特殊之处在于它不复制输入数据。相反，它会简单地引用此内存以执行在 <code>Mat</code> 上执行的所有操作。如果对 
 <code>image_mat</code>
 执行就地操作，这将反映在
原始
 <code>image</code>
 tensor中(反之亦然)。这允许我们使用库’s 本机矩阵类型调用
后续 OpenCV 例程，即使
我们’ 实际上将数据存储在 PyTorch tensor中。我们重复此过程，将
 <code>warp</code>
 PyTorch tensor转换为
 <code>warp_mat</code>
 OpenCV 矩阵：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a> cv::Mat warp_mat(/*rows=*/warp.size(0),
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a> /*cols=*/warp.size(1),
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a> /*type=*/CV_32FC1,
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a> /*data=*/warp.data_ptr&lt;float&gt;());
</code></pre></div>
<p>接下来，我们准备调用我们非常想在 TorchScript 中使用的 OpenCV 函数：
 <code>warpPerspective</code>
 。为此，我们向 OpenCV 函数传递
 <code>image_mat</code>
 和
 <code>warp_mat</code>
 矩阵，以及一个空的输出矩阵
称为
 <code>output_mat</code>\名词我们还指定了我们想要的输出矩阵(图像)的大小。对于此示例，它被硬编码为
 `8</p>
<p>x</p>
<p>8`
:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a> cv::Mat output_mat;
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a> cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{8, 8});
</code></pre></div>
<p>自定义运算符实现的最后一步是将 
 <code>output_mat</code>
 转换回 PyTorch tensor，以便我们可以在 
PyTorch 中进一步使用它。这与我们之前在另一个方向上进行的转换惊人地相似。在这种情况下，PyTorch 提供了
 <code>torch::from_blob</code>
 方法。在这种情况下，A
 <em>blob</em> 
 旨在表示一些不透明的、指向内存的平面指针，
我们希望将其解释为 PyTorch tensor。对
<code>torch::from_blob</code>的调用
看起来像这样：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a> torch::Tensor output = torch::from_blob(output_mat.ptr&lt;float&gt;(), /*sizes=*/{8, 8});
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a> return output.clone();
</code></pre></div>
<p>我们使用 OpenCV
 <code>Mat</code>
 类上的
 <code>.ptr&lt;float&gt;()</code>
 方法来获取指向底层数据的原始
指针(就像
 <code>.data _ptr&lt;float&gt;()</code>
 用于之前的 PyTorch
tensor)。我们还指定tensor的输出形状，
将其硬编码为
 `8</p>
<p>x</p>
<p>8<code>。</code>torch::from_blob<code>的输出是</code>torch::Tensor`
 ，指向 OpenCV 矩阵拥有的内存。</p>
<p>在从运算符实现返回此tensor之前，我们必须在tensor上调用
 <code>.clone()</code>
 以执行底层数据的内存复制。原因是 <code>torch::from_blob</code> 返回一个不拥有数据的tensor。此时，数据仍归 OpenCV 矩阵所有。然而，这个 OpenCV 矩阵将超出范围并在函数结束时被释放。如果我们按原样返回“输出”tensor，那么当我们在函数外部使用它时，它会指向无效的内存。调用
 <code>.clone()</code>
 返回
新tensor以及新tensor本身拥有的原始数据的副本。
因此可以安全地返回到外部世界。</p>
<h2 id="torchscript">使用 TorchScript 注册自定义运算符 <a href="#registering-the-custom-operator-with-torchscript" title="永久链接到此标题">¶</a></h2>
<p>现在已经在 C++ 中实现了我们的自定义运算符，我们需要
 <em>注册</em> 
 它
与 TorchScript 运行时和编译器。这将允许 TorchScript
编译器解析 TorchScript 代码中对我们的自定义运算符的引用。
如果您曾经使用过 pybind11 库，我们的注册语法
与 pybind11 语法非常相似。要注册单个函数，
我们编写：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>TORCH_LIBRARY(my_ops, m) {
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a> m.def(&quot;warp_perspective&quot;, warp_perspective);
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>}
</code></pre></div>
<p>位于我们
 <code>op.cpp</code>
 文件顶层的某个位置。 
 <code>TORCH_LIBRARY</code>
 宏创建一个在程序启动时调用的函数。您的库的名称 (
 <code>my_ops</code>
 ) 作为第一个参数给出(不应包含在引号中)。第二个参数 (
 <code>m</code>
 ) 定义类型为
 <code>torch::Library</code>
 的变量，它是注册运算符的主接口。
方法
 <code>Library::def</code>
实际上创建了一个名为
 <code>warp_perspective</code>
 的运算符，
将其暴露给 Python 和 TorchScript。您可以通过多次调用
 <code>def</code>
 来定义任意数量的运算符。</p>
<p>在幕后，
 <code>def</code>
 函数实际上做了相当多的工作：
 正在使用模板元编程来检查
函数的类型签名，并将其转换为指定运算符的运算符模式
在 TorchScript’s 类型系统中键入。</p>
<h2 id="_1">构建自定义运算符 <a href="#building-the-custom-operator" title="永久链接到此标题">¶</a></h2>
<p>现在我们已经在 C++ 中实现了自定义运算符并编写了其
注册代码，是时候将该运算符构建到(共享)库中
我们可以将其加载到 Python 中进行研究和实验，或者加载到 C++ 中进行
推理在没有Python的环境中。有多种方法可以使用纯 CMake 或 Python 替代方案(例如 <code>setuptools</code>)来构建我们的运算符。
为简洁起见，下面的段落仅讨论 CMake 方法。本教程的附录
深入探讨了其他替代方案。</p>
<h3 id="_2">环境设置 <a href="#environment-setup" title="永久链接到此标题">¶</a></h3>
<p>我们需要安装 PyTorch 和 OpenCV。获取两者的最简单且最独立于平台\的方法是通过 Conda：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>conda install -c pytorch pytorch
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>conda install opencv
</code></pre></div>
<h3 id="cmake">使用 CMake 构建 <a href="#building-with-cmake" title="永久链接到此标题">¶</a></h3>
<p>要使用 <a href="https://cmake.org">CMake</a>
 构建系统将我们的自定义运算符构建到共享库中，我们需要编写一个简短的
 <code>CMakeLists.txt</code>
 文件并放置与我们之前的
 <code>op.cpp</code>
 文件一起使用。为此，让’s 同意如下所示的目录结构：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>warp-perspective/
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>  op.cpp
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>  CMakeLists.txt
</code></pre></div>
<p>我们的
 <code>CMakeLists.txt</code>
 文件的内容应如下所示：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>cmake_minimum_required(VERSION 3.1 FATAL_ERROR)
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>project(warp_perspective)
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>find_package(Torch REQUIRED)
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>find_package(OpenCV REQUIRED)
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a># Define our library target
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>add_library(warp_perspective SHARED op.cpp)
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a># Enable C++14
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>target_compile_features(warp_perspective PRIVATE cxx_std_14)
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a># Link against LibTorch
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>target_link_libraries(warp_perspective &quot;${TORCH_LIBRARIES}&quot;)
<a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a># Link against OpenCV
<a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>target_link_libraries(warp_perspective opencv_core opencv_imgproc)
</code></pre></div>
<p>现在要构建我们的运算符，我们可以从 
 <code>warp_perspective</code>
 文件夹运行以下命令：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>$ mkdir build
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>$ cd build
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>$ cmake -DCMAKE_PREFIX_PATH=&quot;$(python -c &#39;import torch.utils; print(torch.utils.cmake_prefix_path)&#39;)&quot; ..
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>-- The C compiler identification is GNU 5.4.0
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>-- The CXX compiler identification is GNU 5.4.0
<a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>-- Check for working C compiler: /usr/bin/cc
<a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>-- Check for working C compiler: /usr/bin/cc -- works
<a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>-- Detecting C compiler ABI info
<a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>-- Detecting C compiler ABI info - done
<a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>-- Detecting C compile features
<a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a>-- Detecting C compile features - done
<a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>-- Check for working CXX compiler: /usr/bin/c++
<a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>-- Check for working CXX compiler: /usr/bin/c++ -- works
<a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a>-- Detecting CXX compiler ABI info
<a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a>-- Detecting CXX compiler ABI info - done
<a id="__codelineno-9-16" name="__codelineno-9-16" href="#__codelineno-9-16"></a>-- Detecting CXX compile features
<a id="__codelineno-9-17" name="__codelineno-9-17" href="#__codelineno-9-17"></a>-- Detecting CXX compile features - done
<a id="__codelineno-9-18" name="__codelineno-9-18" href="#__codelineno-9-18"></a>-- Looking for pthread.h
<a id="__codelineno-9-19" name="__codelineno-9-19" href="#__codelineno-9-19"></a>-- Looking for pthread.h - found
<a id="__codelineno-9-20" name="__codelineno-9-20" href="#__codelineno-9-20"></a>-- Looking for pthread_create
<a id="__codelineno-9-21" name="__codelineno-9-21" href="#__codelineno-9-21"></a>-- Looking for pthread_create - not found
<a id="__codelineno-9-22" name="__codelineno-9-22" href="#__codelineno-9-22"></a>-- Looking for pthread_create in pthreads
<a id="__codelineno-9-23" name="__codelineno-9-23" href="#__codelineno-9-23"></a>-- Looking for pthread_create in pthreads - not found
<a id="__codelineno-9-24" name="__codelineno-9-24" href="#__codelineno-9-24"></a>-- Looking for pthread_create in pthread
<a id="__codelineno-9-25" name="__codelineno-9-25" href="#__codelineno-9-25"></a>-- Looking for pthread_create in pthread - found
<a id="__codelineno-9-26" name="__codelineno-9-26" href="#__codelineno-9-26"></a>-- Found Threads: TRUE
<a id="__codelineno-9-27" name="__codelineno-9-27" href="#__codelineno-9-27"></a>-- Found torch: /libtorch/lib/libtorch.so
<a id="__codelineno-9-28" name="__codelineno-9-28" href="#__codelineno-9-28"></a>-- Configuring done
<a id="__codelineno-9-29" name="__codelineno-9-29" href="#__codelineno-9-29"></a>-- Generating done
<a id="__codelineno-9-30" name="__codelineno-9-30" href="#__codelineno-9-30"></a>-- Build files have been written to: /warp_perspective/build
<a id="__codelineno-9-31" name="__codelineno-9-31" href="#__codelineno-9-31"></a>$ make -j
<a id="__codelineno-9-32" name="__codelineno-9-32" href="#__codelineno-9-32"></a>Scanning dependencies of target warp_perspective
<a id="__codelineno-9-33" name="__codelineno-9-33" href="#__codelineno-9-33"></a>[ 50%] Building CXX object CMakeFiles/warp_perspective.dir/op.cpp.o
<a id="__codelineno-9-34" name="__codelineno-9-34" href="#__codelineno-9-34"></a>[100%] Linking CXX shared library libwarp_perspective.so
<a id="__codelineno-9-35" name="__codelineno-9-35" href="#__codelineno-9-35"></a>[100%] Built target warp_perspective
</code></pre></div>
<p>它将在
 <code>build</code>
 文件夹中放置
 <code>libwarp_perspective.so</code>
 共享库文件。在上面的
 <code>cmake</code>
 命令中，我们使用帮助器
变量
 <code>torch.utils.cmake_prefix_path</code>
 来方便地告诉我们 PyTorch 安装的 cmake 文件在哪里。 </p>
<p>我们将在下面进一步详细探讨如何使用和调用我们的运算符，但为了
尽早获得成功，我们可以尝试在
Python 中运行以下代码：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>import torch
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>torch.ops.load_library(&quot;build/libwarp_perspective.so&quot;)
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>print(torch.ops.my_ops.warp_perspective)
</code></pre></div>
<p>如果一切顺利，应该打印如下内容：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>&lt;built-in method my_ops::warp_perspective of PyCapsule object at 0x7f618fc6fa50&gt;
</code></pre></div>
<p>这是我们稍后将用来调用自定义运算符的 Python 函数。</p>
<h2 id="python-torchscript">在 Python 中使用 TorchScript 自定义运算符 <a href="#using-the-torchscript-custom-operator-in-python" title="永久链接到此标题">¶</a></h2>
<p>一旦我们的自定义运算符构建到共享库中，我们就可以在 Python 中的 TorchScript 模型中使用此运算符。此操作分为两部分：
首先将运算符加载到 Python 中，然后在
TorchScript 代码中使用运算符。</p>
<p>您已经了解了如何将运算符导入 Python：
 <code>torch.ops.load_library()</code>
 。此函数获取包含自定义运算符的共享库的路径，并将其加载到当前进程中。加载共享库还将执行
 <code>TORCH_LIBRARY</code>
 块。这将向 TorchScript 编译器注册我们的自定义运算符，并允许我们在 TorchScript 代码中使用该运算符。</p>
<p>您可以将加载的运算符引用为
 <code>torch.ops.&lt;namespace&gt;.&lt;function&gt;</code>
 ，
其中
 <code>&lt;namespace&gt;</code>
 是运算符名称的命名空间部分，并且\ n <code>&lt;function&gt;</code>
 运算符的函数名称。对于我们上面编写的操作符，命名空间是 <code>my_ops</code>
 和函数名称
 <code>warp_perspective</code>
 ，
这意味着我们的操作符可以作为
 <code>torch.ops 使用.my_ops.warp_perspective</code>
 。
虽然此函数可以在脚本化或跟踪的 TorchScript 模块中使用，但我们
也可以在普通的 eager PyTorch 中使用它并传递常规 PyTorch
tensor：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>import torch
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>torch.ops.load_library(&quot;build/libwarp_perspective.so&quot;)
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>print(torch.ops.my_ops.warp_perspective(torch.randn(32, 32), torch.rand(3, 3)))
</code></pre></div>
<p>产生:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>tensor([[0.0000, 0.3218, 0.4611,  ..., 0.4636, 0.4636, 0.4636],
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>      [0.3746, 0.0978, 0.5005,  ..., 0.4636, 0.4636, 0.4636],
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>      [0.3245, 0.0169, 0.0000,  ..., 0.4458, 0.4458, 0.4458],
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>      ...,
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>      [0.1862, 0.1862, 0.1692,  ..., 0.0000, 0.0000, 0.0000],
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>      [0.1862, 0.1862, 0.1692,  ..., 0.0000, 0.0000, 0.0000],
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>      [0.1862, 0.1862, 0.1692,  ..., 0.0000, 0.0000, 0.0000]])
</code></pre></div>
<p>没有10</p>
<p>幕后发生的事情是，当您第一次在 Python 中访问
 <code>torch.ops.namespace.function</code>
 时，TorchScript 编译器(在 C++
land 中)将查看是否有一个函数
 <code>namespace::函数</code>
 已注册，
如果是这样，则返回此函数的 Python 句柄，我们随后可以使用该句柄从 Python 调用
我们的 C++ 运算符实现。这是 TorchScript 自定义运算符和 C++ 扩展之间的一个值得注意的区别：C++ 扩展是使用 pybind11 手动绑定的，而 TorchScript 自定义操作是由 PyTorch 本身动态绑定的。 Pybind11 为您提供了更大的灵活性，
您可以将哪些类型和类绑定到 Python 中，因此
推荐用于纯粹的 eager 代码，但 TorchScript
ops 不支持它。</p>
<p>从这里开始，您可以在脚本或跟踪代码中使用自定义运算符，就像 
 <code>torch</code>
 包中的其他函数一样。事实上，“standard
library” 函数如
 <code>torch.matmul</code>
 与自定义操作符的注册路径基本相同
，这使得自定义操作符
真正成为一等公民当谈到如何以及在何处可以在TorchScript 中使用它们时。
 (但是，一个区别是标准库函数
具有与
 <code>torch.ops</code>
 参数解析不同的自定义编写的 Python 参数解析逻辑。)</p>
<h3 id="_3">使用自定义运算符进行跟踪 <a href="#using-the-custom-operator-with-tracing" title="永久链接到此标题">¶</a></h3>
<p>让’s 首先将我们的运算符嵌入到跟踪函数中。回想一下，对于
跟踪，我们从一些普通的 Pytorch 代码开始：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>def compute(x, y, z):
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>    return x.matmul(y) + torch.relu(z)
</code></pre></div>
<p>然后对其调用
 <code>torch.jit.trace</code>。我们进一步传递<code>torch.jit.trace</code>一些示例输入，它将转发到我们的实现以记录输入流经它时发生的操作序列。结果
这实际上是急切 PyTorch 程序的 “frozen” 版本，
TorchScript 编译器可以进一步分析、优化和序列化：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(4, 5)]
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>trace = torch.jit.trace(compute, inputs)
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>print(trace.graph)
</code></pre></div>
<p>制作：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>graph(%x : Float(4:8, 8:1),
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>      %y : Float(8:5, 5:1),
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>      %z : Float(4:5, 5:1)):
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>  %3 : Float(4:5, 5:1) = aten::matmul(%x, %y) # test.py:10:0
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>  %4 : Float(4:5, 5:1) = aten::relu(%z) # test.py:10:0
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>  %5 : int = prim::Constant[value=1]() # test.py:10:0
<a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a>  %6 : Float(4:5, 5:1) = aten::add(%3, %4, %5) # test.py:10:0
<a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a>  return (%6)
</code></pre></div>
<p>现在，令人兴奋的发现是，我们可以简单地将自定义运算符放入
我们的 PyTorch 跟踪中，就像
 <code>torch.relu</code>
 或任何其他
 <code>torch</code>
 函数一样：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>def compute(x, y, z):
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>    x = torch.ops.my_ops.warp_perspective(x, torch.eye(3))
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>    return x.matmul(y) + torch.relu(z)
</code></pre></div>
<p>然后像以前一样跟踪它：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(8, 5)]
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>trace = torch.jit.trace(compute, inputs)
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>print(trace.graph)
</code></pre></div>
<p>制作：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>graph(%x.1 : Float(4:8, 8:1),
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>      %y : Float(8:5, 5:1),
<a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a>      %z : Float(8:5, 5:1)):
<a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a>  %3 : int = prim::Constant[value=3]() # test.py:25:0
<a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a>  %4 : int = prim::Constant[value=6]() # test.py:25:0
<a id="__codelineno-19-6" name="__codelineno-19-6" href="#__codelineno-19-6"></a>  %5 : int = prim::Constant[value=0]() # test.py:25:0
<a id="__codelineno-19-7" name="__codelineno-19-7" href="#__codelineno-19-7"></a>  %6 : Device = prim::Constant[value=&quot;cpu&quot;]() # test.py:25:0
<a id="__codelineno-19-8" name="__codelineno-19-8" href="#__codelineno-19-8"></a>  %7 : bool = prim::Constant[value=0]() # test.py:25:0
<a id="__codelineno-19-9" name="__codelineno-19-9" href="#__codelineno-19-9"></a>  %8 : Float(3:3, 3:1) = aten::eye(%3, %4, %5, %6, %7) # test.py:25:0
<a id="__codelineno-19-10" name="__codelineno-19-10" href="#__codelineno-19-10"></a>  %x : Float(8:8, 8:1) = my_ops::warp_perspective(%x.1, %8) # test.py:25:0
<a id="__codelineno-19-11" name="__codelineno-19-11" href="#__codelineno-19-11"></a>  %10 : Float(8:5, 5:1) = aten::matmul(%x, %y) # test.py:26:0
<a id="__codelineno-19-12" name="__codelineno-19-12" href="#__codelineno-19-12"></a>  %11 : Float(8:5, 5:1) = aten::relu(%z) # test.py:26:0
<a id="__codelineno-19-13" name="__codelineno-19-13" href="#__codelineno-19-13"></a>  %12 : int = prim::Constant[value=1]() # test.py:26:0
<a id="__codelineno-19-14" name="__codelineno-19-14" href="#__codelineno-19-14"></a>  %13 : Float(8:5, 5:1) = aten::add(%10, %11, %12) # test.py:26:0
<a id="__codelineno-19-15" name="__codelineno-19-15" href="#__codelineno-19-15"></a>  return (%13)
</code></pre></div>
<p>将 TorchScript 自定义操作集成到跟踪的 PyTorch 代码中就这么简单！</p>
<h3 id="_4">将自定义运算符与脚本一起使用 <a href="#using-the-custom-operator-with-script" title="永久链接到此标题">¶</a></h3>
<p>除了跟踪之外，获得 PyTorch 程序的 TorchScript 表示的另一种方法是直接编写代码
 <em>in</em> 
 TorchScript。 TorchScript 很大程度上是 Python 语言的子集，有一些限制使得 TorchScript 编译器更容易推理程序。您可以将
常规 PyTorch 代码转换为 TorchScript，方法是使用
 <code>@torch.jit.script</code>
 注释它(对于自由函数)，
 <code>@torch.jit.script_method</code>
 对于类中的方法
 (也必须源自
 <code>torch.jit.ScriptModule</code>
 )。有关 TorchScript 注释的更多详细信息，请参阅
 <a href="https://pytorch.org/docs/master/jit.html">此处</a>。</p>
<p>使用 TorchScript 而不是跟踪的一个特殊原因是跟踪无法捕获 PyTorch 代码中的控制流。因此，让我们考虑这个
确实使用控制流的函数：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>def compute(x, y):
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>  if bool(x[0][0] == 42):
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a>      z = 5
<a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a>  else:
<a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a>      z = 10
<a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a>  return x.matmul(y) + z
</code></pre></div>
<p>要将此函数从普通 PyTorch 转换为 TorchScript，我们用
注释它
<code>@torch.jit.script</code>
 :</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>@torch.jit.script
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>def compute(x, y):
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>  if bool(x[0][0] == 42):
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a>      z = 5
<a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a>  else:
<a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a>      z = 10
<a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a>  return x.matmul(y) + z
</code></pre></div>
<p>这将及时将
 <code>compute</code>
 函数编译为
图形表示，我们可以在
 <code>compute.graph</code>
 属性中检查
：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>&gt;&gt;&gt; compute.graph
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>graph(%x : Dynamic
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a> %y : Dynamic) {
<a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a> %14 : int = prim::Constant[value=1]()
<a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a> %2 : int = prim::Constant[value=0]()
<a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a> %7 : int = prim::Constant[value=42]()
<a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a> %z.1 : int = prim::Constant[value=5]()
<a id="__codelineno-22-8" name="__codelineno-22-8" href="#__codelineno-22-8"></a> %z.2 : int = prim::Constant[value=10]()
<a id="__codelineno-22-9" name="__codelineno-22-9" href="#__codelineno-22-9"></a> %4 : Dynamic = aten::select(%x, %2, %2)
<a id="__codelineno-22-10" name="__codelineno-22-10" href="#__codelineno-22-10"></a> %6 : Dynamic = aten::select(%4, %2, %2)
<a id="__codelineno-22-11" name="__codelineno-22-11" href="#__codelineno-22-11"></a> %8 : Dynamic = aten::eq(%6, %7)
<a id="__codelineno-22-12" name="__codelineno-22-12" href="#__codelineno-22-12"></a> %9 : bool = prim::TensorToBool(%8)
<a id="__codelineno-22-13" name="__codelineno-22-13" href="#__codelineno-22-13"></a> %z : int = prim::If(%9)
<a id="__codelineno-22-14" name="__codelineno-22-14" href="#__codelineno-22-14"></a> block0() {
<a id="__codelineno-22-15" name="__codelineno-22-15" href="#__codelineno-22-15"></a> -&gt; (%z.1)
<a id="__codelineno-22-16" name="__codelineno-22-16" href="#__codelineno-22-16"></a> }
<a id="__codelineno-22-17" name="__codelineno-22-17" href="#__codelineno-22-17"></a> block1() {
<a id="__codelineno-22-18" name="__codelineno-22-18" href="#__codelineno-22-18"></a> -&gt; (%z.2)
<a id="__codelineno-22-19" name="__codelineno-22-19" href="#__codelineno-22-19"></a> }
<a id="__codelineno-22-20" name="__codelineno-22-20" href="#__codelineno-22-20"></a> %13 : Dynamic = aten::matmul(%x, %y)
<a id="__codelineno-22-21" name="__codelineno-22-21" href="#__codelineno-22-21"></a> %15 : Dynamic = aten::add(%13, %z, %14)
<a id="__codelineno-22-22" name="__codelineno-22-22" href="#__codelineno-22-22"></a> return (%15);
<a id="__codelineno-22-23" name="__codelineno-22-23" href="#__codelineno-22-23"></a>}
</code></pre></div>
<p>现在，就像以前一样，我们可以像脚本代码中的任何其他
函数一样使用自定义运算符：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>torch.ops.load_library(&quot;libwarp_perspective.so&quot;)
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a>@torch.jit.script
<a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>def compute(x, y):
<a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a>  if bool(x[0] == 42):
<a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a>      z = 5
<a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a>  else:
<a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a>      z = 10
<a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a>  x = torch.ops.my_ops.warp_perspective(x, torch.eye(3))
<a id="__codelineno-23-10" name="__codelineno-23-10" href="#__codelineno-23-10"></a>  return x.matmul(y) + z
</code></pre></div>
<p>当 TorchScript 编译器看到对
 <code>torch.ops.my_ops.warp_perspective</code>
 的引用时，它将找到我们
通过
 <code>TORCH_LIBRARY</code> 注册的实现
 C++ 中的函数，并将其编译为其
图形表示形式:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>&gt;&gt;&gt; compute.graph
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>graph(%x.1 : Dynamic
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a> %y : Dynamic) {
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a> %20 : int = prim::Constant[value=1]()
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a> %16 : int[] = prim::Constant[value=[0, -1]]()
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a> %14 : int = prim::Constant[value=6]()
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a> %2 : int = prim::Constant[value=0]()
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a> %7 : int = prim::Constant[value=42]()
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a> %z.1 : int = prim::Constant[value=5]()
<a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a> %z.2 : int = prim::Constant[value=10]()
<a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a> %13 : int = prim::Constant[value=3]()
<a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a> %4 : Dynamic = aten::select(%x.1, %2, %2)
<a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a> %6 : Dynamic = aten::select(%4, %2, %2)
<a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a> %8 : Dynamic = aten::eq(%6, %7)
<a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a> %9 : bool = prim::TensorToBool(%8)
<a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a> %z : int = prim::If(%9)
<a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a> block0() {
<a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a> -&gt; (%z.1)
<a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a> }
<a id="__codelineno-24-20" name="__codelineno-24-20" href="#__codelineno-24-20"></a> block1() {
<a id="__codelineno-24-21" name="__codelineno-24-21" href="#__codelineno-24-21"></a> -&gt; (%z.2)
<a id="__codelineno-24-22" name="__codelineno-24-22" href="#__codelineno-24-22"></a> }
<a id="__codelineno-24-23" name="__codelineno-24-23" href="#__codelineno-24-23"></a> %17 : Dynamic = aten::eye(%13, %14, %2, %16)
<a id="__codelineno-24-24" name="__codelineno-24-24" href="#__codelineno-24-24"></a> %x : Dynamic = my_ops::warp_perspective(%x.1, %17)
<a id="__codelineno-24-25" name="__codelineno-24-25" href="#__codelineno-24-25"></a> %19 : Dynamic = aten::matmul(%x, %y)
<a id="__codelineno-24-26" name="__codelineno-24-26" href="#__codelineno-24-26"></a> %21 : Dynamic = aten::add(%19, %z, %20)
<a id="__codelineno-24-27" name="__codelineno-24-27" href="#__codelineno-24-27"></a> return (%21);
<a id="__codelineno-24-28" name="__codelineno-24-28" href="#__codelineno-24-28"></a> }
</code></pre></div>
<p>特别注意图表末尾
 处对
 <code>my_ops::warp_perspective</code> 的引用。</p>
<p>注意</p>
<p>TorchScript 图形表示仍可能发生变化。不要依赖
它看起来像这样。</p>
<p>在 Python 中使用我们的自定义运算符时，’ 确实如此。简而言之，您使用
 <code>torch.ops.load_library</code>
 导入包含运算符的库，并像任何其他
 <code>torch</code>
 运算符一样从跟踪或调用您的自定义操作脚本化 TorchScript 代码。</p>
<h2 id="c-torchscript_1">在 C++ 中使用 TorchScript 自定义运算符 <a href="#using-the-torchscript-custom-operator-in-c" title="永久链接到此标题">¶</a></h2>
<p>TorchScript 的一项有用功能是能够将模型序列化为\非磁盘文件。该文件可以通过线路发送、存储在文件系统中，或者更重要的是，可以动态反序列化和执行，而无需保留原始源代码。这在 Python 中是可能的，但在 C++ 中也是如此。为此，PyTorch 提供了<a href="https://pytorch.org/cppdocs/">纯 C++ API</a> 用于反序列化以及执行 TorchScript 模型。如果您还没有 ’t，
请阅读
 <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">在 C++ 中加载和运行序列化 TorchScript 模型的教程</a> 
 , 
接下来的几段内容将以此为基础。</p>
<p>简而言之，自定义运算符可以像常规
 <code>torch</code>
 运算符
 一样执行，甚至可以从文件反序列化并在 C++ 中运行。唯一的要求是将我们之前构建的自定义运算符共享库与执行模型的 C++ 应用程序链接起来。在 Python 中，只需调用
 <code>torch.ops.load_library</code>
 即可。在 C++ 中，您需要将共享库与
您使用的任何构建系统中的主应用程序链接起来。以下
示例将使用 CMake 展示这一点。</p>
<p>注意</p>
<p>从技术上讲，您还可以在运行时将共享库动态加载到 C++
应用程序中，就像我们在 Python 中所做的那样。在 Linux 上，
 <a href="https://tldp.org/HOWTO/Program-Library-HOWTO/dl-libraries.html">您可以使用 dlopen 执行此操作</a> 
 。其他平台上存在
等效项。</p>
<p>以上面链接的 C++ 执行教程为基础，让’s 从一个文件中的最小
C++ 应用程序开始，
 <code>main.cpp</code>
 与我们的自定义运算符位于不同的文件夹中，加载并执行序列化的 TorchScript 模型:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>#include &lt;torch/script.h&gt; // One-stop header.
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a>#include &lt;iostream&gt;
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a>#include &lt;memory&gt;
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a>
<a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a>
<a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a>int main(int argc, const char* argv[]) {
<a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a> if (argc != 2) {
<a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a> std::cerr &lt;&lt; &quot;usage: example-app &lt;path-to-exported-script-module&gt;&quot;;
<a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a> return -1;
<a id="__codelineno-25-11" name="__codelineno-25-11" href="#__codelineno-25-11"></a> }
<a id="__codelineno-25-12" name="__codelineno-25-12" href="#__codelineno-25-12"></a>
<a id="__codelineno-25-13" name="__codelineno-25-13" href="#__codelineno-25-13"></a> // Deserialize the ScriptModule from a file using torch::jit::load().
<a id="__codelineno-25-14" name="__codelineno-25-14" href="#__codelineno-25-14"></a> torch::jit::script::Module module = torch::jit::load(argv[1]);
<a id="__codelineno-25-15" name="__codelineno-25-15" href="#__codelineno-25-15"></a>
<a id="__codelineno-25-16" name="__codelineno-25-16" href="#__codelineno-25-16"></a> std::vector&lt;torch::jit::IValue&gt; inputs;
<a id="__codelineno-25-17" name="__codelineno-25-17" href="#__codelineno-25-17"></a> inputs.push_back(torch::randn({4, 8}));
<a id="__codelineno-25-18" name="__codelineno-25-18" href="#__codelineno-25-18"></a> inputs.push_back(torch::randn({8, 5}));
<a id="__codelineno-25-19" name="__codelineno-25-19" href="#__codelineno-25-19"></a>
<a id="__codelineno-25-20" name="__codelineno-25-20" href="#__codelineno-25-20"></a> torch::Tensor output = module.forward(std::move(inputs)).toTensor();
<a id="__codelineno-25-21" name="__codelineno-25-21" href="#__codelineno-25-21"></a>
<a id="__codelineno-25-22" name="__codelineno-25-22" href="#__codelineno-25-22"></a> std::cout &lt;&lt; output &lt;&lt; std::endl;
<a id="__codelineno-25-23" name="__codelineno-25-23" href="#__codelineno-25-23"></a>}
</code></pre></div>
<p>以及一个小
 <code>CMakeLists.txt</code>
 文件：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>cmake_minimum_required(VERSION 3.1 FATAL_ERROR)
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>project(example_app)
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>
<a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a>find_package(Torch REQUIRED)
<a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>
<a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a>add_executable(example_app main.cpp)
<a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a>target_link_libraries(example_app &quot;${TORCH_LIBRARIES}&quot;)
<a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a>target_compile_features(example_app PRIVATE cxx_range_for)
</code></pre></div>
<p>此时，我们应该能够构建应用程序：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>$ mkdir build
<a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>$ cd build
<a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>$ cmake -DCMAKE_PREFIX_PATH=&quot;$(python -c &#39;import torch.utils; print(torch.utils.cmake_prefix_path)&#39;)&quot; ..
<a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>-- The C compiler identification is GNU 5.4.0
<a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>-- The CXX compiler identification is GNU 5.4.0
<a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a>-- Check for working C compiler: /usr/bin/cc
<a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a>-- Check for working C compiler: /usr/bin/cc -- works
<a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a>-- Detecting C compiler ABI info
<a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a>-- Detecting C compiler ABI info - done
<a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a>-- Detecting C compile features
<a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a>-- Detecting C compile features - done
<a id="__codelineno-27-12" name="__codelineno-27-12" href="#__codelineno-27-12"></a>-- Check for working CXX compiler: /usr/bin/c++
<a id="__codelineno-27-13" name="__codelineno-27-13" href="#__codelineno-27-13"></a>-- Check for working CXX compiler: /usr/bin/c++ -- works
<a id="__codelineno-27-14" name="__codelineno-27-14" href="#__codelineno-27-14"></a>-- Detecting CXX compiler ABI info
<a id="__codelineno-27-15" name="__codelineno-27-15" href="#__codelineno-27-15"></a>-- Detecting CXX compiler ABI info - done
<a id="__codelineno-27-16" name="__codelineno-27-16" href="#__codelineno-27-16"></a>-- Detecting CXX compile features
<a id="__codelineno-27-17" name="__codelineno-27-17" href="#__codelineno-27-17"></a>-- Detecting CXX compile features - done
<a id="__codelineno-27-18" name="__codelineno-27-18" href="#__codelineno-27-18"></a>-- Looking for pthread.h
<a id="__codelineno-27-19" name="__codelineno-27-19" href="#__codelineno-27-19"></a>-- Looking for pthread.h - found
<a id="__codelineno-27-20" name="__codelineno-27-20" href="#__codelineno-27-20"></a>-- Looking for pthread_create
<a id="__codelineno-27-21" name="__codelineno-27-21" href="#__codelineno-27-21"></a>-- Looking for pthread_create - not found
<a id="__codelineno-27-22" name="__codelineno-27-22" href="#__codelineno-27-22"></a>-- Looking for pthread_create in pthreads
<a id="__codelineno-27-23" name="__codelineno-27-23" href="#__codelineno-27-23"></a>-- Looking for pthread_create in pthreads - not found
<a id="__codelineno-27-24" name="__codelineno-27-24" href="#__codelineno-27-24"></a>-- Looking for pthread_create in pthread
<a id="__codelineno-27-25" name="__codelineno-27-25" href="#__codelineno-27-25"></a>-- Looking for pthread_create in pthread - found
<a id="__codelineno-27-26" name="__codelineno-27-26" href="#__codelineno-27-26"></a>-- Found Threads: TRUE
<a id="__codelineno-27-27" name="__codelineno-27-27" href="#__codelineno-27-27"></a>-- Found torch: /libtorch/lib/libtorch.so
<a id="__codelineno-27-28" name="__codelineno-27-28" href="#__codelineno-27-28"></a>-- Configuring done
<a id="__codelineno-27-29" name="__codelineno-27-29" href="#__codelineno-27-29"></a>-- Generating done
<a id="__codelineno-27-30" name="__codelineno-27-30" href="#__codelineno-27-30"></a>-- Build files have been written to: /example_app/build
<a id="__codelineno-27-31" name="__codelineno-27-31" href="#__codelineno-27-31"></a>$ make -j
<a id="__codelineno-27-32" name="__codelineno-27-32" href="#__codelineno-27-32"></a>Scanning dependencies of target example_app
<a id="__codelineno-27-33" name="__codelineno-27-33" href="#__codelineno-27-33"></a>[ 50%] Building CXX object CMakeFiles/example_app.dir/main.cpp.o
<a id="__codelineno-27-34" name="__codelineno-27-34" href="#__codelineno-27-34"></a>[100%] Linking CXX executable example_app
<a id="__codelineno-27-35" name="__codelineno-27-35" href="#__codelineno-27-35"></a>[100%] Built target example_app
</code></pre></div>
<p>并在不传递模型的情况下运行它：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>$ ./example_app
<a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a>usage: example_app &lt;path-to-exported-script-module&gt;
</code></pre></div>
<p>接下来，让’s 序列化我们之前编写的使用自定义运算符的脚本函数：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>torch.ops.load_library(&quot;libwarp_perspective.so&quot;)
<a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a>
<a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a>@torch.jit.script
<a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a>def compute(x, y):
<a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a>  if bool(x[0][0] == 42):
<a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a>      z = 5
<a id="__codelineno-29-7" name="__codelineno-29-7" href="#__codelineno-29-7"></a>  else:
<a id="__codelineno-29-8" name="__codelineno-29-8" href="#__codelineno-29-8"></a>      z = 10
<a id="__codelineno-29-9" name="__codelineno-29-9" href="#__codelineno-29-9"></a>  x = torch.ops.my_ops.warp_perspective(x, torch.eye(3))
<a id="__codelineno-29-10" name="__codelineno-29-10" href="#__codelineno-29-10"></a>  return x.matmul(y) + z
<a id="__codelineno-29-11" name="__codelineno-29-11" href="#__codelineno-29-11"></a>
<a id="__codelineno-29-12" name="__codelineno-29-12" href="#__codelineno-29-12"></a>compute.save(&quot;example.pt&quot;)
</code></pre></div>
<p>最后一行将脚本函数序列化到名为
“example.pt” 的文件中。如果我们随后将此序列化模型传递给我们的 C++ 应用程序，
我们可以立即运行它：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>$ ./example_app example.pt
<a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a>terminate called after throwing an instance of &#39;torch::jit::script::ErrorReport&#39;
<a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a>what():
<a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a>Schema not found for node. File a bug report.
<a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a>Node: %16 : Dynamic = my_ops::warp_perspective(%0, %19)
</code></pre></div>
<p>或者也许不是。也许还没有。当然！我们还没有’t 将自定义
ooperator 库与我们的应用程序链接起来。让’s 立即执行此操作，并
正确执行此操作，让’s 稍微更新我们的文件组织，如下所示：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a>example_app/
<a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a>  CMakeLists.txt
<a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a>  main.cpp
<a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a>  warp_perspective/
<a id="__codelineno-31-5" name="__codelineno-31-5" href="#__codelineno-31-5"></a>    CMakeLists.txt
<a id="__codelineno-31-6" name="__codelineno-31-6" href="#__codelineno-31-6"></a>    op.cpp
</code></pre></div>
<p>这将允许我们将 
 <code>warp_perspective</code>
 库 CMake 目标添加为 
 应用程序目标的子目录。 
 <code>example_app</code>
 文件夹中的
 顶层
 <code>CMakeLists.txt</code>
 应如下所示：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>cmake_minimum_required(VERSION 3.1 FATAL_ERROR)
<a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a>project(example_app)
<a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a>
<a id="__codelineno-32-4" name="__codelineno-32-4" href="#__codelineno-32-4"></a>find_package(Torch REQUIRED)
<a id="__codelineno-32-5" name="__codelineno-32-5" href="#__codelineno-32-5"></a>
<a id="__codelineno-32-6" name="__codelineno-32-6" href="#__codelineno-32-6"></a>add_subdirectory(warp_perspective)
<a id="__codelineno-32-7" name="__codelineno-32-7" href="#__codelineno-32-7"></a>
<a id="__codelineno-32-8" name="__codelineno-32-8" href="#__codelineno-32-8"></a>add_executable(example_app main.cpp)
<a id="__codelineno-32-9" name="__codelineno-32-9" href="#__codelineno-32-9"></a>target_link_libraries(example_app &quot;${TORCH_LIBRARIES}&quot;)
<a id="__codelineno-32-10" name="__codelineno-32-10" href="#__codelineno-32-10"></a>target_link_libraries(example_app -Wl,--no-as-needed warp_perspective)
<a id="__codelineno-32-11" name="__codelineno-32-11" href="#__codelineno-32-11"></a>target_compile_features(example_app PRIVATE cxx_range_for)
</code></pre></div>
<p>这个基本的 CMake 配置看起来很像以前，除了我们添加 
 <code>warp_perspective</code>
 CMake build 作为子目录。 CMake 代码运行后，我们会将我们的
 <code>example_app</code>
 应用程序与</p>
<p><code>warp_perspective</code>
 共享库链接起来。</p>
<p>注意</p>
<p>上面的示例中嵌入了一个关键细节：链接行的“-Wl,--no-as-needed”前缀。这是必需的，因为我们实际上不会在应用程序代码中调用来自“warp_perspective”共享库的任何函数。我们只需要
 <code>TORCH_LIBRARY</code>
 函数即可运行。不方便的是，这会使链接器感到困惑，并使其认为可以完全跳过对库的链接。在 Linux 上，
 <code>-Wl,--no-as-needed</code>
 标志强制链接发生(注意：此标志特定于 Linux！)。 
对此还有其他解决方法。最简单的方法是在运算符库中定义
<em>某些函数</em>
，您需要从主应用程序调用该函数。这可以像在某个标头中声明的
函数
 `void</p>
<p>init();<code>一样简单，然后定义为</code>void</p>
<p>init()\ n </p>
<p>{</p>
<p>}<code>在运算符库中。在主应用程序中调用此</code>init()`
 函数会给链接器留下这是一个值得链接的库的印象。不幸的是，这超出了我们的控制范围，
我们宁愿让您知道原因和简单的解决方法
，而不是给您一些不透明的宏来放入您的代码中。</p>
<p>现在，由于我们在顶层找到了
 <code>Torch</code>
 包，因此
 <code>warp_perspective</code>
 子目录中的
 <code>CMakeLists.txt</code>
 文件可以是
缩短了一点。它应该看起来像这样：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a>find_package(OpenCV REQUIRED)
<a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a>add_library(warp_perspective SHARED op.cpp)
<a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a>target_compile_features(warp_perspective PRIVATE cxx_range_for)
<a id="__codelineno-33-4" name="__codelineno-33-4" href="#__codelineno-33-4"></a>target_link_libraries(warp_perspective PRIVATE &quot;${TORCH_LIBRARIES}&quot;)
<a id="__codelineno-33-5" name="__codelineno-33-5" href="#__codelineno-33-5"></a>target_link_libraries(warp_perspective PRIVATE opencv_core opencv_photo)
</code></pre></div>
<p>让’s 重新构建我们的示例应用程序，该应用程序也将与自定义运算符
库链接。在顶级
 <code>example_app</code>
 目录中:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a>$ mkdir build
<a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a>$ cd build
<a id="__codelineno-34-3" name="__codelineno-34-3" href="#__codelineno-34-3"></a>$ cmake -DCMAKE_PREFIX_PATH=&quot;$(python -c &#39;import torch.utils; print(torch.utils.cmake_prefix_path)&#39;)&quot; ..
<a id="__codelineno-34-4" name="__codelineno-34-4" href="#__codelineno-34-4"></a>-- The C compiler identification is GNU 5.4.0
<a id="__codelineno-34-5" name="__codelineno-34-5" href="#__codelineno-34-5"></a>-- The CXX compiler identification is GNU 5.4.0
<a id="__codelineno-34-6" name="__codelineno-34-6" href="#__codelineno-34-6"></a>-- Check for working C compiler: /usr/bin/cc
<a id="__codelineno-34-7" name="__codelineno-34-7" href="#__codelineno-34-7"></a>-- Check for working C compiler: /usr/bin/cc -- works
<a id="__codelineno-34-8" name="__codelineno-34-8" href="#__codelineno-34-8"></a>-- Detecting C compiler ABI info
<a id="__codelineno-34-9" name="__codelineno-34-9" href="#__codelineno-34-9"></a>-- Detecting C compiler ABI info - done
<a id="__codelineno-34-10" name="__codelineno-34-10" href="#__codelineno-34-10"></a>-- Detecting C compile features
<a id="__codelineno-34-11" name="__codelineno-34-11" href="#__codelineno-34-11"></a>-- Detecting C compile features - done
<a id="__codelineno-34-12" name="__codelineno-34-12" href="#__codelineno-34-12"></a>-- Check for working CXX compiler: /usr/bin/c++
<a id="__codelineno-34-13" name="__codelineno-34-13" href="#__codelineno-34-13"></a>-- Check for working CXX compiler: /usr/bin/c++ -- works
<a id="__codelineno-34-14" name="__codelineno-34-14" href="#__codelineno-34-14"></a>-- Detecting CXX compiler ABI info
<a id="__codelineno-34-15" name="__codelineno-34-15" href="#__codelineno-34-15"></a>-- Detecting CXX compiler ABI info - done
<a id="__codelineno-34-16" name="__codelineno-34-16" href="#__codelineno-34-16"></a>-- Detecting CXX compile features
<a id="__codelineno-34-17" name="__codelineno-34-17" href="#__codelineno-34-17"></a>-- Detecting CXX compile features - done
<a id="__codelineno-34-18" name="__codelineno-34-18" href="#__codelineno-34-18"></a>-- Looking for pthread.h
<a id="__codelineno-34-19" name="__codelineno-34-19" href="#__codelineno-34-19"></a>-- Looking for pthread.h - found
<a id="__codelineno-34-20" name="__codelineno-34-20" href="#__codelineno-34-20"></a>-- Looking for pthread_create
<a id="__codelineno-34-21" name="__codelineno-34-21" href="#__codelineno-34-21"></a>-- Looking for pthread_create - not found
<a id="__codelineno-34-22" name="__codelineno-34-22" href="#__codelineno-34-22"></a>-- Looking for pthread_create in pthreads
<a id="__codelineno-34-23" name="__codelineno-34-23" href="#__codelineno-34-23"></a>-- Looking for pthread_create in pthreads - not found
<a id="__codelineno-34-24" name="__codelineno-34-24" href="#__codelineno-34-24"></a>-- Looking for pthread_create in pthread
<a id="__codelineno-34-25" name="__codelineno-34-25" href="#__codelineno-34-25"></a>-- Looking for pthread_create in pthread - found
<a id="__codelineno-34-26" name="__codelineno-34-26" href="#__codelineno-34-26"></a>-- Found Threads: TRUE
<a id="__codelineno-34-27" name="__codelineno-34-27" href="#__codelineno-34-27"></a>-- Found torch: /libtorch/lib/libtorch.so
<a id="__codelineno-34-28" name="__codelineno-34-28" href="#__codelineno-34-28"></a>-- Configuring done
<a id="__codelineno-34-29" name="__codelineno-34-29" href="#__codelineno-34-29"></a>-- Generating done
<a id="__codelineno-34-30" name="__codelineno-34-30" href="#__codelineno-34-30"></a>-- Build files have been written to: /warp_perspective/example_app/build
<a id="__codelineno-34-31" name="__codelineno-34-31" href="#__codelineno-34-31"></a>$ make -j
<a id="__codelineno-34-32" name="__codelineno-34-32" href="#__codelineno-34-32"></a>Scanning dependencies of target warp_perspective
<a id="__codelineno-34-33" name="__codelineno-34-33" href="#__codelineno-34-33"></a>[ 25%] Building CXX object warp_perspective/CMakeFiles/warp_perspective.dir/op.cpp.o
<a id="__codelineno-34-34" name="__codelineno-34-34" href="#__codelineno-34-34"></a>[ 50%] Linking CXX shared library libwarp_perspective.so
<a id="__codelineno-34-35" name="__codelineno-34-35" href="#__codelineno-34-35"></a>[ 50%] Built target warp_perspective
<a id="__codelineno-34-36" name="__codelineno-34-36" href="#__codelineno-34-36"></a>Scanning dependencies of target example_app
<a id="__codelineno-34-37" name="__codelineno-34-37" href="#__codelineno-34-37"></a>[ 75%] Building CXX object CMakeFiles/example_app.dir/main.cpp.o
<a id="__codelineno-34-38" name="__codelineno-34-38" href="#__codelineno-34-38"></a>[100%] Linking CXX executable example_app
<a id="__codelineno-34-39" name="__codelineno-34-39" href="#__codelineno-34-39"></a>[100%] Built target example_app
</code></pre></div>
<p>如果我们现在运行
 <code>example_app</code>
 二进制文件并将我们的序列化模型交给它，
我们应该会得到一个圆满的结局：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a>$ ./example_app example.pt
<a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a>11.4125 5.8262 9.5345 8.6111 12.3997
<a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a> 7.4683 13.5969 9.0850 11.0698 9.4008
<a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a> 7.4597 15.0926 12.5727 8.9319 9.0666
<a id="__codelineno-35-5" name="__codelineno-35-5" href="#__codelineno-35-5"></a> 9.4834 11.1747 9.0162 10.9521 8.6269
<a id="__codelineno-35-6" name="__codelineno-35-6" href="#__codelineno-35-6"></a>10.0000 10.0000 10.0000 10.0000 10.0000
<a id="__codelineno-35-7" name="__codelineno-35-7" href="#__codelineno-35-7"></a>10.0000 10.0000 10.0000 10.0000 10.0000
<a id="__codelineno-35-8" name="__codelineno-35-8" href="#__codelineno-35-8"></a>10.0000 10.0000 10.0000 10.0000 10.0000
<a id="__codelineno-35-9" name="__codelineno-35-9" href="#__codelineno-35-9"></a>10.0000 10.0000 10.0000 10.0000 10.0000
<a id="__codelineno-35-10" name="__codelineno-35-10" href="#__codelineno-35-10"></a>[ Variable[CPUFloatType]{8,5} ]
</code></pre></div>
<p>成功！您现在已准备好进行推断。</p>
<h2 id="_5">结论 <a href="#conclusion" title="此标题的永久链接">¶</a></h2>
<p>本教程向您介绍了如何在 C++ 中实现自定义 TorchScript 运算符、如何将其构建到共享库、如何在 Python 中使用它来定义
TorchScript 模型以及最后如何将其加载到 C++ 应用程序中
推理工作负载。现在，您可以使用与第三方 C++ 库交互的 C++ 运算符来扩展您的 TorchScript 模型，编写自定义高性能 CUDA 内核，或实现需要 Python、TorchScript 和 C++ 之间的顺畅融合的任何其他用例。 </p>
<p>一如既往，如果您遇到任何问题或有疑问，可以使用我们的
 <a href="https://discuss.pytorch.org/">论坛</a> 
 或
 <a href="https://github.com/pytorch/pytorch/issues">GitHub issues</a> 
 取得联系。此外，我们的
 <a href="https://pytorch.org/cppdocs/notes/faq.html">常见问题 (FAQ) 页面</a>
 可能包含有用的信息。</p>
<h2 id="a">附录 A：构建自定义运算符的更多方法 <a href="#appendix-a-more-ways-of-building-custom-operators" title="永久链接到此标题">¶</a></h2>
<p>“构建自定义运算符”部分解释了如何使用 CMake 将自定义
运算符构建到共享库中。本附录概述了另外两种
编译方法。它们都使用Python作为编译过程的“driver”或
“接口”。此外，两者都重新使用
 <a href="https://pytorch.org/docs/stable/cpp_extension.html">现有\基础设施</a> 
 PyTorch
提供
 <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html"><em>C++ 扩展</em></a> 
 ，这是依赖于 
 <a href="https://github.com/pybind/pybind11">pybind11</a> 
 用于将 C++ 函数</p>
<p>“explicit” 绑定到 Python 中。</p>
<p>第一种方法使用 C++ 扩展’
 <a href="https://pytorch.org/docs/stable/cpp_extension.html#torch.utils.cpp_extension.load">方便的即时 (JIT)
编译接口</a> 
 以便在您第一次运行 PyTorch 脚本时
在后台编译您的代码。第二种方法依赖于古老的
 <code>setuptools</code>
 包并涉及
 编写单独的
 <code>setup.py</code>
 文件。这允许更高级的
配置以及与其他
基于<code>setuptools</code>
的项目的集成。
我们将在下面详细探讨这两种方法。</p>
<h3 id="jit">使用 JIT 编译进行构建 <a href="#building-with-jit-compilation" title="永久链接到此标题">¶</a></h3>
<p>PyTorch C++ 扩展工具包提供的 JIT 编译功能允许将自定义运算符的编译直接嵌入到 Python 代码中，例如在训练脚本的顶部。</p>
<p>注意</p>
<p>“JIT 编译” 这里与 TorchScript 编译器中进行的 JIT 编译无关，以优化你的程序。它只是意味着
您的自定义运算符 C++ 代码将在您第一次导入时编译到系统’s</p>
<p>/tmp</p>
<p>目录下的文件夹中，就好像您已编译它一样\事先你自己。</p>
<p>这个 JIT 编译功能有两种风格。在第一个中，您仍然将运算符实现保存在单独的文件 (
 <code>op.cpp</code>
 ) 中，然后使用
 <code>torch.utils.cpp_extension.load()</code>
 进行编译你的分机。通常，此函数将返回公开 C++ 扩展的 Python 模块。然而，由于我们没有将自定义运算符编译到它自己的 Python 模块中，因此我们只想编译一个普通的共享库。幸运的是，
 <code>torch.utils.cpp_extension.load()</code>
 有一个参数
 <code>is_python_module</code>
，
我们可以将其设置为
 <code>False</code>
表明我们只对构建
共享库感兴趣，而不是 Python 模块。
 <code>torch.utils.cpp_extension.load()</code>
 然后将编译并将共享库加载到当前进程中， 
就像
 <code>torch.ops.load_library</code>
 之前所做的那样：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a>import torch.utils.cpp_extension
<a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a>
<a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a>torch.utils.cpp_extension.load(
<a id="__codelineno-36-4" name="__codelineno-36-4" href="#__codelineno-36-4"></a>    name=&quot;warp_perspective&quot;,
<a id="__codelineno-36-5" name="__codelineno-36-5" href="#__codelineno-36-5"></a>    sources=[&quot;op.cpp&quot;],
<a id="__codelineno-36-6" name="__codelineno-36-6" href="#__codelineno-36-6"></a>    extra_ldflags=[&quot;-lopencv_core&quot;, &quot;-lopencv_imgproc&quot;],
<a id="__codelineno-36-7" name="__codelineno-36-7" href="#__codelineno-36-7"></a>    is_python_module=False,
<a id="__codelineno-36-8" name="__codelineno-36-8" href="#__codelineno-36-8"></a>    verbose=True
<a id="__codelineno-36-9" name="__codelineno-36-9" href="#__codelineno-36-9"></a>)
<a id="__codelineno-36-10" name="__codelineno-36-10" href="#__codelineno-36-10"></a>
<a id="__codelineno-36-11" name="__codelineno-36-11" href="#__codelineno-36-11"></a>print(torch.ops.my_ops.warp_perspective)
</code></pre></div>
<p>这应该大约打印：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a>&lt;built-in method my_ops::warp_perspective of PyCapsule object at 0x7f3e0f840b10&gt;
</code></pre></div>
<p>JIT 编译的第二种风格允许您将自定义 TorchScript 运算符的源代码作为字符串传递。为此，请使用
 <code>torch.utils.cpp_extension.load_inline</code>
 :</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a>import torch
<a id="__codelineno-38-2" name="__codelineno-38-2" href="#__codelineno-38-2"></a>import torch.utils.cpp_extension
<a id="__codelineno-38-3" name="__codelineno-38-3" href="#__codelineno-38-3"></a>
<a id="__codelineno-38-4" name="__codelineno-38-4" href="#__codelineno-38-4"></a>op_source = &quot;&quot;&quot;
<a id="__codelineno-38-5" name="__codelineno-38-5" href="#__codelineno-38-5"></a>#include &lt;opencv2/opencv.hpp&gt;
<a id="__codelineno-38-6" name="__codelineno-38-6" href="#__codelineno-38-6"></a>#include &lt;torch/script.h&gt;
<a id="__codelineno-38-7" name="__codelineno-38-7" href="#__codelineno-38-7"></a>
<a id="__codelineno-38-8" name="__codelineno-38-8" href="#__codelineno-38-8"></a>torch::Tensor warp_perspective(torch::Tensor image, torch::Tensor warp) {
<a id="__codelineno-38-9" name="__codelineno-38-9" href="#__codelineno-38-9"></a> cv::Mat image_mat(/*rows=*/image.size(0),
<a id="__codelineno-38-10" name="__codelineno-38-10" href="#__codelineno-38-10"></a> /*cols=*/image.size(1),
<a id="__codelineno-38-11" name="__codelineno-38-11" href="#__codelineno-38-11"></a> /*type=*/CV_32FC1,
<a id="__codelineno-38-12" name="__codelineno-38-12" href="#__codelineno-38-12"></a> /*data=*/image.data&lt;float&gt;());
<a id="__codelineno-38-13" name="__codelineno-38-13" href="#__codelineno-38-13"></a> cv::Mat warp_mat(/*rows=*/warp.size(0),
<a id="__codelineno-38-14" name="__codelineno-38-14" href="#__codelineno-38-14"></a> /*cols=*/warp.size(1),
<a id="__codelineno-38-15" name="__codelineno-38-15" href="#__codelineno-38-15"></a> /*type=*/CV_32FC1,
<a id="__codelineno-38-16" name="__codelineno-38-16" href="#__codelineno-38-16"></a> /*data=*/warp.data&lt;float&gt;());
<a id="__codelineno-38-17" name="__codelineno-38-17" href="#__codelineno-38-17"></a>
<a id="__codelineno-38-18" name="__codelineno-38-18" href="#__codelineno-38-18"></a> cv::Mat output_mat;
<a id="__codelineno-38-19" name="__codelineno-38-19" href="#__codelineno-38-19"></a> cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{64, 64});
<a id="__codelineno-38-20" name="__codelineno-38-20" href="#__codelineno-38-20"></a>
<a id="__codelineno-38-21" name="__codelineno-38-21" href="#__codelineno-38-21"></a> torch::Tensor output =
<a id="__codelineno-38-22" name="__codelineno-38-22" href="#__codelineno-38-22"></a> torch::from_blob(output_mat.ptr&lt;float&gt;(), /*sizes=*/{64, 64});
<a id="__codelineno-38-23" name="__codelineno-38-23" href="#__codelineno-38-23"></a> return output.clone();
<a id="__codelineno-38-24" name="__codelineno-38-24" href="#__codelineno-38-24"></a>}
<a id="__codelineno-38-25" name="__codelineno-38-25" href="#__codelineno-38-25"></a>
<a id="__codelineno-38-26" name="__codelineno-38-26" href="#__codelineno-38-26"></a>TORCH_LIBRARY(my_ops, m) {
<a id="__codelineno-38-27" name="__codelineno-38-27" href="#__codelineno-38-27"></a> m.def(&quot;warp_perspective&quot;, &amp;warp_perspective);
<a id="__codelineno-38-28" name="__codelineno-38-28" href="#__codelineno-38-28"></a>}
<a id="__codelineno-38-29" name="__codelineno-38-29" href="#__codelineno-38-29"></a>&quot;&quot;&quot;
<a id="__codelineno-38-30" name="__codelineno-38-30" href="#__codelineno-38-30"></a>
<a id="__codelineno-38-31" name="__codelineno-38-31" href="#__codelineno-38-31"></a>torch.utils.cpp_extension.load_inline(
<a id="__codelineno-38-32" name="__codelineno-38-32" href="#__codelineno-38-32"></a>    name=&quot;warp_perspective&quot;,
<a id="__codelineno-38-33" name="__codelineno-38-33" href="#__codelineno-38-33"></a>    cpp_sources=op_source,
<a id="__codelineno-38-34" name="__codelineno-38-34" href="#__codelineno-38-34"></a>    extra_ldflags=[&quot;-lopencv_core&quot;, &quot;-lopencv_imgproc&quot;],
<a id="__codelineno-38-35" name="__codelineno-38-35" href="#__codelineno-38-35"></a>    is_python_module=False,
<a id="__codelineno-38-36" name="__codelineno-38-36" href="#__codelineno-38-36"></a>    verbose=True,
<a id="__codelineno-38-37" name="__codelineno-38-37" href="#__codelineno-38-37"></a>)
<a id="__codelineno-38-38" name="__codelineno-38-38" href="#__codelineno-38-38"></a>
<a id="__codelineno-38-39" name="__codelineno-38-39" href="#__codelineno-38-39"></a>print(torch.ops.my_ops.warp_perspective)
</code></pre></div>
<p>当然，如果您的源代码相当短，最好只使用
 <code>torch.utils.cpp_extension.load_inline</code>
。</p>
<p>请注意，如果您’ 在 Jupyter Notebook 中使用此功能，则不应多次执行
具有注册的单元，因为每次执行都会
注册新库并重新注册自定义运算符。如果需要重新执行，
请先重启笔记本的Python内核。</p>
<h3 id="_6">使用安装工具构建 <a href="#building-with-setuptools" title="此标题的永久链接">¶</a></h3>
<p>仅从 Python 构建自定义运算符的第二种方法是
使用
 <code>setuptools</code>
 。这样做的优点是
 <code>setuptools</code>
 有一个相当
强大且广泛的接口，用于构建用 C++ 编写的 Python 模块。
但是，</p>
<p><code>setuptools</code> 实际上是用于构建 Python 模块，而不是简单的共享库(没有 Python
期望的模块所需的入口点)，这条路线可能有点奇怪。也就是说，您
需要的只是一个
 <code>setup.py</code>
 文件来代替
 <code>CMakeLists.txt</code>
，它看起来像
这样：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a>from setuptools import setup
<a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a>from torch.utils.cpp_extension import BuildExtension, CppExtension
<a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a>
<a id="__codelineno-39-4" name="__codelineno-39-4" href="#__codelineno-39-4"></a>setup(
<a id="__codelineno-39-5" name="__codelineno-39-5" href="#__codelineno-39-5"></a>    name=&quot;warp_perspective&quot;,
<a id="__codelineno-39-6" name="__codelineno-39-6" href="#__codelineno-39-6"></a>    ext_modules=[
<a id="__codelineno-39-7" name="__codelineno-39-7" href="#__codelineno-39-7"></a>        CppExtension(
<a id="__codelineno-39-8" name="__codelineno-39-8" href="#__codelineno-39-8"></a>            &quot;warp_perspective&quot;,
<a id="__codelineno-39-9" name="__codelineno-39-9" href="#__codelineno-39-9"></a>            [&quot;example_app/warp_perspective/op.cpp&quot;],
<a id="__codelineno-39-10" name="__codelineno-39-10" href="#__codelineno-39-10"></a>            libraries=[&quot;opencv_core&quot;, &quot;opencv_imgproc&quot;],
<a id="__codelineno-39-11" name="__codelineno-39-11" href="#__codelineno-39-11"></a>        )
<a id="__codelineno-39-12" name="__codelineno-39-12" href="#__codelineno-39-12"></a>    ],
<a id="__codelineno-39-13" name="__codelineno-39-13" href="#__codelineno-39-13"></a>    cmdclass={&quot;build_ext&quot;: BuildExtension.with_options(no_python_abi_suffix=True)},
<a id="__codelineno-39-14" name="__codelineno-39-14" href="#__codelineno-39-14"></a>)
</code></pre></div>
<p>请注意，我们在底部的
 <code>BuildExtension</code>
 中启用了
 <code>no_python_abi_suffix</code>
 选项。这指示
 <code>setuptools</code>
 在生成的共享库的名称中省略任何
Python-3 特定的 ABI 后缀。
否则，例如在 Python 3.7 上，该库可能被称为
 <code>warp_perspective。 cpython-37m-x86_64-linux-gnu.so</code>
 其中
 <code>cpython-37m-x86_64-linux-gnu</code>
 是 ABI 标记，但我们实际上只是希望它
称为
 <code>warp_perspective.so</code></p>
<p>如果我们现在在终端中的
文件夹中运行
 `python</p>
<p>setup.py</p>
<p>build</p>
<p>development<code></code>setup.py`
 已定位，我们应该看到类似以下内容：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a>$ python setup.py build develop
<a id="__codelineno-40-2" name="__codelineno-40-2" href="#__codelineno-40-2"></a>running build
<a id="__codelineno-40-3" name="__codelineno-40-3" href="#__codelineno-40-3"></a>running build_ext
<a id="__codelineno-40-4" name="__codelineno-40-4" href="#__codelineno-40-4"></a>building &#39;warp_perspective&#39; extension
<a id="__codelineno-40-5" name="__codelineno-40-5" href="#__codelineno-40-5"></a>creating build
<a id="__codelineno-40-6" name="__codelineno-40-6" href="#__codelineno-40-6"></a>creating build/temp.linux-x86_64-3.7
<a id="__codelineno-40-7" name="__codelineno-40-7" href="#__codelineno-40-7"></a>gcc -pthread -B /root/local/miniconda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/torch/csrc/api/include -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/TH -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/THC -I/root/local/miniconda/include/python3.7m -c op.cpp -o build/temp.linux-x86_64-3.7/op.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=warp_perspective -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11
<a id="__codelineno-40-8" name="__codelineno-40-8" href="#__codelineno-40-8"></a>cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++
<a id="__codelineno-40-9" name="__codelineno-40-9" href="#__codelineno-40-9"></a>creating build/lib.linux-x86_64-3.7
<a id="__codelineno-40-10" name="__codelineno-40-10" href="#__codelineno-40-10"></a>g++ -pthread -shared -B /root/local/miniconda/compiler_compat -L/root/local/miniconda/lib -Wl,-rpath=/root/local/miniconda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/op.o -lopencv_core -lopencv_imgproc -o build/lib.linux-x86_64-3.7/warp_perspective.so
<a id="__codelineno-40-11" name="__codelineno-40-11" href="#__codelineno-40-11"></a>running develop
<a id="__codelineno-40-12" name="__codelineno-40-12" href="#__codelineno-40-12"></a>running egg_info
<a id="__codelineno-40-13" name="__codelineno-40-13" href="#__codelineno-40-13"></a>creating warp_perspective.egg-info
<a id="__codelineno-40-14" name="__codelineno-40-14" href="#__codelineno-40-14"></a>writing warp_perspective.egg-info/PKG-INFO
<a id="__codelineno-40-15" name="__codelineno-40-15" href="#__codelineno-40-15"></a>writing dependency_links to warp_perspective.egg-info/dependency_links.txt
<a id="__codelineno-40-16" name="__codelineno-40-16" href="#__codelineno-40-16"></a>writing top-level names to warp_perspective.egg-info/top_level.txt
<a id="__codelineno-40-17" name="__codelineno-40-17" href="#__codelineno-40-17"></a>writing manifest file &#39;warp_perspective.egg-info/SOURCES.txt&#39;
<a id="__codelineno-40-18" name="__codelineno-40-18" href="#__codelineno-40-18"></a>reading manifest file &#39;warp_perspective.egg-info/SOURCES.txt&#39;
<a id="__codelineno-40-19" name="__codelineno-40-19" href="#__codelineno-40-19"></a>writing manifest file &#39;warp_perspective.egg-info/SOURCES.txt&#39;
<a id="__codelineno-40-20" name="__codelineno-40-20" href="#__codelineno-40-20"></a>running build_ext
<a id="__codelineno-40-21" name="__codelineno-40-21" href="#__codelineno-40-21"></a>copying build/lib.linux-x86_64-3.7/warp_perspective.so -&gt;
<a id="__codelineno-40-22" name="__codelineno-40-22" href="#__codelineno-40-22"></a>Creating /root/local/miniconda/lib/python3.7/site-packages/warp-perspective.egg-link (link to .)
<a id="__codelineno-40-23" name="__codelineno-40-23" href="#__codelineno-40-23"></a>Adding warp-perspective 0.0.0 to easy-install.pth file
<a id="__codelineno-40-24" name="__codelineno-40-24" href="#__codelineno-40-24"></a>
<a id="__codelineno-40-25" name="__codelineno-40-25" href="#__codelineno-40-25"></a>Installed /warp_perspective
<a id="__codelineno-40-26" name="__codelineno-40-26" href="#__codelineno-40-26"></a>Processing dependencies for warp-perspective==0.0.0
<a id="__codelineno-40-27" name="__codelineno-40-27" href="#__codelineno-40-27"></a>Finished processing dependencies for warp-perspective==0.0.0
</code></pre></div>
<p>这将生成一个名为
 <code>warp_perspective.so</code>
 的共享库，我们可以
将其传递给
 <code>torch.ops.load_library</code>
 就像我们之前所做的那样我们的运算符
对 TorchScript 可见：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a>&gt;&gt;&gt; import torch
<a id="__codelineno-41-2" name="__codelineno-41-2" href="#__codelineno-41-2"></a>&gt;&gt;&gt; torch.ops.load_library(&quot;warp_perspective.so&quot;)
<a id="__codelineno-41-3" name="__codelineno-41-3" href="#__codelineno-41-3"></a>&gt;&gt;&gt; print(torch.ops.my_ops.warp_perspective)
<a id="__codelineno-41-4" name="__codelineno-41-4" href="#__codelineno-41-4"></a>&lt;built-in method custom::warp_perspective of PyCapsule object at 0x7ff51c5b7bd0&gt;
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../cpp_extension/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Custom C++ and CUDA Extensions">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Custom C++ and CUDA Extensions
              </div>
            </div>
          </a>
        
        
          
          <a href="../torch_script_custom_classes/" class="md-footer__link md-footer__link--next" aria-label="Next: Extending TorchScript with Custom C++ Classes">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Extending TorchScript with Custom C++ Classes
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>