
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/2.0/tutorials/beginner/introyt/tensors_deeper_tutorial/">
      
      
        <link rel="prev" href="../introyt1_tutorial/">
      
      
        <link rel="next" href="../autogradyt_tutorial/">
      
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>Introduction to PyTorch Tensors - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.d7758b05.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.75 1.75 0 0 1 1 7.775m1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2"/></svg>');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.5 1.75v11.5c0 .138.112.25.25.25h3.17a.75.75 0 0 1 0 1.5H2.75A1.75 1.75 0 0 1 1 13.25V1.75C1 .784 1.784 0 2.75 0h8.5C12.216 0 13 .784 13 1.75v7.736a.75.75 0 0 1-1.5 0V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25m13.274 9.537zl-4.557 4.45a.75.75 0 0 1-1.055-.008l-1.943-1.95a.75.75 0 0 1 1.062-1.058l1.419 1.425 4.026-3.932a.75.75 0 1 1 1.048 1.074M4.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5M4 7.75A.75.75 0 0 1 4.75 7h2a.75.75 0 0 1 0 1.5h-2A.75.75 0 0 1 4 7.75"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75M8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2"/></svg>');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M3.499.75a.75.75 0 0 1 1.5 0v.996C5.9 2.903 6.793 3.65 7.662 4.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873 10.794-.045 12.622.26 14.408.558 16 1.94 16 4.25c0 1.278-.954 2.575-2.44 2.734l.146.508.065.22c.203.701.412 1.455.476 2.226.142 1.707-.4 3.03-1.487 3.898C11.714 14.671 10.27 15 8.75 15h-6a.75.75 0 0 1 0-1.5h1.376a4.5 4.5 0 0 1-.563-1.191 3.84 3.84 0 0 1-.05-2.063 4.65 4.65 0 0 1-2.025-.293.75.75 0 0 1 .525-1.406c1.357.507 2.376-.006 2.698-.318l.009-.01a.747.747 0 0 1 1.06 0 .75.75 0 0 1-.012 1.074c-.912.92-.992 1.835-.768 2.586.221.74.745 1.337 1.196 1.621H8.75c1.343 0 2.398-.296 3.074-.836.635-.507 1.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4 2.4 0 0 1-.507-.441 3.1 3.1 0 0 1-.633-1.248.75.75 0 0 1 1.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738 0 1.25-.615 1.25-1.25 0-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706 1.345-.46.92-.27 1.774.019 3.062l.042.19.01.05c.348.443.666.949.94 1.553a.75.75 0 1 1-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7 5.527c-.814-.68-1.75-1.462-2.692-2.619a3.7 3.7 0 0 0-1.023.88c-.406.495-.663 1.036-.722 1.508.116.122.306.21.591.239.388.038.797-.06 1.032-.19a.75.75 0 0 1 .728 1.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75 5.677V5.5c0-.984.48-1.94 1.077-2.664.46-.559 1.05-1.055 1.673-1.353z"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0"/></svg>');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.92 6.085h.001a.749.749 0 1 1-1.342-.67c.169-.339.436-.701.849-.977C6.845 4.16 7.369 4 8 4a2.76 2.76 0 0 1 1.637.525c.503.377.863.965.863 1.725 0 .448-.115.83-.329 1.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6 6 0 0 0-.26.16 1 1 0 0 0-.276.245.75.75 0 0 1-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1 1 0 0 0 .277-.245C8.96 6.514 9 6.427 9 6.25a.61.61 0 0 0-.262-.525A1.27 1.27 0 0 0 8 5.5c-.369 0-.595.09-.74.187a1 1 0 0 0-.34.398M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.344 2.343za8 8 0 0 1 11.314 11.314A8.002 8.002 0 0 1 .234 10.089a8 8 0 0 1 2.11-7.746m1.06 10.253a6.5 6.5 0 1 0 9.108-9.275 6.5 6.5 0 0 0-9.108 9.275M6.03 4.97 8 6.94l1.97-1.97a.749.749 0 0 1 1.275.326.75.75 0 0 1-.215.734L9.06 8l1.97 1.97a.749.749 0 0 1-.326 1.275.75.75 0 0 1-.734-.215L8 9.06l-1.97 1.97a.749.749 0 0 1-1.275-.326.75.75 0 0 1 .215-.734L6.94 8 4.97 6.03a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018"/></svg>');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M9.504.43a1.516 1.516 0 0 1 2.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 0 1-.871.354h-.302a1.25 1.25 0 0 1-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004zm1.047 1.074L3.286 8.571A.25.25 0 0 0 3.462 9H6.75a.75.75 0 0 1 .694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0 0 12.538 7H9.25a.75.75 0 0 1-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005 0-.009.004"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M5 5.782V2.5h-.25a.75.75 0 0 1 0-1.5h6.5a.75.75 0 0 1 0 1.5H11v3.282l3.666 5.76C15.619 13.04 14.543 15 12.767 15H3.233c-1.776 0-2.852-1.96-1.899-3.458Zm-2.4 6.565a.75.75 0 0 0 .633 1.153h9.534a.75.75 0 0 0 .633-1.153L12.225 10.5h-8.45ZM9.5 2.5h-3V6c0 .143-.04.283-.117.403L4.73 9h6.54L9.617 6.403A.75.75 0 0 1 9.5 6Z"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 2.5h10.5a.75.75 0 0 1 0 1.5H1.75a.75.75 0 0 1 0-1.5m4 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5m0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5M2.5 7.75v6a.75.75 0 0 1-1.5 0v-6a.75.75 0 0 1 1.5 0"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pytorch-tensor" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.dafeiyang.cn/images/logo/logo_green.webp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Introduction to PyTorch Tensors
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.dafeiyang.cn/images/logo/logo_green.webp" alt="logo">

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 新特性
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 新特性
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.13
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.12
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.11
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.10
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.8
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.7
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 2.x 中文文档 & 教程
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 2.x 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch Recipes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch Recipes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../recipes/recipes_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Recipes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../prototype/prototype_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Prototype Recipes
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learn the Basics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/quickstart_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/tensorqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/data_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets & DataLoaders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/transforms_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transforms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/buildmodel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build the Neural Network
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/autogradqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Differentiation with torch.autograd
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/optimization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Model Parameters
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/saveloadrun_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Save and Load the Model
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch on YouTube
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch on YouTube
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch - YouTube Series
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introyt1_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Introduction to PyTorch Tensors
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch Tensors
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensor" class="md-nav__link">
    <span class="md-ellipsis">
      创建tensor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="创建tensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor_1" class="md-nav__link">
    <span class="md-ellipsis">
      随机tensor和种子设置
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_2" class="md-nav__link">
    <span class="md-ellipsis">
      tensor形状
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_3" class="md-nav__link">
    <span class="md-ellipsis">
      tensor数据类型
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pytorch-tensor_1" class="md-nav__link">
    <span class="md-ellipsis">
      用 PyTorch tensor进行数学和逻辑运算
    </span>
  </a>
  
    <nav class="md-nav" aria-label="用 PyTorch tensor进行数学和逻辑运算">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor_4" class="md-nav__link">
    <span class="md-ellipsis">
      简述：tensor广播
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_5" class="md-nav__link">
    <span class="md-ellipsis">
      更多tensor数学运算
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_6" class="md-nav__link">
    <span class="md-ellipsis">
      原地修改tensor
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor_7" class="md-nav__link">
    <span class="md-ellipsis">
      复制tensor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu" class="md-nav__link">
    <span class="md-ellipsis">
      转用 GPU
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor_8" class="md-nav__link">
    <span class="md-ellipsis">
      操作tensor形状
    </span>
  </a>
  
    <nav class="md-nav" aria-label="操作tensor形状">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      更改维数
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#numpy" class="md-nav__link">
    <span class="md-ellipsis">
      NumPy 桥接
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autogradyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Fundamentals of Autograd
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modelsyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Models with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorboardyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch TensorBoard Support
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trainingyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../captumyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Understanding with Captum
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_4" >
        
          
          <label class="md-nav__link" for="__nav_3_1_4" id="__nav_3_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Learning PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_4">
            <span class="md-nav__icon md-icon"></span>
            Learning PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning with PyTorch: A 60 Minute Blitz
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning PyTorch with Examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/tensorboard_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualizing Models, Data, and Training with TensorBoard
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_5" >
        
          
          <label class="md-nav__link" for="__nav_3_1_5" id="__nav_3_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Image and Video
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_5">
            <span class="md-nav__icon md-icon"></span>
            Image and Video
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torchvision_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision Object Detection Finetuning Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transfer Learning for Computer Vision Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adversarial Example Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial Transformer Networks Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/tiatoolbox_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Whole Slide Image Classification Using PyTorch and TIAToolbox
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_6" >
        
          
          <label class="md-nav__link" for="__nav_3_1_6" id="__nav_3_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Audio
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_6">
            <span class="md-nav__icon md-icon"></span>
            Audio
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_io_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio I/O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_resampling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Resampling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_data_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Data Augmentation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_feature_extractions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Extractions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_feature_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Augmentation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_datasets_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Datasets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/speech_recognition_pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speech Recognition with Wav2Vec2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/text_to_speech_with_torchaudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-speech with Tacotron2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/forced_alignment_with_torchaudio_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forced Alignment with Wav2Vec2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_7" >
        
          
          <label class="md-nav__link" for="__nav_3_1_7" id="__nav_3_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_7">
            <span class="md-nav__icon md-icon"></span>
            Text
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bettertransformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fast Transformer Inference with Better Transformer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Classifying Names with a Character-Level RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Generating Names with a Character-Level RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Translation with a Sequence to Sequence Network and Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../text_sentiment_ngrams_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text classification with the torchtext library
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../translation_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Translation with nn.Transformer and torchtext
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../torchtext_custom_dataset_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocess custom text dataset using Torchtext
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_8" >
        
          
          <label class="md-nav__link" for="__nav_3_1_8" id="__nav_3_1_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Backends
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_8">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_9" >
        
          
          <label class="md-nav__link" for="__nav_3_1_9" id="__nav_3_1_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_9">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/reinforcement_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (PPO) with TorchRL Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/mario_rl_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a Mario-playing RL Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/pendulum/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pendulum: Writing your environment and transforms with TorchRL
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_10" >
        
          
          <label class="md-nav__link" for="__nav_3_1_10" id="__nav_3_1_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deploying PyTorch Models in Production
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_10">
            <span class="md-nav__icon md-icon"></span>
            Deploying PyTorch Models in Production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/flask_rest_api_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying PyTorch in Python via a REST API with Flask
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Intro_to_TorchScript_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchScript
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loading a TorchScript Model in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/super_resolution_with_onnxruntime/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/realtime_rpi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Real Time Inference on Raspberry Pi 4 (30 fps!)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_11" >
        
          
          <label class="md-nav__link" for="__nav_3_1_11" id="__nav_3_1_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Profiling PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_11">
            <span class="md-nav__icon md-icon"></span>
            Profiling PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hta_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Holistic Trace Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hta_trace_diff_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Trace Diff using Holistic Trace Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_12" >
        
          
          <label class="md-nav__link" for="__nav_3_1_12" id="__nav_3_1_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code Transforms with FX
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_12">
            <span class="md-nav__icon md-icon"></span>
            Code Transforms with FX
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/fx_conv_bn_fuser/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Convolution/Batch Norm fuser in FX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/fx_profiling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Simple CPU Performance Profiler with FX
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_13" >
        
          
          <label class="md-nav__link" for="__nav_3_1_13" id="__nav_3_1_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Frontend APIs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_13">
            <span class="md-nav__icon md-icon"></span>
            Frontend APIs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/memory_format_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Channels Last Memory Format in PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/forward_ad_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forward-mode Automatic Differentiation (Beta)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/jacobians_hessians/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Jacobians, Hessians, hvp, vhp, and more: composing function transforms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/ensembling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model ensembling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/per_sample_grads/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Per-sample-gradients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the PyTorch C++ Frontend
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/torch-script-parallelism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Parallelism in TorchScript
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/cpp_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd in C++ Frontend
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_14" >
        
          
          <label class="md-nav__link" for="__nav_3_1_14" id="__nav_3_1_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Extending PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_14">
            <span class="md-nav__icon md-icon"></span>
            Extending PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/custom_function_double_backward_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Double Backward with Custom Functions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/custom_function_conv_bn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fusing Convolution and Batch Norm using Custom Function
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/torch_script_custom_classes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Classes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Registering a Dispatched Operator in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/extend_dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending dispatcher for a new backend in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/privateuseone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Facilitating New Backend Integration by PrivateUse1
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_15" >
        
          
          <label class="md-nav__link" for="__nav_3_1_15" id="__nav_3_1_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Optimization
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_15">
            <span class="md-nav__icon md-icon"></span>
            Model Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/tensorboard_profiler_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Profiler With TensorBoard
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hyperparameter_tuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter tuning with Ray Tune
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/parametrizations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametrizations Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/pruning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pruning Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/dynamic_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on an LSTM Word Language Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/dynamic_quantization_bert_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on BERT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/quantized_transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Quantized Transfer Learning for Computer Vision Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/static_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Static Quantization with Eager Mode in PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torchserve_with_ipex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torchserve_with_ipex_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles (Part 2)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/nvfuser_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started - Accelerate Your Scripts with nvFuser
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/ax_multiobjective_nas_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Objective NAS with Ax
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torch_compile_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to torch.compile
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/inductor_debug_cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inductor CPU backend debugging and profiling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../knowledge_distillation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge Distillation Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_16" >
        
          
          <label class="md-nav__link" for="__nav_3_1_16" id="__nav_3_1_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Parallel and Distributed Training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_16">
            <span class="md-nav__icon md-icon"></span>
            Parallel and Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../distributed/home/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed and Parallel Training Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dist_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Distributed Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ddp_series_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Data Parallel in PyTorch - Video Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/model_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single-Machine Model Parallel Best Practices
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed Data Parallel
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/FSDP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Fully Sharded Data Parallel(FSDP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/FSDP_adavnced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced Model Training with Fully Sharded Data Parallel (FSDP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/TP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Large Scale Transformer model training with Tensor Parallel (TP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/process_group_cpp_extension_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Process Group Backends Using Cpp Extensions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/rpc_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/rpc_param_server_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing a Parameter Server Using Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/dist_pipeline_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Pipeline Parallelism Using RPC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/rpc_async_execution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing Batch RPC Processing Using Asynchronous Executions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/rpc_ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Combining Distributed DataParallel with Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/ddp_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Distributed Data Parallel and Pipeline Parallelism
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/generic_join/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Training with Uneven Inputs Using the Join Context Manager
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_17" >
        
          
          <label class="md-nav__link" for="__nav_3_1_17" id="__nav_3_1_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Edge with ExecuTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_17">
            <span class="md-nav__icon md-icon"></span>
            Edge with ExecuTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exporting to ExecuTorch Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/running-a-model-cpp-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Running an ExecuTorch Model in C++ Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/tutorials/sdk-integration-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the ExecuTorch SDK to Profile a Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/demo-apps-ios.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building an ExecuTorch iOS Demo App
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/demo-apps-android.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building an ExecuTorch Android Demo App
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/examples-end-to-end-to-lower-model-to-delegate.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lowering a Model as a Delegate
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_18" >
        
          
          <label class="md-nav__link" for="__nav_3_1_18" id="__nav_3_1_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Recommendation Systems
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_18">
            <span class="md-nav__icon md-icon"></span>
            Recommendation Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torchrec_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchRec
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/sharding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exploring TorchRec sharding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_19" >
        
          
          <label class="md-nav__link" for="__nav_3_1_19" id="__nav_3_1_19_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Multimodality
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_19">
            <span class="md-nav__icon md-icon"></span>
            Multimodality
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../flava_finetuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchMultimodal Tutorial: Finetuning FLAVA
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/docs/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pytorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/audio/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torchaudio
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/text/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchText
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/vision/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torcharrow/beta/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchArrow
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torchrec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchRec
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/serve/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchServe
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torchx/latest/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/xla/release/2.3/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch on XLA Devices
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.7 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.4 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.0 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.4 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.3 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.2 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../contrib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贡献指南
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于我们
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/join" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加入我们
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中文资源合集
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensor" class="md-nav__link">
    <span class="md-ellipsis">
      创建tensor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="创建tensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor_1" class="md-nav__link">
    <span class="md-ellipsis">
      随机tensor和种子设置
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_2" class="md-nav__link">
    <span class="md-ellipsis">
      tensor形状
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_3" class="md-nav__link">
    <span class="md-ellipsis">
      tensor数据类型
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pytorch-tensor_1" class="md-nav__link">
    <span class="md-ellipsis">
      用 PyTorch tensor进行数学和逻辑运算
    </span>
  </a>
  
    <nav class="md-nav" aria-label="用 PyTorch tensor进行数学和逻辑运算">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor_4" class="md-nav__link">
    <span class="md-ellipsis">
      简述：tensor广播
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_5" class="md-nav__link">
    <span class="md-ellipsis">
      更多tensor数学运算
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_6" class="md-nav__link">
    <span class="md-ellipsis">
      原地修改tensor
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor_7" class="md-nav__link">
    <span class="md-ellipsis">
      复制tensor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu" class="md-nav__link">
    <span class="md-ellipsis">
      转用 GPU
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor_8" class="md-nav__link">
    <span class="md-ellipsis">
      操作tensor形状
    </span>
  </a>
  
    <nav class="md-nav" aria-label="操作tensor形状">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      更改维数
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#numpy" class="md-nav__link">
    <span class="md-ellipsis">
      NumPy 桥接
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/2.0/tutorials/beginner/introyt/tensors_deeper_tutorial.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/2.0/tutorials/beginner/introyt/tensors_deeper_tutorial.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="pytorch-tensor">PyTorch tensor入门</h1>
<blockquote>
<p>译者：<a href="https://github.com/Fadegentle">Fadegentle</a></p>
<p>项目地址：<a href="https://pytorch.apachecn.org/2.0/tutorials/beginner/introyt/tensors_deeper_tutorial">https://pytorch.apachecn.org/2.0/tutorials/beginner/introyt/tensors_deeper_tutorial</a></p>
<p>原始地址：<a href="https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html">https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html</a></p>
</blockquote>
<p>请跟随下面的视频或在 <a href="https://www.youtube.com/watch?v=r7QDUPb2dCM">youtube</a> 上观看。</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/r7QDUPb2dCM" title="Introduction to PyTorch Tensors" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

<p>tensor是 PyTorch 的核心数据抽象。本互动笔记本将深入介绍 <code>torch.Tensor</code> 类。</p>
<p>首先，让我们导入 PyTorch 模块。另外因为某些示例需要，我们还要添加 Python 的数学模块。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
</code></pre></div>
<h2 id="tensor">创建tensor</h2>
<p>创建tensor最简单的方法是调用 <code>torch.empty()</code>：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>&lt;class<span class="w"> </span><span class="s1">&#39;torch.Tensor&#39;</span>&gt;
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>tensor<span class="o">([[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>,
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>,
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]])</span>
</code></pre></div></p>
<p>让我们来解读一下刚才的操作：</p>
<ul>
<li>我们使用 <code>torch</code> 模块附带的众多工厂方法之一创建了一个tensor。</li>
<li>该tensor本身是二维的，有 3 行 4 列。</li>
<li>返回对象的类型是 <code>torch.Tensor</code>，它是 <code>torch.FloatTensor</code> 的别名；默认情况下，PyTorch tensor使用 32 位浮点数填充。(下面将详细介绍数据类型。)</li>
<li>在打印tensor时，您可能会看到一些随机的数值。<code>torrent.empty()</code> 调用为tensor分配了内存，但没用任何值对其初始化——所以您看到的是分配时内存中的内容。</li>
</ul>
<p>关于tensor及其维数和术语的简要说明：</p>
<ul>
<li>有时，您会看到一个一维tensor被称为向量。</li>
<li>同样，二维tensor通常被称为矩阵。</li>
<li>超过两个维度的情况一般都被称为tensor。</li>
</ul>
<p>在大多数情况下，您会想要用一些值来初始化您的tensor。常见的情况有全 0、全 1 或随机值，<code>torch</code> 模块为这些情况都提供了工厂方法：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">zeros</span><span class="p">)</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">ones</span><span class="p">)</span>
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="n">random</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="nb">print</span><span class="p">(</span><span class="n">random</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>tensor<span class="o">([[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>,
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]])</span>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>tensor<span class="o">([[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]</span>,
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]])</span>
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>tensor<span class="o">([[</span><span class="m">0</span>.3126,<span class="w"> </span><span class="m">0</span>.3791,<span class="w"> </span><span class="m">0</span>.3087<span class="o">]</span>,
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.0736,<span class="w"> </span><span class="m">0</span>.4216,<span class="w"> </span><span class="m">0</span>.0691<span class="o">]])</span>
</code></pre></div></p>
<p>这些工厂方法都如您所愿——我们得到了一个全是 0 的tensor，另一个全是 1 的tensor，还有一个包含 0 和 1 之间随机值的tensor。</p>
<h3 id="tensor_1">随机tensor和种子设置</h3>
<p>说到随机tensor，您是否注意到紧接在它之前调用了 <code>torch.manual_seed()</code> ？将tensor初始化为随机值是常见的做法，比如模型的学习权重，但在某些情况下(尤其是在研究环境中)您可能希望确保您的结果是可重现的。手动设置随机数生成器的种子就能做到这个，让我们仔细看一下：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="n">random1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="nb">print</span><span class="p">(</span><span class="n">random1</span><span class="p">)</span>
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="n">random2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">random2</span><span class="p">)</span>
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="n">random3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">random3</span><span class="p">)</span>
<a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>
<a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="n">random4</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a><span class="nb">print</span><span class="p">(</span><span class="n">random4</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>tensor<span class="o">([[</span><span class="m">0</span>.3126,<span class="w"> </span><span class="m">0</span>.3791,<span class="w"> </span><span class="m">0</span>.3087<span class="o">]</span>,
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.0736,<span class="w"> </span><span class="m">0</span>.4216,<span class="w"> </span><span class="m">0</span>.0691<span class="o">]])</span>
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>tensor<span class="o">([[</span><span class="m">0</span>.2332,<span class="w"> </span><span class="m">0</span>.4047,<span class="w"> </span><span class="m">0</span>.2162<span class="o">]</span>,
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.9927,<span class="w"> </span><span class="m">0</span>.4128,<span class="w"> </span><span class="m">0</span>.5938<span class="o">]])</span>
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>tensor<span class="o">([[</span><span class="m">0</span>.3126,<span class="w"> </span><span class="m">0</span>.3791,<span class="w"> </span><span class="m">0</span>.3087<span class="o">]</span>,
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.0736,<span class="w"> </span><span class="m">0</span>.4216,<span class="w"> </span><span class="m">0</span>.0691<span class="o">]])</span>
<a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>tensor<span class="o">([[</span><span class="m">0</span>.2332,<span class="w"> </span><span class="m">0</span>.4047,<span class="w"> </span><span class="m">0</span>.2162<span class="o">]</span>,
<a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.9927,<span class="w"> </span><span class="m">0</span>.4128,<span class="w"> </span><span class="m">0</span>.5938<span class="o">]])</span>
</code></pre></div></p>
<p>您应该在上面看到，<code>random1</code> 和 <code>random3</code> 携带着相同的值，<code>random2</code> 和 <code>random4</code> 也是如此。手动设置随机数生成器的种子会重置它，因此一般而言，相同随机数的相同计算应有相同的结果。</p>
<p>有关更多信息，请参阅 <a href="https://pytorch.org/docs/stable/notes/randomness.html">PyTorch 文档关于可重现性的部分</a>。</p>
<h3 id="tensor_2">tensor形状</h3>
<p>通常，当您对两个或多个tensor执行操作时，它们需要具有相同的形状——也就是说，维数相同和每个维度中的单元数相同。为此，我们有 <code>torch.*_like()</code> 方法：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="n">empty_like_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">empty_like_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="nb">print</span><span class="p">(</span><span class="n">empty_like_x</span><span class="p">)</span>
<a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>
<a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="n">zeros_like_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">zeros_like_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="nb">print</span><span class="p">(</span><span class="n">zeros_like_x</span><span class="p">)</span>
<a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a>
<a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a><span class="n">ones_like_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a><span class="nb">print</span><span class="p">(</span><span class="n">ones_like_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a><span class="nb">print</span><span class="p">(</span><span class="n">ones_like_x</span><span class="p">)</span>
<a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>
<a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a><span class="n">rand_like_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a><span class="nb">print</span><span class="p">(</span><span class="n">rand_like_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a><span class="nb">print</span><span class="p">(</span><span class="n">rand_like_x</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span>,<span class="w"> </span><span class="m">3</span><span class="o">])</span>
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>tensor<span class="o">([[[</span><span class="w"> </span><span class="m">1</span>.3323e-33,<span class="w">  </span><span class="m">0</span>.0000e+00,<span class="w">  </span><span class="m">1</span>.2565e-33<span class="o">]</span>,
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="w">         </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.0000e+00,<span class="w"> </span>-6.9300e-03,<span class="w"> </span>-2.9693e-02<span class="o">]]</span>,
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="w">        </span><span class="o">[[</span>-4.2094e-02,<span class="w">  </span><span class="m">2</span>.6203e-02,<span class="w">  </span><span class="m">6</span>.7262e-44<span class="o">]</span>,
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="w">         </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.0000e+00,<span class="w">  </span><span class="m">6</span>.7262e-44,<span class="w">  </span><span class="m">0</span>.0000e+00<span class="o">]]])</span>
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span>,<span class="w"> </span><span class="m">3</span><span class="o">])</span>
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>tensor<span class="o">([[[</span><span class="w"> </span><span class="m">6</span>.0476e-35,<span class="w">  </span><span class="m">0</span>.0000e+00,<span class="w"> </span>-9.5918e-01<span class="o">]</span>,
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a><span class="w">         </span><span class="o">[</span><span class="w"> </span><span class="m">4</span>.5559e-41,<span class="w">  </span><span class="m">4</span>.4842e-44,<span class="w">  </span><span class="m">0</span>.0000e+00<span class="o">]]</span>,
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a><span class="w">        </span><span class="o">[[</span><span class="w"> </span><span class="m">8</span>.9683e-44,<span class="w">  </span><span class="m">0</span>.0000e+00,<span class="w">  </span><span class="m">1</span>.3039e-33<span class="o">]</span>,
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a><span class="w">         </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.0000e+00,<span class="w">  </span><span class="m">1</span>.1351e-43,<span class="w">  </span><span class="m">0</span>.0000e+00<span class="o">]]])</span>
<a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span>,<span class="w"> </span><span class="m">3</span><span class="o">])</span>
<a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>tensor<span class="o">([[[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>,
<a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]]</span>,
<a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>
<a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>,
<a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]]])</span>
<a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span>,<span class="w"> </span><span class="m">3</span><span class="o">])</span>
<a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a>tensor<span class="o">([[[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]</span>,
<a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a><span class="w">         </span><span class="o">[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]]</span>,
<a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>
<a id="__codelineno-8-23" name="__codelineno-8-23" href="#__codelineno-8-23"></a><span class="w">        </span><span class="o">[[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]</span>,
<a id="__codelineno-8-24" name="__codelineno-8-24" href="#__codelineno-8-24"></a><span class="w">         </span><span class="o">[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]]])</span>
<a id="__codelineno-8-25" name="__codelineno-8-25" href="#__codelineno-8-25"></a>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span>,<span class="w"> </span><span class="m">3</span><span class="o">])</span>
<a id="__codelineno-8-26" name="__codelineno-8-26" href="#__codelineno-8-26"></a>tensor<span class="o">([[[</span><span class="m">0</span>.6128,<span class="w"> </span><span class="m">0</span>.1519,<span class="w"> </span><span class="m">0</span>.0453<span class="o">]</span>,
<a id="__codelineno-8-27" name="__codelineno-8-27" href="#__codelineno-8-27"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.5035,<span class="w"> </span><span class="m">0</span>.9978,<span class="w"> </span><span class="m">0</span>.3884<span class="o">]]</span>,
<a id="__codelineno-8-28" name="__codelineno-8-28" href="#__codelineno-8-28"></a>
<a id="__codelineno-8-29" name="__codelineno-8-29" href="#__codelineno-8-29"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.6929,<span class="w"> </span><span class="m">0</span>.1703,<span class="w"> </span><span class="m">0</span>.1384<span class="o">]</span>,
<a id="__codelineno-8-30" name="__codelineno-8-30" href="#__codelineno-8-30"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.4759,<span class="w"> </span><span class="m">0</span>.7481,<span class="w"> </span><span class="m">0</span>.0361<span class="o">]]])</span>
</code></pre></div></p>
<p>上面代码单元中的第一个新功能是在tensor上使用 <code>.shape</code> 属性。该属性包含一个列表，其中包含tensor各维度的范围——在我们的例子中，<code>x</code> 是一个形状为 2 x 2 x 3 的三维tensor。</p>
<p>下面，我们将调用 <code>.empty_like()</code>、<code>.zeros_like()</code>、<code>.one_like()</code> 和 <code>.rand_like()</code> 方法。通过使用 <code>.shape</code> 属性，我们可以验证这些方法返回的tensor的维数和范围都是相同的。</p>
<p>创建tensor的最后一种方法是直接从 PyTorch 集合中指定数据：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="n">some_constants</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.1415926</span><span class="p">,</span> <span class="mf">2.71828</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.61803</span><span class="p">,</span> <span class="mf">0.0072897</span><span class="p">]])</span>
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">some_constants</span><span class="p">)</span>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="n">some_integers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">19</span><span class="p">))</span>
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">some_integers</span><span class="p">)</span>
<a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>
<a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a><span class="n">more_integers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">]))</span>
<a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">more_integers</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>tensor<span class="o">([[</span><span class="m">3</span>.1416,<span class="w"> </span><span class="m">2</span>.7183<span class="o">]</span>,
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.6180,<span class="w"> </span><span class="m">0</span>.0073<span class="o">]])</span>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">2</span>,<span class="w">  </span><span class="m">3</span>,<span class="w">  </span><span class="m">5</span>,<span class="w">  </span><span class="m">7</span>,<span class="w"> </span><span class="m">11</span>,<span class="w"> </span><span class="m">13</span>,<span class="w"> </span><span class="m">17</span>,<span class="w"> </span><span class="m">19</span><span class="o">])</span>
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>tensor<span class="o">([[</span><span class="m">2</span>,<span class="w"> </span><span class="m">4</span>,<span class="w"> </span><span class="m">6</span><span class="o">]</span>,
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="w">        </span><span class="o">[</span><span class="m">3</span>,<span class="w"> </span><span class="m">6</span>,<span class="w"> </span><span class="m">9</span><span class="o">]])</span>
</code></pre></div></p>
<p>如果数据已经存在于 Python 元组或列表中，使用 <code>torch.tensor()</code> 是创建tensor最简单的方法。如上所示，嵌套集合将产生多维tensor。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p><code>torch.tensor()</code> 会创建一个数据副本。</p>
</div>
<h3 id="tensor_3">tensor数据类型</h3>
<p>设置tensor的数据类型有几种方法：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="o">*</span> <span class="mf">20.</span>
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a><span class="n">c</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>tensor<span class="o">([[</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span><span class="o">]</span>,
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span><span class="o">]]</span>,<span class="w"> </span><span class="nv">dtype</span><span class="o">=</span>torch.int16<span class="o">)</span>
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>tensor<span class="o">([[</span><span class="w"> </span><span class="m">0</span>.9956,<span class="w">  </span><span class="m">1</span>.4148,<span class="w">  </span><span class="m">5</span>.8364<span class="o">]</span>,
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="w">        </span><span class="o">[</span><span class="m">11</span>.2406,<span class="w"> </span><span class="m">11</span>.2083,<span class="w"> </span><span class="m">11</span>.6692<span class="o">]]</span>,<span class="w"> </span><span class="nv">dtype</span><span class="o">=</span>torch.float64<span class="o">)</span>
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>tensor<span class="o">([[</span><span class="w"> </span><span class="m">0</span>,<span class="w">  </span><span class="m">1</span>,<span class="w">  </span><span class="m">5</span><span class="o">]</span>,
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="w">        </span><span class="o">[</span><span class="m">11</span>,<span class="w"> </span><span class="m">11</span>,<span class="w"> </span><span class="m">11</span><span class="o">]]</span>,<span class="w"> </span><span class="nv">dtype</span><span class="o">=</span>torch.int32<span class="o">)</span>
</code></pre></div></p>
<p>设置tensor底层数据类型的最简单方法是在创建时使用可选的参数。在上述单元格的第一行，我们为tensor <code>a</code> 设置了 <code>dtype=torch.int16</code>。当我们打印 <code>a</code> 时，可以看到它被填满了 <code>1</code>，而不是 <code>1.0</code>——这是 Python 的小提示，表示这是整数类型而非浮点数。</p>
<p>在打印 <code>a</code> 时还需要注意的一点是，与将 <code>dtype</code> 保持默认值(32 位浮点数)不同，打印tensor还会指定其 <code>dtype</code>。</p>
<p>您可能也发现了，我们从指定tensor的形状为一系列整数参数，变成了将这些参数分组为一个元组。严格来说，这并不是必须的( PyTorch 会将一系列初始的、无标签的整数参数作为tensor形状)，但在添加可选参数时，这可以使您的意图便于理解。</p>
<p>另一种设置数据类型的方法是使用 <code>.to()</code> 方法。在上面的单元格中，我们按照通常的方式创建了一个随机浮点tensor <code>b</code>。在随后，我们使用 <code>.to()</code> 方法将 <code>b</code> 转换为 32 位整数来创建 <code>c</code>。请注意，<code>c</code> 包含的所有值与 <code>b</code> 相同，但被截断为整数。</p>
<p>可用数据类型包括：</p>
<ul>
<li><code>torch.bool</code></li>
<li><code>torch.int8</code></li>
<li><code>torch.uint8</code></li>
<li><code>torch.int16</code></li>
<li><code>torch.int32</code></li>
<li><code>torch.int64</code></li>
<li><code>torch.half</code></li>
<li><code>torch.float</code></li>
<li><code>torch.double</code></li>
<li><code>torch.bfloat</code></li>
</ul>
<h2 id="pytorch-tensor_1">用 PyTorch tensor进行数学和逻辑运算</h2>
<p>现在您已经了解了一些创建tensor的方法，那么您可以用它们做什么呢？</p>
<p>首先，让我们先看一下基本的算术运算，以及tensor如何与简单的标量进行交互：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="n">twos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="n">threes</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="n">fours</span> <span class="o">=</span> <span class="n">twos</span> <span class="o">**</span> <span class="mi">2</span>
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a><span class="n">sqrt2s</span> <span class="o">=</span> <span class="n">twos</span> <span class="o">**</span> <span class="mf">0.5</span>
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a><span class="nb">print</span><span class="p">(</span><span class="n">ones</span><span class="p">)</span>
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">twos</span><span class="p">)</span>
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a><span class="nb">print</span><span class="p">(</span><span class="n">threes</span><span class="p">)</span>
<a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">fours</span><span class="p">)</span>
<a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a><span class="nb">print</span><span class="p">(</span><span class="n">sqrt2s</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>tensor<span class="o">([[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]</span>,
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]])</span>
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>tensor<span class="o">([[</span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.<span class="o">]</span>,
<a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="w">        </span><span class="o">[</span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.<span class="o">]])</span>
<a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>tensor<span class="o">([[</span><span class="m">3</span>.,<span class="w"> </span><span class="m">3</span>.<span class="o">]</span>,
<a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a><span class="w">        </span><span class="o">[</span><span class="m">3</span>.,<span class="w"> </span><span class="m">3</span>.<span class="o">]])</span>
<a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>tensor<span class="o">([[</span><span class="m">4</span>.,<span class="w"> </span><span class="m">4</span>.<span class="o">]</span>,
<a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a><span class="w">        </span><span class="o">[</span><span class="m">4</span>.,<span class="w"> </span><span class="m">4</span>.<span class="o">]])</span>
<a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a>tensor<span class="o">([[</span><span class="m">1</span>.4142,<span class="w"> </span><span class="m">1</span>.4142<span class="o">]</span>,
<a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.4142,<span class="w"> </span><span class="m">1</span>.4142<span class="o">]])</span>
</code></pre></div></p>
<p>如您在上面看到的，tensor与标量之间的算术运算，比如加法、减法、乘法、除法和指数运算，会作用于tensor的每个元素。因为此类运算的输出将是一个tensor，您可以按通用运算符优先规则将它们链接在一起，就像我们在创建 <code>threes</code> 的那一行中所示。</p>
<p>类似的操作在两个tensor之间也如您所愿：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="n">powers2</span> <span class="o">=</span> <span class="n">twos</span> <span class="o">**</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">powers2</span><span class="p">)</span>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a><span class="n">fives</span> <span class="o">=</span> <span class="n">ones</span> <span class="o">+</span> <span class="n">fours</span>
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">fives</span><span class="p">)</span>
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>
<a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a><span class="n">dozens</span> <span class="o">=</span> <span class="n">threes</span> <span class="o">*</span> <span class="n">fours</span>
<a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">dozens</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>tensor<span class="o">([[</span><span class="w"> </span><span class="m">2</span>.,<span class="w">  </span><span class="m">4</span>.<span class="o">]</span>,
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a><span class="w">        </span><span class="o">[</span><span class="w"> </span><span class="m">8</span>.,<span class="w"> </span><span class="m">16</span>.<span class="o">]])</span>
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>tensor<span class="o">([[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]</span>,
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a><span class="w">        </span><span class="o">[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]])</span>
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>tensor<span class="o">([[</span><span class="m">12</span>.,<span class="w"> </span><span class="m">12</span>.<span class="o">]</span>,
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a><span class="w">        </span><span class="o">[</span><span class="m">12</span>.,<span class="w"> </span><span class="m">12</span>.<span class="o">]])</span>
</code></pre></div></p>
<p>这里需要注意的是，上面代码单元格中的所有tensor都具有相同的形状。如果我们尝试在形状不同的tensor上执行二元运算，会发生什么呢？</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>以下单元格会抛出运行时错误。是故意为之。</p>
</div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>
<a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span>
</code></pre></div>
<p>通常，您不能以这种方式操作不同形状的tensor，即使像上面的单元格中，tensor具有相同数量元素的情况，也不行。</p>
<h3 id="tensor_4">简述：tensor广播</h3>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>如果您熟悉 NumPy ndarrays 中的广播语义，您会发现相同的规则也适用于这里。</p>
</div>
<p>相同形状规则的例外是tensor广播。以下是一个示例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="n">rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="n">doubled</span> <span class="o">=</span> <span class="n">rand</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>
<a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">rand</span><span class="p">)</span>
<a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">doubled</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>tensor<span class="o">([[</span><span class="m">0</span>.6146,<span class="w"> </span><span class="m">0</span>.5999,<span class="w"> </span><span class="m">0</span>.5013,<span class="w"> </span><span class="m">0</span>.9397<span class="o">]</span>,
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.8656,<span class="w"> </span><span class="m">0</span>.5207,<span class="w"> </span><span class="m">0</span>.6865,<span class="w"> </span><span class="m">0</span>.3614<span class="o">]])</span>
<a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a>tensor<span class="o">([[</span><span class="m">1</span>.2291,<span class="w"> </span><span class="m">1</span>.1998,<span class="w"> </span><span class="m">1</span>.0026,<span class="w"> </span><span class="m">1</span>.8793<span class="o">]</span>,
<a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.7312,<span class="w"> </span><span class="m">1</span>.0413,<span class="w"> </span><span class="m">1</span>.3730,<span class="w"> </span><span class="m">0</span>.7228<span class="o">]])</span>
</code></pre></div></p>
<p>这里有什么诀窍？我们是如何将一个 2x4 tensor乘以一个 1x4 tensor的呢？</p>
<p>广播是在形状相似的tensor之间进行运算的一种方式。在上面的例子中，单行四列tensor与双行四列tensor的两行相乘。</p>
<p>这是深度学习中的一个重要操作。常见的例子是将一个学习权重tensor与一批输入tensor相乘，分别对批次中的每个实例进行运算，然后返回一个形状相同的tensor——就像我们上面的 (2, 4) * (1, 4) 例子一样，返回一个形状为 (2, 4) 的tensor。</p>
<p>广播的规则如下：</p>
<ul>
<li>每个tensor必须至少有一个维度，不能是空tensor。</li>
<li>比较两个tensor的维数大小，从最后一个到第一个：<ul>
<li>每个维度必须相等，或</li>
<li>其中一个维的大小必须为 1，或</li>
<li>维度在一个tensor中不存在</li>
</ul>
</li>
</ul>
<p>当然，形状相同的tensor是“可广播”的，这在前面已经提到过。</p>
<p>下面是一些符合上述规则的可广播示例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="n">a</span> <span class="o">=</span>     <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>   <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 3rd &amp; 2nd dims identical to a, dim 1 absent</span>
<a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a>
<a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a><span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>   <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 3rd dim = 1, 2nd dim identical to a</span>
<a id="__codelineno-20-7" name="__codelineno-20-7" href="#__codelineno-20-7"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<a id="__codelineno-20-8" name="__codelineno-20-8" href="#__codelineno-20-8"></a>
<a id="__codelineno-20-9" name="__codelineno-20-9" href="#__codelineno-20-9"></a><span class="n">d</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>   <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 3rd dim identical to a, 2nd dim = 1</span>
<a id="__codelineno-20-10" name="__codelineno-20-10" href="#__codelineno-20-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>tensor<span class="o">([[[</span><span class="m">0</span>.6493,<span class="w"> </span><span class="m">0</span>.2633<span class="o">]</span>,
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.4762,<span class="w"> </span><span class="m">0</span>.0548<span class="o">]</span>,
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.2024,<span class="w"> </span><span class="m">0</span>.5731<span class="o">]]</span>,
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a>
<a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.6493,<span class="w"> </span><span class="m">0</span>.2633<span class="o">]</span>,
<a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.4762,<span class="w"> </span><span class="m">0</span>.0548<span class="o">]</span>,
<a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.2024,<span class="w"> </span><span class="m">0</span>.5731<span class="o">]]</span>,
<a id="__codelineno-21-8" name="__codelineno-21-8" href="#__codelineno-21-8"></a>
<a id="__codelineno-21-9" name="__codelineno-21-9" href="#__codelineno-21-9"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.6493,<span class="w"> </span><span class="m">0</span>.2633<span class="o">]</span>,
<a id="__codelineno-21-10" name="__codelineno-21-10" href="#__codelineno-21-10"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.4762,<span class="w"> </span><span class="m">0</span>.0548<span class="o">]</span>,
<a id="__codelineno-21-11" name="__codelineno-21-11" href="#__codelineno-21-11"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.2024,<span class="w"> </span><span class="m">0</span>.5731<span class="o">]]</span>,
<a id="__codelineno-21-12" name="__codelineno-21-12" href="#__codelineno-21-12"></a>
<a id="__codelineno-21-13" name="__codelineno-21-13" href="#__codelineno-21-13"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.6493,<span class="w"> </span><span class="m">0</span>.2633<span class="o">]</span>,
<a id="__codelineno-21-14" name="__codelineno-21-14" href="#__codelineno-21-14"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.4762,<span class="w"> </span><span class="m">0</span>.0548<span class="o">]</span>,
<a id="__codelineno-21-15" name="__codelineno-21-15" href="#__codelineno-21-15"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.2024,<span class="w"> </span><span class="m">0</span>.5731<span class="o">]]])</span>
<a id="__codelineno-21-16" name="__codelineno-21-16" href="#__codelineno-21-16"></a>tensor<span class="o">([[[</span><span class="m">0</span>.7191,<span class="w"> </span><span class="m">0</span>.7191<span class="o">]</span>,
<a id="__codelineno-21-17" name="__codelineno-21-17" href="#__codelineno-21-17"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.4067,<span class="w"> </span><span class="m">0</span>.4067<span class="o">]</span>,
<a id="__codelineno-21-18" name="__codelineno-21-18" href="#__codelineno-21-18"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.7301,<span class="w"> </span><span class="m">0</span>.7301<span class="o">]]</span>,
<a id="__codelineno-21-19" name="__codelineno-21-19" href="#__codelineno-21-19"></a>
<a id="__codelineno-21-20" name="__codelineno-21-20" href="#__codelineno-21-20"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.7191,<span class="w"> </span><span class="m">0</span>.7191<span class="o">]</span>,
<a id="__codelineno-21-21" name="__codelineno-21-21" href="#__codelineno-21-21"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.4067,<span class="w"> </span><span class="m">0</span>.4067<span class="o">]</span>,
<a id="__codelineno-21-22" name="__codelineno-21-22" href="#__codelineno-21-22"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.7301,<span class="w"> </span><span class="m">0</span>.7301<span class="o">]]</span>,
<a id="__codelineno-21-23" name="__codelineno-21-23" href="#__codelineno-21-23"></a>
<a id="__codelineno-21-24" name="__codelineno-21-24" href="#__codelineno-21-24"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.7191,<span class="w"> </span><span class="m">0</span>.7191<span class="o">]</span>,
<a id="__codelineno-21-25" name="__codelineno-21-25" href="#__codelineno-21-25"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.4067,<span class="w"> </span><span class="m">0</span>.4067<span class="o">]</span>,
<a id="__codelineno-21-26" name="__codelineno-21-26" href="#__codelineno-21-26"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.7301,<span class="w"> </span><span class="m">0</span>.7301<span class="o">]]</span>,
<a id="__codelineno-21-27" name="__codelineno-21-27" href="#__codelineno-21-27"></a>
<a id="__codelineno-21-28" name="__codelineno-21-28" href="#__codelineno-21-28"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.7191,<span class="w"> </span><span class="m">0</span>.7191<span class="o">]</span>,
<a id="__codelineno-21-29" name="__codelineno-21-29" href="#__codelineno-21-29"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.4067,<span class="w"> </span><span class="m">0</span>.4067<span class="o">]</span>,
<a id="__codelineno-21-30" name="__codelineno-21-30" href="#__codelineno-21-30"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.7301,<span class="w"> </span><span class="m">0</span>.7301<span class="o">]]])</span>
<a id="__codelineno-21-31" name="__codelineno-21-31" href="#__codelineno-21-31"></a>tensor<span class="o">([[[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]</span>,
<a id="__codelineno-21-32" name="__codelineno-21-32" href="#__codelineno-21-32"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]</span>,
<a id="__codelineno-21-33" name="__codelineno-21-33" href="#__codelineno-21-33"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]]</span>,
<a id="__codelineno-21-34" name="__codelineno-21-34" href="#__codelineno-21-34"></a>
<a id="__codelineno-21-35" name="__codelineno-21-35" href="#__codelineno-21-35"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]</span>,
<a id="__codelineno-21-36" name="__codelineno-21-36" href="#__codelineno-21-36"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]</span>,
<a id="__codelineno-21-37" name="__codelineno-21-37" href="#__codelineno-21-37"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]]</span>,
<a id="__codelineno-21-38" name="__codelineno-21-38" href="#__codelineno-21-38"></a>
<a id="__codelineno-21-39" name="__codelineno-21-39" href="#__codelineno-21-39"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]</span>,
<a id="__codelineno-21-40" name="__codelineno-21-40" href="#__codelineno-21-40"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]</span>,
<a id="__codelineno-21-41" name="__codelineno-21-41" href="#__codelineno-21-41"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]]</span>,
<a id="__codelineno-21-42" name="__codelineno-21-42" href="#__codelineno-21-42"></a>
<a id="__codelineno-21-43" name="__codelineno-21-43" href="#__codelineno-21-43"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]</span>,
<a id="__codelineno-21-44" name="__codelineno-21-44" href="#__codelineno-21-44"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]</span>,
<a id="__codelineno-21-45" name="__codelineno-21-45" href="#__codelineno-21-45"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.6276,<span class="w"> </span><span class="m">0</span>.7357<span class="o">]]])</span>
</code></pre></div></p>
<p>仔细观察上面每个tensor的值：</p>
<ul>
<li>创建tensor <code>b</code> 的乘法操作是在tensor <code>a</code> 的每个“层”上进行广播的。</li>
<li>对于 <code>c</code>，操作在 <code>a</code> 的每个层和每一行上进行广播——每个由 3 个元素组成的列是相同的。</li>
<li>对于 <code>d</code>，我们将它改变了——现在每一行在层和列之间都是相同的。</li>
</ul>
<p>有关广播的更多信息，请参阅 <a href="https://pytorch.org/docs/stable/notes/broadcasting.html">PyTorch 的相关文档</a>。</p>
<p>以下是一些尝试进行广播的示例，这些示例会失败：</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>以下单元格会抛出运行时错误。是故意为之。</p>
</div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="n">a</span> <span class="o">=</span>     <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>    <span class="c1"># dimensions must match last-to-first</span>
<a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a>
<a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a><span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>   <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># both 3rd &amp; 2nd dims different</span>
<a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a>
<a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a><span class="n">d</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="p">))</span>   <span class="c1"># can&#39;t broadcast with an empty tensor</span>
</code></pre></div>
<h3 id="tensor_5">更多tensor数学运算</h3>
<p>PyTorch tensor上有三百多种可以执行的操作。</p>
<p>以下是一小部分主要类别操作的示例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="c1"># common functions</span>
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Common functions:&#39;</span><span class="p">)</span>
<a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
<a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
<a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
<a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a>
<a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a><span class="c1"># trigonometric functions and their inverses</span>
<a id="__codelineno-23-10" name="__codelineno-23-10" href="#__codelineno-23-10"></a><span class="n">angles</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">4</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">4</span><span class="p">])</span>
<a id="__codelineno-23-11" name="__codelineno-23-11" href="#__codelineno-23-11"></a><span class="n">sines</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span>
<a id="__codelineno-23-12" name="__codelineno-23-12" href="#__codelineno-23-12"></a><span class="n">inverses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">asin</span><span class="p">(</span><span class="n">sines</span><span class="p">)</span>
<a id="__codelineno-23-13" name="__codelineno-23-13" href="#__codelineno-23-13"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Sine and arcsine:&#39;</span><span class="p">)</span>
<a id="__codelineno-23-14" name="__codelineno-23-14" href="#__codelineno-23-14"></a><span class="nb">print</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span>
<a id="__codelineno-23-15" name="__codelineno-23-15" href="#__codelineno-23-15"></a><span class="nb">print</span><span class="p">(</span><span class="n">sines</span><span class="p">)</span>
<a id="__codelineno-23-16" name="__codelineno-23-16" href="#__codelineno-23-16"></a><span class="nb">print</span><span class="p">(</span><span class="n">inverses</span><span class="p">)</span>
<a id="__codelineno-23-17" name="__codelineno-23-17" href="#__codelineno-23-17"></a>
<a id="__codelineno-23-18" name="__codelineno-23-18" href="#__codelineno-23-18"></a><span class="c1"># bitwise operations</span>
<a id="__codelineno-23-19" name="__codelineno-23-19" href="#__codelineno-23-19"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Bitwise XOR:&#39;</span><span class="p">)</span>
<a id="__codelineno-23-20" name="__codelineno-23-20" href="#__codelineno-23-20"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">11</span><span class="p">])</span>
<a id="__codelineno-23-21" name="__codelineno-23-21" href="#__codelineno-23-21"></a><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<a id="__codelineno-23-22" name="__codelineno-23-22" href="#__codelineno-23-22"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bitwise_xor</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
<a id="__codelineno-23-23" name="__codelineno-23-23" href="#__codelineno-23-23"></a>
<a id="__codelineno-23-24" name="__codelineno-23-24" href="#__codelineno-23-24"></a><span class="c1"># comparisons:</span>
<a id="__codelineno-23-25" name="__codelineno-23-25" href="#__codelineno-23-25"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Broadcasted, element-wise equality comparison:&#39;</span><span class="p">)</span>
<a id="__codelineno-23-26" name="__codelineno-23-26" href="#__codelineno-23-26"></a><span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]])</span>
<a id="__codelineno-23-27" name="__codelineno-23-27" href="#__codelineno-23-27"></a><span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># many comparison ops support broadcasting!</span>
<a id="__codelineno-23-28" name="__codelineno-23-28" href="#__codelineno-23-28"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span> <span class="c1"># returns a tensor of type bool</span>
<a id="__codelineno-23-29" name="__codelineno-23-29" href="#__codelineno-23-29"></a>
<a id="__codelineno-23-30" name="__codelineno-23-30" href="#__codelineno-23-30"></a><span class="c1"># reductions:</span>
<a id="__codelineno-23-31" name="__codelineno-23-31" href="#__codelineno-23-31"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Reduction ops:&#39;</span><span class="p">)</span>
<a id="__codelineno-23-32" name="__codelineno-23-32" href="#__codelineno-23-32"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>        <span class="c1"># returns a single-element tensor</span>
<a id="__codelineno-23-33" name="__codelineno-23-33" href="#__codelineno-23-33"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="c1"># extracts the value from the returned tensor</span>
<a id="__codelineno-23-34" name="__codelineno-23-34" href="#__codelineno-23-34"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>       <span class="c1"># average</span>
<a id="__codelineno-23-35" name="__codelineno-23-35" href="#__codelineno-23-35"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>        <span class="c1"># standard deviation</span>
<a id="__codelineno-23-36" name="__codelineno-23-36" href="#__codelineno-23-36"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>       <span class="c1"># product of all numbers</span>
<a id="__codelineno-23-37" name="__codelineno-23-37" href="#__codelineno-23-37"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])))</span> <span class="c1"># filter unique elements</span>
<a id="__codelineno-23-38" name="__codelineno-23-38" href="#__codelineno-23-38"></a>
<a id="__codelineno-23-39" name="__codelineno-23-39" href="#__codelineno-23-39"></a><span class="c1"># vector and linear algebra operations</span>
<a id="__codelineno-23-40" name="__codelineno-23-40" href="#__codelineno-23-40"></a><span class="n">v1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>         <span class="c1"># x unit vector</span>
<a id="__codelineno-23-41" name="__codelineno-23-41" href="#__codelineno-23-41"></a><span class="n">v2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>         <span class="c1"># y unit vector</span>
<a id="__codelineno-23-42" name="__codelineno-23-42" href="#__codelineno-23-42"></a><span class="n">m1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>                   <span class="c1"># random matrix</span>
<a id="__codelineno-23-43" name="__codelineno-23-43" href="#__codelineno-23-43"></a><span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]])</span> <span class="c1"># three times identity matrix</span>
<a id="__codelineno-23-44" name="__codelineno-23-44" href="#__codelineno-23-44"></a>
<a id="__codelineno-23-45" name="__codelineno-23-45" href="#__codelineno-23-45"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Vectors &amp; Matrices:&#39;</span><span class="p">)</span>
<a id="__codelineno-23-46" name="__codelineno-23-46" href="#__codelineno-23-46"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v1</span><span class="p">))</span> <span class="c1"># negative of z unit vector (v1 x v2 == -v2 x v1)</span>
<a id="__codelineno-23-47" name="__codelineno-23-47" href="#__codelineno-23-47"></a><span class="nb">print</span><span class="p">(</span><span class="n">m1</span><span class="p">)</span>
<a id="__codelineno-23-48" name="__codelineno-23-48" href="#__codelineno-23-48"></a><span class="n">m3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">)</span>
<a id="__codelineno-23-49" name="__codelineno-23-49" href="#__codelineno-23-49"></a><span class="nb">print</span><span class="p">(</span><span class="n">m3</span><span class="p">)</span>                  <span class="c1"># 3 times m1</span>
<a id="__codelineno-23-50" name="__codelineno-23-50" href="#__codelineno-23-50"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">m3</span><span class="p">))</span>       <span class="c1"># singular value decomposition</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>Common<span class="w"> </span>functions:
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>tensor<span class="o">([[</span><span class="m">0</span>.9238,<span class="w"> </span><span class="m">0</span>.5724,<span class="w"> </span><span class="m">0</span>.0791,<span class="w"> </span><span class="m">0</span>.2629<span class="o">]</span>,
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.1986,<span class="w"> </span><span class="m">0</span>.4439,<span class="w"> </span><span class="m">0</span>.6434,<span class="w"> </span><span class="m">0</span>.4776<span class="o">]])</span>
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>tensor<span class="o">([[</span>-0.,<span class="w"> </span>-0.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span>-0.<span class="o">]</span>,
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="w">        </span><span class="o">[</span>-0.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span>-0.<span class="o">]])</span>
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>tensor<span class="o">([[</span>-1.,<span class="w"> </span>-1.,<span class="w">  </span><span class="m">0</span>.,<span class="w"> </span>-1.<span class="o">]</span>,
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a><span class="w">        </span><span class="o">[</span>-1.,<span class="w">  </span><span class="m">0</span>.,<span class="w">  </span><span class="m">0</span>.,<span class="w"> </span>-1.<span class="o">]])</span>
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a>tensor<span class="o">([[</span>-0.5000,<span class="w"> </span>-0.5000,<span class="w">  </span><span class="m">0</span>.0791,<span class="w"> </span>-0.2629<span class="o">]</span>,
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a><span class="w">        </span><span class="o">[</span>-0.1986,<span class="w">  </span><span class="m">0</span>.4439,<span class="w">  </span><span class="m">0</span>.5000,<span class="w"> </span>-0.4776<span class="o">]])</span>
<a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a>
<a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a>Sine<span class="w"> </span>and<span class="w"> </span>arcsine:
<a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.7854,<span class="w"> </span><span class="m">1</span>.5708,<span class="w"> </span><span class="m">2</span>.3562<span class="o">])</span>
<a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.7071,<span class="w"> </span><span class="m">1</span>.0000,<span class="w"> </span><span class="m">0</span>.7071<span class="o">])</span>
<a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.7854,<span class="w"> </span><span class="m">1</span>.5708,<span class="w"> </span><span class="m">0</span>.7854<span class="o">])</span>
<a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a>
<a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a>Bitwise<span class="w"> </span>XOR:
<a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a>tensor<span class="o">([</span><span class="m">3</span>,<span class="w"> </span><span class="m">2</span>,<span class="w"> </span><span class="m">1</span><span class="o">])</span>
<a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a>
<a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a>Broadcasted,<span class="w"> </span>element-wise<span class="w"> </span>equality<span class="w"> </span>comparison:
<a id="__codelineno-24-20" name="__codelineno-24-20" href="#__codelineno-24-20"></a>tensor<span class="o">([[</span><span class="w"> </span>True,<span class="w"> </span>False<span class="o">]</span>,
<a id="__codelineno-24-21" name="__codelineno-24-21" href="#__codelineno-24-21"></a><span class="w">        </span><span class="o">[</span>False,<span class="w"> </span>False<span class="o">]])</span>
<a id="__codelineno-24-22" name="__codelineno-24-22" href="#__codelineno-24-22"></a>
<a id="__codelineno-24-23" name="__codelineno-24-23" href="#__codelineno-24-23"></a>Reduction<span class="w"> </span>ops:
<a id="__codelineno-24-24" name="__codelineno-24-24" href="#__codelineno-24-24"></a>tensor<span class="o">(</span><span class="m">4</span>.<span class="o">)</span>
<a id="__codelineno-24-25" name="__codelineno-24-25" href="#__codelineno-24-25"></a><span class="m">4</span>.0
<a id="__codelineno-24-26" name="__codelineno-24-26" href="#__codelineno-24-26"></a>tensor<span class="o">(</span><span class="m">2</span>.5000<span class="o">)</span>
<a id="__codelineno-24-27" name="__codelineno-24-27" href="#__codelineno-24-27"></a>tensor<span class="o">(</span><span class="m">1</span>.2910<span class="o">)</span>
<a id="__codelineno-24-28" name="__codelineno-24-28" href="#__codelineno-24-28"></a>tensor<span class="o">(</span><span class="m">24</span>.<span class="o">)</span>
<a id="__codelineno-24-29" name="__codelineno-24-29" href="#__codelineno-24-29"></a>tensor<span class="o">([</span><span class="m">1</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<a id="__codelineno-24-30" name="__codelineno-24-30" href="#__codelineno-24-30"></a>
<a id="__codelineno-24-31" name="__codelineno-24-31" href="#__codelineno-24-31"></a>Vectors<span class="w"> </span><span class="p">&amp;</span><span class="w"> </span>Matrices:
<a id="__codelineno-24-32" name="__codelineno-24-32" href="#__codelineno-24-32"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">0</span>.,<span class="w">  </span><span class="m">0</span>.,<span class="w"> </span>-1.<span class="o">])</span>
<a id="__codelineno-24-33" name="__codelineno-24-33" href="#__codelineno-24-33"></a>tensor<span class="o">([[</span><span class="m">0</span>.7375,<span class="w"> </span><span class="m">0</span>.8328<span class="o">]</span>,
<a id="__codelineno-24-34" name="__codelineno-24-34" href="#__codelineno-24-34"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.8444,<span class="w"> </span><span class="m">0</span>.2941<span class="o">]])</span>
<a id="__codelineno-24-35" name="__codelineno-24-35" href="#__codelineno-24-35"></a>tensor<span class="o">([[</span><span class="m">2</span>.2125,<span class="w"> </span><span class="m">2</span>.4985<span class="o">]</span>,
<a id="__codelineno-24-36" name="__codelineno-24-36" href="#__codelineno-24-36"></a><span class="w">        </span><span class="o">[</span><span class="m">2</span>.5332,<span class="w"> </span><span class="m">0</span>.8822<span class="o">]])</span>
<a id="__codelineno-24-37" name="__codelineno-24-37" href="#__codelineno-24-37"></a>torch.return_types.svd<span class="o">(</span>
<a id="__codelineno-24-38" name="__codelineno-24-38" href="#__codelineno-24-38"></a><span class="nv">U</span><span class="o">=</span>tensor<span class="o">([[</span>-0.7889,<span class="w"> </span>-0.6145<span class="o">]</span>,
<a id="__codelineno-24-39" name="__codelineno-24-39" href="#__codelineno-24-39"></a><span class="w">        </span><span class="o">[</span>-0.6145,<span class="w">  </span><span class="m">0</span>.7889<span class="o">]])</span>,
<a id="__codelineno-24-40" name="__codelineno-24-40" href="#__codelineno-24-40"></a><span class="nv">S</span><span class="o">=</span>tensor<span class="o">([</span><span class="m">4</span>.1498,<span class="w"> </span><span class="m">1</span>.0548<span class="o">])</span>,
<a id="__codelineno-24-41" name="__codelineno-24-41" href="#__codelineno-24-41"></a><span class="nv">V</span><span class="o">=</span>tensor<span class="o">([[</span>-0.7957,<span class="w">  </span><span class="m">0</span>.6056<span class="o">]</span>,
<a id="__codelineno-24-42" name="__codelineno-24-42" href="#__codelineno-24-42"></a><span class="w">        </span><span class="o">[</span>-0.6056,<span class="w"> </span>-0.7957<span class="o">]]))</span>
</code></pre></div></p>
<p>这只是一小部分运算示例。如需了解更多详情和所有数学函数，请参阅<a href="https://pytorch.org/docs/stable/torch.html#math-operations">文档</a>。</p>
<h3 id="tensor_6">原地修改tensor</h3>
<p>大多数对tensor的二进制运算都会返回第三个新tensor。当我们说 <code>c = a * b</code>(其中 <code>a</code> 和 <code>b</code> 都是tensor)时，新的tensor <code>c</code> 将占据一个与其他tensor不同的内存区域。</p>
<p>不过，有时您可能希望原地改变一个tensor——例如，如果您正在进行元素计算，您可以丢弃中间值。为此，大多数数学函数都有一个带下划线 (<code>_</code>) 的版本，可以原地改变tensor。</p>
<p>例如：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">4</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">4</span><span class="p">])</span>
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;a:&#39;</span><span class="p">)</span>
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>   <span class="c1"># this operation creates a new tensor in memory</span>
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>              <span class="c1"># a has not changed</span>
<a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a>
<a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">4</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">4</span><span class="p">])</span>
<a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">b:&#39;</span><span class="p">)</span>
<a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sin_</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>  <span class="c1"># note the underscore</span>
<a id="__codelineno-25-11" name="__codelineno-25-11" href="#__codelineno-25-11"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>              <span class="c1"># b has changed</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>a:
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.7854,<span class="w"> </span><span class="m">1</span>.5708,<span class="w"> </span><span class="m">2</span>.3562<span class="o">])</span>
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.7071,<span class="w"> </span><span class="m">1</span>.0000,<span class="w"> </span><span class="m">0</span>.7071<span class="o">])</span>
<a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.7854,<span class="w"> </span><span class="m">1</span>.5708,<span class="w"> </span><span class="m">2</span>.3562<span class="o">])</span>
<a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>
<a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a>b:
<a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.7854,<span class="w"> </span><span class="m">1</span>.5708,<span class="w"> </span><span class="m">2</span>.3562<span class="o">])</span>
<a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.7071,<span class="w"> </span><span class="m">1</span>.0000,<span class="w"> </span><span class="m">0</span>.7071<span class="o">])</span>
<a id="__codelineno-26-9" name="__codelineno-26-9" href="#__codelineno-26-9"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.7071,<span class="w"> </span><span class="m">1</span>.0000,<span class="w"> </span><span class="m">0</span>.7071<span class="o">])</span>
</code></pre></div></p>
<p>对于算术运算，也有类似的函数：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>
<a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before:&#39;</span><span class="p">)</span>
<a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">After adding:&#39;</span><span class="p">)</span>
<a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
<a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">After multiplying&#39;</span><span class="p">)</span>
<a id="__codelineno-27-12" name="__codelineno-27-12" href="#__codelineno-27-12"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
<a id="__codelineno-27-13" name="__codelineno-27-13" href="#__codelineno-27-13"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>Before:
<a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a>tensor<span class="o">([[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]</span>,
<a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]])</span>
<a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a>tensor<span class="o">([[</span><span class="m">0</span>.3788,<span class="w"> </span><span class="m">0</span>.4567<span class="o">]</span>,
<a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.0649,<span class="w"> </span><span class="m">0</span>.6677<span class="o">]])</span>
<a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a>
<a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a>After<span class="w"> </span>adding:
<a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a>tensor<span class="o">([[</span><span class="m">1</span>.3788,<span class="w"> </span><span class="m">1</span>.4567<span class="o">]</span>,
<a id="__codelineno-28-9" name="__codelineno-28-9" href="#__codelineno-28-9"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.0649,<span class="w"> </span><span class="m">1</span>.6677<span class="o">]])</span>
<a id="__codelineno-28-10" name="__codelineno-28-10" href="#__codelineno-28-10"></a>tensor<span class="o">([[</span><span class="m">1</span>.3788,<span class="w"> </span><span class="m">1</span>.4567<span class="o">]</span>,
<a id="__codelineno-28-11" name="__codelineno-28-11" href="#__codelineno-28-11"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.0649,<span class="w"> </span><span class="m">1</span>.6677<span class="o">]])</span>
<a id="__codelineno-28-12" name="__codelineno-28-12" href="#__codelineno-28-12"></a>tensor<span class="o">([[</span><span class="m">0</span>.3788,<span class="w"> </span><span class="m">0</span>.4567<span class="o">]</span>,
<a id="__codelineno-28-13" name="__codelineno-28-13" href="#__codelineno-28-13"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.0649,<span class="w"> </span><span class="m">0</span>.6677<span class="o">]])</span>
<a id="__codelineno-28-14" name="__codelineno-28-14" href="#__codelineno-28-14"></a>
<a id="__codelineno-28-15" name="__codelineno-28-15" href="#__codelineno-28-15"></a>After<span class="w"> </span>multiplying
<a id="__codelineno-28-16" name="__codelineno-28-16" href="#__codelineno-28-16"></a>tensor<span class="o">([[</span><span class="m">0</span>.1435,<span class="w"> </span><span class="m">0</span>.2086<span class="o">]</span>,
<a id="__codelineno-28-17" name="__codelineno-28-17" href="#__codelineno-28-17"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.0042,<span class="w"> </span><span class="m">0</span>.4459<span class="o">]])</span>
<a id="__codelineno-28-18" name="__codelineno-28-18" href="#__codelineno-28-18"></a>tensor<span class="o">([[</span><span class="m">0</span>.1435,<span class="w"> </span><span class="m">0</span>.2086<span class="o">]</span>,
<a id="__codelineno-28-19" name="__codelineno-28-19" href="#__codelineno-28-19"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.0042,<span class="w"> </span><span class="m">0</span>.4459<span class="o">]])</span>
</code></pre></div></p>
<p>请注意，这些原地运算函数是 <code>torch.Tensor</code> 对象上的方法，而不是像许多其他函数(如 <code>torch.sin()</code>)那样附加到 <code>torch</code> 模块上。从 <code>a.add_(b)</code> 可以看出，调用的tensor会原地发生变化。</p>
<p>还有一种方法可以将计算结果放入现有的已分配tensor中。到目前为止，我们看到的许多方法和函数(包括创建方法)都有一个 <code>out</code> 参数，可以指定一个tensor来接收输出结果。如果 <code>out</code> tensor的形状和 <code>dtype</code> 正确，就无需分配新的内存：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a><span class="n">old_id</span> <span class="o">=</span> <span class="nb">id</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a>
<a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<a id="__codelineno-29-7" name="__codelineno-29-7" href="#__codelineno-29-7"></a><span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
<a id="__codelineno-29-8" name="__codelineno-29-8" href="#__codelineno-29-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>                <span class="c1"># contents of c have changed</span>
<a id="__codelineno-29-9" name="__codelineno-29-9" href="#__codelineno-29-9"></a>
<a id="__codelineno-29-10" name="__codelineno-29-10" href="#__codelineno-29-10"></a><span class="k">assert</span> <span class="n">c</span> <span class="ow">is</span> <span class="n">d</span>           <span class="c1"># test c &amp; d are same object, not just containing equal values</span>
<a id="__codelineno-29-11" name="__codelineno-29-11" href="#__codelineno-29-11"></a><span class="k">assert</span> <span class="nb">id</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="n">old_id</span>  <span class="c1"># make sure that our new c is the same object as the old one</span>
<a id="__codelineno-29-12" name="__codelineno-29-12" href="#__codelineno-29-12"></a>
<a id="__codelineno-29-13" name="__codelineno-29-13" href="#__codelineno-29-13"></a><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">c</span><span class="p">)</span> <span class="c1"># works for creation too!</span>
<a id="__codelineno-29-14" name="__codelineno-29-14" href="#__codelineno-29-14"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>                <span class="c1"># c has changed again</span>
<a id="__codelineno-29-15" name="__codelineno-29-15" href="#__codelineno-29-15"></a><span class="k">assert</span> <span class="nb">id</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="n">old_id</span>  <span class="c1"># still the same object!</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>tensor<span class="o">([[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>,
<a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]])</span>
<a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a>tensor<span class="o">([[</span><span class="m">0</span>.3653,<span class="w"> </span><span class="m">0</span>.8699<span class="o">]</span>,
<a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.2364,<span class="w"> </span><span class="m">0</span>.3604<span class="o">]])</span>
<a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a>tensor<span class="o">([[</span><span class="m">0</span>.0776,<span class="w"> </span><span class="m">0</span>.4004<span class="o">]</span>,
<a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.9877,<span class="w"> </span><span class="m">0</span>.0352<span class="o">]])</span>
</code></pre></div></p>
<h2 id="tensor_7">复制tensor</h2>
<p>与 Python 中的对象一样，将tensor赋值给变量会使变量成为tensor的标签，而不会复制它。例如：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a><span class="n">b</span> <span class="o">=</span> <span class="n">a</span>
<a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a>
<a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">561</span>  <span class="c1"># we change a...</span>
<a id="__codelineno-31-5" name="__codelineno-31-5" href="#__codelineno-31-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>       <span class="c1"># ...and b is also altered</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>tensor<span class="o">([[</span><span class="w">  </span><span class="m">1</span>.,<span class="w"> </span><span class="m">561</span>.<span class="o">]</span>,
<a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a><span class="w">        </span><span class="o">[</span><span class="w">  </span><span class="m">1</span>.,<span class="w">   </span><span class="m">1</span>.<span class="o">]])</span>
</code></pre></div></p>
<p>但是，如果您需要一个单独的数据副本来处理数据，该怎么办呢？clone()方法就能满足您的需求：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a>
<a id="__codelineno-33-4" name="__codelineno-33-4" href="#__codelineno-33-4"></a><span class="k">assert</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">a</span>      <span class="c1"># different objects in memory...</span>
<a id="__codelineno-33-5" name="__codelineno-33-5" href="#__codelineno-33-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>  <span class="c1"># ...but still with the same contents!</span>
<a id="__codelineno-33-6" name="__codelineno-33-6" href="#__codelineno-33-6"></a>
<a id="__codelineno-33-7" name="__codelineno-33-7" href="#__codelineno-33-7"></a><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">561</span>          <span class="c1"># a changes...</span>
<a id="__codelineno-33-8" name="__codelineno-33-8" href="#__codelineno-33-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>               <span class="c1"># ...but b is still all ones</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a>tensor<span class="o">([[</span>True,<span class="w"> </span>True<span class="o">]</span>,
<a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a><span class="w">        </span><span class="o">[</span>True,<span class="w"> </span>True<span class="o">]])</span>
<a id="__codelineno-34-3" name="__codelineno-34-3" href="#__codelineno-34-3"></a>tensor<span class="o">([[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]</span>,
<a id="__codelineno-34-4" name="__codelineno-34-4" href="#__codelineno-34-4"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]])</span>
</code></pre></div></p>
<p><strong>使用 <code>clone()</code> 时需要注意一件重要的事情</strong>。如果源tensor启用了自动微分，那么克隆也会启用。<strong>关于自动微分的视频将对此进行更深入的介绍</strong>，但如果您想了解更多细节，请继续往下看。</p>
<p><em>在大多情况下</em>，这就是您想要的。例如，如果模型的 <code>forward()</code> 方法有多个计算路径，而原始tensor和克隆tensor都对模型的输出有贡献，那么要实现模型学习，就需要同时打开两个tensor的自动微分。如果源tensor启用了自动微分(如果它是一组学习权重或从涉及权重的计算中导出，则通常会启用)，那么就会得到想要的结果。</p>
<p><em>另一方面</em>，如果您正在进行的计算中，原始tensor或其克隆都不需要跟踪梯度，那么只要源tensor关闭了自动微分，就可以正常运行。</p>
<p><em>不过还有第三种情况</em>,想象一下：您在模型的 <code>forward()</code> 函数中执行计算，默认情况下梯度都是打开的，但您想在中途取出一些值来生成一些指标。在这种情况下，您不希望源tensor的克隆副本跟踪梯度——关闭自动微分的历史跟踪可以提高性能。为此，您可以在源tensor上使用 <code>.detach()</code> 方法：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># turn on autograd</span>
<a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a>
<a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<a id="__codelineno-35-5" name="__codelineno-35-5" href="#__codelineno-35-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<a id="__codelineno-35-6" name="__codelineno-35-6" href="#__codelineno-35-6"></a>
<a id="__codelineno-35-7" name="__codelineno-35-7" href="#__codelineno-35-7"></a><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<a id="__codelineno-35-8" name="__codelineno-35-8" href="#__codelineno-35-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<a id="__codelineno-35-9" name="__codelineno-35-9" href="#__codelineno-35-9"></a>
<a id="__codelineno-35-10" name="__codelineno-35-10" href="#__codelineno-35-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a>tensor<span class="o">([[</span><span class="m">0</span>.0905,<span class="w"> </span><span class="m">0</span>.4485<span class="o">]</span>,
<a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.8740,<span class="w"> </span><span class="m">0</span>.2526<span class="o">]]</span>,<span class="w"> </span><span class="nv">requires_grad</span><span class="o">=</span>True<span class="o">)</span>
<a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a>tensor<span class="o">([[</span><span class="m">0</span>.0905,<span class="w"> </span><span class="m">0</span>.4485<span class="o">]</span>,
<a id="__codelineno-36-4" name="__codelineno-36-4" href="#__codelineno-36-4"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.8740,<span class="w"> </span><span class="m">0</span>.2526<span class="o">]]</span>,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;CloneBackward0&gt;<span class="o">)</span>
<a id="__codelineno-36-5" name="__codelineno-36-5" href="#__codelineno-36-5"></a>tensor<span class="o">([[</span><span class="m">0</span>.0905,<span class="w"> </span><span class="m">0</span>.4485<span class="o">]</span>,
<a id="__codelineno-36-6" name="__codelineno-36-6" href="#__codelineno-36-6"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.8740,<span class="w"> </span><span class="m">0</span>.2526<span class="o">]])</span>
<a id="__codelineno-36-7" name="__codelineno-36-7" href="#__codelineno-36-7"></a>tensor<span class="o">([[</span><span class="m">0</span>.0905,<span class="w"> </span><span class="m">0</span>.4485<span class="o">]</span>,
<a id="__codelineno-36-8" name="__codelineno-36-8" href="#__codelineno-36-8"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.8740,<span class="w"> </span><span class="m">0</span>.2526<span class="o">]]</span>,<span class="w"> </span><span class="nv">requires_grad</span><span class="o">=</span>True<span class="o">)</span>
</code></pre></div></p>
<p>发生了什么？</p>
<ul>
<li>我们创建了一个开启 <code>requirements_grad=True</code> 的 <code>a</code>。<strong>我们还没有涉及这个可选参数，但会在自动微分单元中涉及。</strong></li>
<li>当我们打印 <code>a</code> 时，它会告诉我们属性 <code>requires_grad=True</code> ——这意味着自动微分和计算历史跟踪已打开。</li>
<li>我们拷贝 <code>a</code> 并标记为 <code>b</code>。当我们打印 <code>b</code> 时，可以看到它正在跟踪计算历史记录——它继承了 <code>a</code> 的自动微分设置，并添加到了计算历史记录中。</li>
<li>我们将 <code>a</code> 复制到 <code>c</code> 中，但要先调用 <code>detach()</code>。</li>
<li>在打印 <code>c</code> 时，我们没有看到计算历史，也没有看到 <code>requires_grad=True</code>。</li>
</ul>
<p><code>detach()</code> 方法 <em>将tensor从其计算历史中分离出来</em>。它说："不管接下来要做什么，都要像关闭自动微分一样"。我们可以看到，当我们在最后再次打印 <code>a</code> 时，它保留了 <code>requires_grad=True</code> 属性。</p>
<h2 id="gpu">转用 GPU</h2>
<p>PyTorch 的主要优势之一是其在兼容 CUDA 的 Nvidia GPU 上的强大加速能力。 CUDA 是计算统一设备架构(Compute Unified Device Architecture)的缩写，是 Nvidia 的并行计算平台。到目前为止，我们所做的一切都是在 CPU 上完成的。我们该如何使用更快的硬件呢？</p>
<p>首先，我们应该使用 <code>is_available()</code> 方法检查 GPU 是否可用。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>如果您没有安装与 CUDA 兼容的 GPU 和 CUDA 驱动程序，本节中的可执行单元将无法执行任何与 GPU 相关的代码。</p>
</div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
<a id="__codelineno-37-2" name="__codelineno-37-2" href="#__codelineno-37-2"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;We have a GPU!&#39;</span><span class="p">)</span>
<a id="__codelineno-37-3" name="__codelineno-37-3" href="#__codelineno-37-3"></a><span class="k">else</span><span class="p">:</span>
<a id="__codelineno-37-4" name="__codelineno-37-4" href="#__codelineno-37-4"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sorry, CPU only.&#39;</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a>We<span class="w"> </span>have<span class="w"> </span>a<span class="w"> </span>GPU!
</code></pre></div></p>
<p>一旦确定有一个或多个 GPU 可用，我们就需要将数据放到 GPU 可以看到的地方。CPU 在计算机 RAM 中对数据进行计算。而 GPU 则连接有专用内存。每当要在设备上执行计算时，必须将计算所需的所有数据移动到该设备可访问的内存中。(通俗地说，"将数据移至 GPU 可访问的内存 "简称为 "将数据移至 GPU")。</p>
<p>将数据转移到目标设备上的方法有多种，可以在创建时进行：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
<a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a>    <span class="n">gpu_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">gpu_rand</span><span class="p">)</span>
<a id="__codelineno-39-4" name="__codelineno-39-4" href="#__codelineno-39-4"></a><span class="k">else</span><span class="p">:</span>
<a id="__codelineno-39-5" name="__codelineno-39-5" href="#__codelineno-39-5"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sorry, CPU only.&#39;</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a>tensor<span class="o">([[</span><span class="m">0</span>.3344,<span class="w"> </span><span class="m">0</span>.2640<span class="o">]</span>,
<a id="__codelineno-40-2" name="__codelineno-40-2" href="#__codelineno-40-2"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.2119,<span class="w"> </span><span class="m">0</span>.0582<span class="o">]]</span>,<span class="w"> </span><span class="nv">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="o">)</span>
</code></pre></div></p>
<p>默认情况下，新tensor是在 CPU 上创建的，因此我们必须使用可选的 <code>device</code> 参数来指定何时在 GPU 上创建tensor。您可以看到，当我们打印新tensor时，PyTorch 会告诉我们它在哪个设备上(如果它不在 CPU 上)。</p>
<p>您可以使用 <code>torch.cuda.device_count()</code> 来查询 GPU 的数量。如果有多个 GPU，可以通过索引指定：<code>device='cuda:0'</code>、<code>device='cuda:1'</code> 等。</p>
<p>在编码实践中，使用字符串常量指定设备是非常不稳健的。在理想情况下，无论您使用的是 CPU 还是 GPU 硬件，您的代码都应该能稳定运行。为此，您可以创建一个设备句柄，将其传递给您的tensor，而非字符串：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
<a id="__codelineno-41-2" name="__codelineno-41-2" href="#__codelineno-41-2"></a>    <span class="n">my_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<a id="__codelineno-41-3" name="__codelineno-41-3" href="#__codelineno-41-3"></a><span class="k">else</span><span class="p">:</span>
<a id="__codelineno-41-4" name="__codelineno-41-4" href="#__codelineno-41-4"></a>    <span class="n">my_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<a id="__codelineno-41-5" name="__codelineno-41-5" href="#__codelineno-41-5"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">my_device</span><span class="p">))</span>
<a id="__codelineno-41-6" name="__codelineno-41-6" href="#__codelineno-41-6"></a>
<a id="__codelineno-41-7" name="__codelineno-41-7" href="#__codelineno-41-7"></a><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">my_device</span><span class="p">)</span>
<a id="__codelineno-41-8" name="__codelineno-41-8" href="#__codelineno-41-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a>Device:<span class="w"> </span>cuda
<a id="__codelineno-42-2" name="__codelineno-42-2" href="#__codelineno-42-2"></a>tensor<span class="o">([[</span><span class="m">0</span>.0024,<span class="w"> </span><span class="m">0</span>.6778<span class="o">]</span>,
<a id="__codelineno-42-3" name="__codelineno-42-3" href="#__codelineno-42-3"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.2441,<span class="w"> </span><span class="m">0</span>.6812<span class="o">]]</span>,<span class="w"> </span><span class="nv">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="o">)</span>
</code></pre></div></p>
<p>如果在一个设备上已有一个tensor，可以使用 <code>to()</code> 方法将其移动到另一个设备上。下面的代码在 CPU 上创建了一个tensor，并将其移动到上一单元中获得的设备句柄。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-43-2" name="__codelineno-43-2" href="#__codelineno-43-2"></a><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">my_device</span><span class="p">)</span>
</code></pre></div>
<p>要知道，想进行涉及两个或多个tensor的计算，所有tensor必须在同一设备上。无论您是否拥有 GPU 设备，以下代码都会在运行时出错：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-44-2" name="__codelineno-44-2" href="#__codelineno-44-2"></a><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;gpu&#39;</span><span class="p">)</span>
<a id="__codelineno-44-3" name="__codelineno-44-3" href="#__codelineno-44-3"></a><span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>  <span class="c1"># exception will be thrown</span>
</code></pre></div>
<h2 id="tensor_8">操作tensor形状</h2>
<p>有时，您需要改变tensor的形状。下面，我们将介绍几种常见情况，以及如何处理它们。</p>
<h3 id="_1">更改维数</h3>
<p>您可能需要更改维数的一种情况是，向模型传递单个输入实例。PyTorch 模型通常需要成批的输入。</p>
<p>例如，想象一下有一个模型可以在 3 x 226 x 226 图像(一个具有 3 个颜色通道的 226 像素正方形)上工作。当您加载并转换它时，您会得到一个形状为 (<code>3</code>, <code>226</code>, <code>226</code>) 的tensor。而您的模型则希望输入形状为(<code>N</code>，<code>3</code>，<code>226</code>，<code>226</code>)的tensor，其中 <code>N</code> 是批次中图像的数量。那么，如何制作一个批次的图像呢？</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">226</span><span class="p">,</span> <span class="mi">226</span><span class="p">)</span>
<a id="__codelineno-45-2" name="__codelineno-45-2" href="#__codelineno-45-2"></a><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-45-3" name="__codelineno-45-3" href="#__codelineno-45-3"></a>
<a id="__codelineno-45-4" name="__codelineno-45-4" href="#__codelineno-45-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-45-5" name="__codelineno-45-5" href="#__codelineno-45-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-45-6" name="__codelineno-45-6" href="#__codelineno-45-6"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">226</span><span class="p">,</span> <span class="mi">226</span><span class="p">])</span>
<a id="__codelineno-45-7" name="__codelineno-45-7" href="#__codelineno-45-7"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">226</span><span class="p">,</span> <span class="mi">226</span><span class="p">])</span>
</code></pre></div>
<p><code>unsqueeze()</code> 方法添加了一个范围为 1 的维度，<code>unsqueeze(0)</code> 则将其添加为一个新的第零维度——现在您有了一批 1 的维度！</p>
<p>所以这就是 <em>维度扩展( unsqueezing )</em>？维度压缩( squeezing )又是什么意思？实际上，范围为 1 的任何维度都 <em>不会</em> 改变tensor中元素的数量。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-46-2" name="__codelineno-46-2" href="#__codelineno-46-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a>tensor<span class="o">([[[[[</span><span class="m">0</span>.2347<span class="o">]]]]])</span>
</code></pre></div></p>
<p>继续上面的例子，假设模型的输出是每个输入的 20 元素的向量。那么您就会期望输出的形状是 (<code>N</code>, <code>20</code>)，其中 <code>N</code> 是输入批次中实例的数量。这意味着，对于单输入批次而言，我们将得到一个形状为(<code>1</code>，<code>20</code>)的输出。</p>
<p>如果您想用该输出进行一些非批处理计算——只期望得到一个 20 元素的向量，该怎么办呢？</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-48-1" name="__codelineno-48-1" href="#__codelineno-48-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<a id="__codelineno-48-2" name="__codelineno-48-2" href="#__codelineno-48-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-48-3" name="__codelineno-48-3" href="#__codelineno-48-3"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-48-4" name="__codelineno-48-4" href="#__codelineno-48-4"></a>
<a id="__codelineno-48-5" name="__codelineno-48-5" href="#__codelineno-48-5"></a><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-48-6" name="__codelineno-48-6" href="#__codelineno-48-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-48-7" name="__codelineno-48-7" href="#__codelineno-48-7"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<a id="__codelineno-48-8" name="__codelineno-48-8" href="#__codelineno-48-8"></a>
<a id="__codelineno-48-9" name="__codelineno-48-9" href="#__codelineno-48-9"></a><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-48-10" name="__codelineno-48-10" href="#__codelineno-48-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-48-11" name="__codelineno-48-11" href="#__codelineno-48-11"></a>
<a id="__codelineno-48-12" name="__codelineno-48-12" href="#__codelineno-48-12"></a><span class="n">d</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-48-13" name="__codelineno-48-13" href="#__codelineno-48-13"></a><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-49-1" name="__codelineno-49-1" href="#__codelineno-49-1"></a>torch.Size<span class="o">([</span><span class="m">1</span>,<span class="w"> </span><span class="m">20</span><span class="o">])</span>
<a id="__codelineno-49-2" name="__codelineno-49-2" href="#__codelineno-49-2"></a>tensor<span class="o">([[</span><span class="m">0</span>.1899,<span class="w"> </span><span class="m">0</span>.4067,<span class="w"> </span><span class="m">0</span>.1519,<span class="w"> </span><span class="m">0</span>.1506,<span class="w"> </span><span class="m">0</span>.9585,<span class="w"> </span><span class="m">0</span>.7756,<span class="w"> </span><span class="m">0</span>.8973,<span class="w"> </span><span class="m">0</span>.4929,<span class="w"> </span><span class="m">0</span>.2367,
<a id="__codelineno-49-3" name="__codelineno-49-3" href="#__codelineno-49-3"></a><span class="w">         </span><span class="m">0</span>.8194,<span class="w"> </span><span class="m">0</span>.4509,<span class="w"> </span><span class="m">0</span>.2690,<span class="w"> </span><span class="m">0</span>.8381,<span class="w"> </span><span class="m">0</span>.8207,<span class="w"> </span><span class="m">0</span>.6818,<span class="w"> </span><span class="m">0</span>.5057,<span class="w"> </span><span class="m">0</span>.9335,<span class="w"> </span><span class="m">0</span>.9769,
<a id="__codelineno-49-4" name="__codelineno-49-4" href="#__codelineno-49-4"></a><span class="w">         </span><span class="m">0</span>.2792,<span class="w"> </span><span class="m">0</span>.3277<span class="o">]])</span>
<a id="__codelineno-49-5" name="__codelineno-49-5" href="#__codelineno-49-5"></a>torch.Size<span class="o">([</span><span class="m">20</span><span class="o">])</span>
<a id="__codelineno-49-6" name="__codelineno-49-6" href="#__codelineno-49-6"></a>tensor<span class="o">([</span><span class="m">0</span>.1899,<span class="w"> </span><span class="m">0</span>.4067,<span class="w"> </span><span class="m">0</span>.1519,<span class="w"> </span><span class="m">0</span>.1506,<span class="w"> </span><span class="m">0</span>.9585,<span class="w"> </span><span class="m">0</span>.7756,<span class="w"> </span><span class="m">0</span>.8973,<span class="w"> </span><span class="m">0</span>.4929,<span class="w"> </span><span class="m">0</span>.2367,
<a id="__codelineno-49-7" name="__codelineno-49-7" href="#__codelineno-49-7"></a><span class="w">        </span><span class="m">0</span>.8194,<span class="w"> </span><span class="m">0</span>.4509,<span class="w"> </span><span class="m">0</span>.2690,<span class="w"> </span><span class="m">0</span>.8381,<span class="w"> </span><span class="m">0</span>.8207,<span class="w"> </span><span class="m">0</span>.6818,<span class="w"> </span><span class="m">0</span>.5057,<span class="w"> </span><span class="m">0</span>.9335,<span class="w"> </span><span class="m">0</span>.9769,
<a id="__codelineno-49-8" name="__codelineno-49-8" href="#__codelineno-49-8"></a><span class="w">        </span><span class="m">0</span>.2792,<span class="w"> </span><span class="m">0</span>.3277<span class="o">])</span>
<a id="__codelineno-49-9" name="__codelineno-49-9" href="#__codelineno-49-9"></a>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<a id="__codelineno-49-10" name="__codelineno-49-10" href="#__codelineno-49-10"></a>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
</code></pre></div>
如果仔细观察上面单元格的输出，就会发现由于多了一个维度，打印 <code>a</code> 显示了一组“额外”的方括号 <code>[]</code>。</p>
<p>您只能 <code>squeeze()</code> 范围为 1 的维数。请看上图，我们试图在 <code>c</code> 中压缩一个尺寸为 2 的维度，结果得到的形状和开始时一样。对 <code>squeeze()</code> 和 <code>unsqueeze()</code> 的调用只能作用于范围为 1 的维度，否则会改变tensor中元素的数量。</p>
<p><code>unsqueeze()</code>的另一个用途是简化广播。回顾上面的示例，我们有如下代码：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-50-1" name="__codelineno-50-1" href="#__codelineno-50-1"></a><span class="n">a</span> <span class="o">=</span>     <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-50-2" name="__codelineno-50-2" href="#__codelineno-50-2"></a>
<a id="__codelineno-50-3" name="__codelineno-50-3" href="#__codelineno-50-3"></a><span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>   <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 3rd dim = 1, 2nd dim identical to a</span>
<a id="__codelineno-50-4" name="__codelineno-50-4" href="#__codelineno-50-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</code></pre></div>
<p>这样做的效果是在 0 维和 2 维上广播操作，导致随机的 3 x 1 tensor与 <code>a</code> 中每一列的 3 元素相乘。</p>
<p>如果随机向量只是 3 元素向量呢？我们将无法广播，因为根据广播规则，最终维数将不匹配。这时 <code>unsqueeze()</code> 就派上用场了：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-51-1" name="__codelineno-51-1" href="#__codelineno-51-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-51-2" name="__codelineno-51-2" href="#__codelineno-51-2"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>   <span class="mi">3</span><span class="p">)</span>     <span class="c1"># trying to multiply a * b will give a runtime error</span>
<a id="__codelineno-51-3" name="__codelineno-51-3" href="#__codelineno-51-3"></a><span class="n">c</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>       <span class="c1"># change to a 2-dimensional tensor, adding new dim at the end</span>
<a id="__codelineno-51-4" name="__codelineno-51-4" href="#__codelineno-51-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-51-5" name="__codelineno-51-5" href="#__codelineno-51-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">c</span><span class="p">)</span>             <span class="c1"># broadcasting works again!</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-52-1" name="__codelineno-52-1" href="#__codelineno-52-1"></a>torch.Size<span class="o">([</span><span class="m">3</span>,<span class="w"> </span><span class="m">1</span><span class="o">])</span>
<a id="__codelineno-52-2" name="__codelineno-52-2" href="#__codelineno-52-2"></a>tensor<span class="o">([[[</span><span class="m">0</span>.1891,<span class="w"> </span><span class="m">0</span>.1891<span class="o">]</span>,
<a id="__codelineno-52-3" name="__codelineno-52-3" href="#__codelineno-52-3"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.3952,<span class="w"> </span><span class="m">0</span>.3952<span class="o">]</span>,
<a id="__codelineno-52-4" name="__codelineno-52-4" href="#__codelineno-52-4"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.9176,<span class="w"> </span><span class="m">0</span>.9176<span class="o">]]</span>,
<a id="__codelineno-52-5" name="__codelineno-52-5" href="#__codelineno-52-5"></a>
<a id="__codelineno-52-6" name="__codelineno-52-6" href="#__codelineno-52-6"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.1891,<span class="w"> </span><span class="m">0</span>.1891<span class="o">]</span>,
<a id="__codelineno-52-7" name="__codelineno-52-7" href="#__codelineno-52-7"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.3952,<span class="w"> </span><span class="m">0</span>.3952<span class="o">]</span>,
<a id="__codelineno-52-8" name="__codelineno-52-8" href="#__codelineno-52-8"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.9176,<span class="w"> </span><span class="m">0</span>.9176<span class="o">]]</span>,
<a id="__codelineno-52-9" name="__codelineno-52-9" href="#__codelineno-52-9"></a>
<a id="__codelineno-52-10" name="__codelineno-52-10" href="#__codelineno-52-10"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.1891,<span class="w"> </span><span class="m">0</span>.1891<span class="o">]</span>,
<a id="__codelineno-52-11" name="__codelineno-52-11" href="#__codelineno-52-11"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.3952,<span class="w"> </span><span class="m">0</span>.3952<span class="o">]</span>,
<a id="__codelineno-52-12" name="__codelineno-52-12" href="#__codelineno-52-12"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.9176,<span class="w"> </span><span class="m">0</span>.9176<span class="o">]]</span>,
<a id="__codelineno-52-13" name="__codelineno-52-13" href="#__codelineno-52-13"></a>
<a id="__codelineno-52-14" name="__codelineno-52-14" href="#__codelineno-52-14"></a><span class="w">        </span><span class="o">[[</span><span class="m">0</span>.1891,<span class="w"> </span><span class="m">0</span>.1891<span class="o">]</span>,
<a id="__codelineno-52-15" name="__codelineno-52-15" href="#__codelineno-52-15"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.3952,<span class="w"> </span><span class="m">0</span>.3952<span class="o">]</span>,
<a id="__codelineno-52-16" name="__codelineno-52-16" href="#__codelineno-52-16"></a><span class="w">         </span><span class="o">[</span><span class="m">0</span>.9176,<span class="w"> </span><span class="m">0</span>.9176<span class="o">]]])</span>
</code></pre></div></p>
<p><code>squeeze()</code> 和 <code>unsqueeze()</code> 也有原地版，<code>squeeze_()</code> 和 <code>unsqueeze_()</code>：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-53-1" name="__codelineno-53-1" href="#__codelineno-53-1"></a><span class="n">batch_me</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">226</span><span class="p">,</span> <span class="mi">226</span><span class="p">)</span>
<a id="__codelineno-53-2" name="__codelineno-53-2" href="#__codelineno-53-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">batch_me</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-53-3" name="__codelineno-53-3" href="#__codelineno-53-3"></a><span class="n">batch_me</span><span class="o">.</span><span class="n">unsqueeze_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-53-4" name="__codelineno-53-4" href="#__codelineno-53-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">batch_me</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-54-1" name="__codelineno-54-1" href="#__codelineno-54-1"></a>torch.Size<span class="o">([</span><span class="m">3</span>,<span class="w"> </span><span class="m">226</span>,<span class="w"> </span><span class="m">226</span><span class="o">])</span>
<a id="__codelineno-54-2" name="__codelineno-54-2" href="#__codelineno-54-2"></a>torch.Size<span class="o">([</span><span class="m">1</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">226</span>,<span class="w"> </span><span class="m">226</span><span class="o">])</span>
</code></pre></div></p>
<p>有时，您会希望更彻底地改变tensor的形状，同时仍保留元素的数量和内容。其中一种情况发生在模型的卷积层和线性层之间的接口处——这在图像分类模型中很常见。卷积核会产生一个形状特征 <em>x 宽 x 高</em> 的输出tensor，但接下来的线性层希望得到一个一维的输入。<code>reshape()</code> 可以帮您做到这一点，前提是您想要的维数与输入tensor的元素数相同：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-55-1" name="__codelineno-55-1" href="#__codelineno-55-1"></a><span class="n">output3d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<a id="__codelineno-55-2" name="__codelineno-55-2" href="#__codelineno-55-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">output3d</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-55-3" name="__codelineno-55-3" href="#__codelineno-55-3"></a>
<a id="__codelineno-55-4" name="__codelineno-55-4" href="#__codelineno-55-4"></a><span class="n">input1d</span> <span class="o">=</span> <span class="n">output3d</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">20</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<a id="__codelineno-55-5" name="__codelineno-55-5" href="#__codelineno-55-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">input1d</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-55-6" name="__codelineno-55-6" href="#__codelineno-55-6"></a>
<a id="__codelineno-55-7" name="__codelineno-55-7" href="#__codelineno-55-7"></a><span class="c1"># can also call it as a method on the torch module:</span>
<a id="__codelineno-55-8" name="__codelineno-55-8" href="#__codelineno-55-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">output3d</span><span class="p">,</span> <span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">20</span> <span class="o">*</span> <span class="mi">20</span><span class="p">,))</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-56-1" name="__codelineno-56-1" href="#__codelineno-56-1"></a>torch.Size<span class="o">([</span><span class="m">6</span>,<span class="w"> </span><span class="m">20</span>,<span class="w"> </span><span class="m">20</span><span class="o">])</span>
<a id="__codelineno-56-2" name="__codelineno-56-2" href="#__codelineno-56-2"></a>torch.Size<span class="o">([</span><span class="m">2400</span><span class="o">])</span>
<a id="__codelineno-56-3" name="__codelineno-56-3" href="#__codelineno-56-3"></a>torch.Size<span class="o">([</span><span class="m">2400</span><span class="o">])</span>
</code></pre></div></p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>上面单元格中最后一行的 <code>(6 * 20 * 20,)</code> 参数是因为 PyTorch 在指定tensor形状时期望一个<strong>元组</strong>——但当方法的第一个参数是形状时，它允许我们欺骗一下，只使用一系列整数。在这里，我们必须添加括号和逗号，告诉方法这是一个单元素元组。</p>
</div>
<p>如果可以，<code>reshape()</code> 会返回要更改的tensor的视图——也就是说，一个单独的tensor对象将查看同样的底层内存。这一点很重要：这意味着对源tensor所做的任何更改都会反映在该tensor的视图中，除非您 <code>clone()</code> 它。</p>
<p>在某些情况下，<code>reshape()</code> 必须返回一个携带数据副本的tensor，这超出了本介绍的范围。更多信息，请参阅<a href="https://pytorch.org/docs/stable/torch.html#torch.reshape">文档</a>。</p>
<h2 id="numpy">NumPy 桥接</h2>
<p>在上面关于广播的章节中，我们提到 PyTorch 的广播语义与 NumPy 的广播语义兼容，但 PyTorch 和 NumPy 之间的联系远不止于此。</p>
<p>如果您现有的 ML 或科学代码中的数据存储在 NumPy ndarrays 中，您可能希望用 PyTorch tensors 来表达相同的数据，无论是利用 PyTorch 的 GPU 加速，还是利用它构建 ML 模型的高效抽象。在 ndarrays 和 PyTorch tensors 之间切换非常简单：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-57-1" name="__codelineno-57-1" href="#__codelineno-57-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-57-2" name="__codelineno-57-2" href="#__codelineno-57-2"></a>
<a id="__codelineno-57-3" name="__codelineno-57-3" href="#__codelineno-57-3"></a><span class="n">numpy_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<a id="__codelineno-57-4" name="__codelineno-57-4" href="#__codelineno-57-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">numpy_array</span><span class="p">)</span>
<a id="__codelineno-57-5" name="__codelineno-57-5" href="#__codelineno-57-5"></a>
<a id="__codelineno-57-6" name="__codelineno-57-6" href="#__codelineno-57-6"></a><span class="n">pytorch_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">numpy_array</span><span class="p">)</span>
<a id="__codelineno-57-7" name="__codelineno-57-7" href="#__codelineno-57-7"></a><span class="nb">print</span><span class="p">(</span><span class="n">pytorch_tensor</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-58-1" name="__codelineno-58-1" href="#__codelineno-58-1"></a><span class="o">[[</span><span class="m">1</span>.<span class="w"> </span><span class="m">1</span>.<span class="w"> </span><span class="m">1</span>.<span class="o">]</span>
<a id="__codelineno-58-2" name="__codelineno-58-2" href="#__codelineno-58-2"></a><span class="w"> </span><span class="o">[</span><span class="m">1</span>.<span class="w"> </span><span class="m">1</span>.<span class="w"> </span><span class="m">1</span>.<span class="o">]]</span>
<a id="__codelineno-58-3" name="__codelineno-58-3" href="#__codelineno-58-3"></a>tensor<span class="o">([[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]</span>,
<a id="__codelineno-58-4" name="__codelineno-58-4" href="#__codelineno-58-4"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]]</span>,<span class="w"> </span><span class="nv">dtype</span><span class="o">=</span>torch.float64<span class="o">)</span>
</code></pre></div></p>
<p>PyTorch 创建了一个与 NumPy 数组形状、数据相同的tensor，甚至保留了 NumPy 的默认 64 位浮点数据类型。</p>
<p>这种转换也可以很容易地反过来：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-59-1" name="__codelineno-59-1" href="#__codelineno-59-1"></a><span class="n">pytorch_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-59-2" name="__codelineno-59-2" href="#__codelineno-59-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">pytorch_rand</span><span class="p">)</span>
<a id="__codelineno-59-3" name="__codelineno-59-3" href="#__codelineno-59-3"></a>
<a id="__codelineno-59-4" name="__codelineno-59-4" href="#__codelineno-59-4"></a><span class="n">numpy_rand</span> <span class="o">=</span> <span class="n">pytorch_rand</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-59-5" name="__codelineno-59-5" href="#__codelineno-59-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">numpy_rand</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a>tensor<span class="o">([[</span><span class="m">0</span>.8716,<span class="w"> </span><span class="m">0</span>.2459,<span class="w"> </span><span class="m">0</span>.3499<span class="o">]</span>,
<a id="__codelineno-60-2" name="__codelineno-60-2" href="#__codelineno-60-2"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.2853,<span class="w"> </span><span class="m">0</span>.9091,<span class="w"> </span><span class="m">0</span>.5695<span class="o">]])</span>
<a id="__codelineno-60-3" name="__codelineno-60-3" href="#__codelineno-60-3"></a><span class="o">[[</span><span class="m">0</span>.87163675<span class="w"> </span><span class="m">0</span>.2458961<span class="w">  </span><span class="m">0</span>.34993553<span class="o">]</span>
<a id="__codelineno-60-4" name="__codelineno-60-4" href="#__codelineno-60-4"></a><span class="w"> </span><span class="o">[</span><span class="m">0</span>.2853077<span class="w">  </span><span class="m">0</span>.90905803<span class="w"> </span><span class="m">0</span>.5695162<span class="w"> </span><span class="o">]]</span>
</code></pre></div></p>
<p>要知道，这些转换后的对象与其源对象使用的是相同的底层内存，也就是说，其中一个对象的变化会反映在另一个对象上：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a><span class="n">numpy_array</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">23</span>
<a id="__codelineno-61-2" name="__codelineno-61-2" href="#__codelineno-61-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">pytorch_tensor</span><span class="p">)</span>
<a id="__codelineno-61-3" name="__codelineno-61-3" href="#__codelineno-61-3"></a>
<a id="__codelineno-61-4" name="__codelineno-61-4" href="#__codelineno-61-4"></a><span class="n">pytorch_rand</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">17</span>
<a id="__codelineno-61-5" name="__codelineno-61-5" href="#__codelineno-61-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">numpy_rand</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-62-1" name="__codelineno-62-1" href="#__codelineno-62-1"></a>tensor<span class="o">([[</span><span class="w"> </span><span class="m">1</span>.,<span class="w">  </span><span class="m">1</span>.,<span class="w">  </span><span class="m">1</span>.<span class="o">]</span>,
<a id="__codelineno-62-2" name="__codelineno-62-2" href="#__codelineno-62-2"></a><span class="w">        </span><span class="o">[</span><span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">23</span>.,<span class="w">  </span><span class="m">1</span>.<span class="o">]]</span>,<span class="w"> </span><span class="nv">dtype</span><span class="o">=</span>torch.float64<span class="o">)</span>
<a id="__codelineno-62-3" name="__codelineno-62-3" href="#__codelineno-62-3"></a><span class="o">[[</span><span class="w"> </span><span class="m">0</span>.87163675<span class="w">  </span><span class="m">0</span>.2458961<span class="w">   </span><span class="m">0</span>.34993553<span class="o">]</span>
<a id="__codelineno-62-4" name="__codelineno-62-4" href="#__codelineno-62-4"></a><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.2853077<span class="w">  </span><span class="m">17</span>.<span class="w">          </span><span class="m">0</span>.5695162<span class="w"> </span><span class="o">]]</span>
</code></pre></div></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../introyt1_tutorial/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Introduction to PyTorch">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Introduction to PyTorch
              </div>
            </div>
          </a>
        
        
          
          <a href="../autogradyt_tutorial/" class="md-footer__link md-footer__link--next" aria-label="Next: The Fundamentals of Autograd">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                The Fundamentals of Autograd
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>