
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/2.0/tutorials/beginner/introyt/autogradyt_tutorial/">
      
      
        <link rel="prev" href="../tensors_deeper_tutorial/">
      
      
        <link rel="next" href="../modelsyt_tutorial/">
      
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>The Fundamentals of Autograd - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.d7758b05.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.75 1.75 0 0 1 1 7.775m1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2"/></svg>');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.5 1.75v11.5c0 .138.112.25.25.25h3.17a.75.75 0 0 1 0 1.5H2.75A1.75 1.75 0 0 1 1 13.25V1.75C1 .784 1.784 0 2.75 0h8.5C12.216 0 13 .784 13 1.75v7.736a.75.75 0 0 1-1.5 0V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25m13.274 9.537zl-4.557 4.45a.75.75 0 0 1-1.055-.008l-1.943-1.95a.75.75 0 0 1 1.062-1.058l1.419 1.425 4.026-3.932a.75.75 0 1 1 1.048 1.074M4.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5M4 7.75A.75.75 0 0 1 4.75 7h2a.75.75 0 0 1 0 1.5h-2A.75.75 0 0 1 4 7.75"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75M8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2"/></svg>');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M3.499.75a.75.75 0 0 1 1.5 0v.996C5.9 2.903 6.793 3.65 7.662 4.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873 10.794-.045 12.622.26 14.408.558 16 1.94 16 4.25c0 1.278-.954 2.575-2.44 2.734l.146.508.065.22c.203.701.412 1.455.476 2.226.142 1.707-.4 3.03-1.487 3.898C11.714 14.671 10.27 15 8.75 15h-6a.75.75 0 0 1 0-1.5h1.376a4.5 4.5 0 0 1-.563-1.191 3.84 3.84 0 0 1-.05-2.063 4.65 4.65 0 0 1-2.025-.293.75.75 0 0 1 .525-1.406c1.357.507 2.376-.006 2.698-.318l.009-.01a.747.747 0 0 1 1.06 0 .75.75 0 0 1-.012 1.074c-.912.92-.992 1.835-.768 2.586.221.74.745 1.337 1.196 1.621H8.75c1.343 0 2.398-.296 3.074-.836.635-.507 1.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4 2.4 0 0 1-.507-.441 3.1 3.1 0 0 1-.633-1.248.75.75 0 0 1 1.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738 0 1.25-.615 1.25-1.25 0-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706 1.345-.46.92-.27 1.774.019 3.062l.042.19.01.05c.348.443.666.949.94 1.553a.75.75 0 1 1-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7 5.527c-.814-.68-1.75-1.462-2.692-2.619a3.7 3.7 0 0 0-1.023.88c-.406.495-.663 1.036-.722 1.508.116.122.306.21.591.239.388.038.797-.06 1.032-.19a.75.75 0 0 1 .728 1.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75 5.677V5.5c0-.984.48-1.94 1.077-2.664.46-.559 1.05-1.055 1.673-1.353z"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0"/></svg>');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.92 6.085h.001a.749.749 0 1 1-1.342-.67c.169-.339.436-.701.849-.977C6.845 4.16 7.369 4 8 4a2.76 2.76 0 0 1 1.637.525c.503.377.863.965.863 1.725 0 .448-.115.83-.329 1.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6 6 0 0 0-.26.16 1 1 0 0 0-.276.245.75.75 0 0 1-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1 1 0 0 0 .277-.245C8.96 6.514 9 6.427 9 6.25a.61.61 0 0 0-.262-.525A1.27 1.27 0 0 0 8 5.5c-.369 0-.595.09-.74.187a1 1 0 0 0-.34.398M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.344 2.343za8 8 0 0 1 11.314 11.314A8.002 8.002 0 0 1 .234 10.089a8 8 0 0 1 2.11-7.746m1.06 10.253a6.5 6.5 0 1 0 9.108-9.275 6.5 6.5 0 0 0-9.108 9.275M6.03 4.97 8 6.94l1.97-1.97a.749.749 0 0 1 1.275.326.75.75 0 0 1-.215.734L9.06 8l1.97 1.97a.749.749 0 0 1-.326 1.275.75.75 0 0 1-.734-.215L8 9.06l-1.97 1.97a.749.749 0 0 1-1.275-.326.75.75 0 0 1 .215-.734L6.94 8 4.97 6.03a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018"/></svg>');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M9.504.43a1.516 1.516 0 0 1 2.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 0 1-.871.354h-.302a1.25 1.25 0 0 1-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004zm1.047 1.074L3.286 8.571A.25.25 0 0 0 3.462 9H6.75a.75.75 0 0 1 .694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0 0 12.538 7H9.25a.75.75 0 0 1-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005 0-.009.004"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M5 5.782V2.5h-.25a.75.75 0 0 1 0-1.5h6.5a.75.75 0 0 1 0 1.5H11v3.282l3.666 5.76C15.619 13.04 14.543 15 12.767 15H3.233c-1.776 0-2.852-1.96-1.899-3.458Zm-2.4 6.565a.75.75 0 0 0 .633 1.153h9.534a.75.75 0 0 0 .633-1.153L12.225 10.5h-8.45ZM9.5 2.5h-3V6c0 .143-.04.283-.117.403L4.73 9h6.54L9.617 6.403A.75.75 0 0 1 9.5 6Z"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 2.5h10.5a.75.75 0 0 1 0 1.5H1.75a.75.75 0 0 1 0-1.5m4 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5m0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5M2.5 7.75v6a.75.75 0 0 1-1.5 0v-6a.75.75 0 0 1 1.5 0"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.dafeiyang.cn/images/logo/logo_green.webp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              The Fundamentals of Autograd
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.dafeiyang.cn/images/logo/logo_green.webp" alt="logo">

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 新特性
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 新特性
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V2.0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.13
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.12
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.11
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.10
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.8
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.7
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../LatestChanges/PyTorch_V1.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 2.x 中文文档 & 教程
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 2.x 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch Recipes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch Recipes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../recipes/recipes_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Recipes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../prototype/prototype_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Prototype Recipes
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learn the Basics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/quickstart_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/tensorqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/data_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets & DataLoaders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/transforms_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transforms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/buildmodel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build the Neural Network
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/autogradqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Differentiation with torch.autograd
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/optimization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Model Parameters
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/saveloadrun_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Save and Load the Model
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch on YouTube
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch on YouTube
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch - YouTube Series
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introyt1_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensors_deeper_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch Tensors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    The Fundamentals of Autograd
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    The Fundamentals of Autograd
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      为什么我们需要自动微分呢？
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      一个简单的例子
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      训练中的自动微分
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      启停自动微分
    </span>
  </a>
  
    <nav class="md-nav" aria-label="启停自动微分">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      自动微分和原地操作
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      自动微分分析器
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#api" class="md-nav__link">
    <span class="md-ellipsis">
      进阶主题：更多的自动微分细节和高级 API
    </span>
  </a>
  
    <nav class="md-nav" aria-label="进阶主题：更多的自动微分细节和高级 API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#api_1" class="md-nav__link">
    <span class="md-ellipsis">
      高级 API
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modelsyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Models with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorboardyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch TensorBoard Support
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trainingyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../captumyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Understanding with Captum
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_4" >
        
          
          <label class="md-nav__link" for="__nav_3_1_4" id="__nav_3_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Learning PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_4">
            <span class="md-nav__icon md-icon"></span>
            Learning PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning with PyTorch: A 60 Minute Blitz
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning PyTorch with Examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/tensorboard_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualizing Models, Data, and Training with TensorBoard
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_5" >
        
          
          <label class="md-nav__link" for="__nav_3_1_5" id="__nav_3_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Image and Video
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_5">
            <span class="md-nav__icon md-icon"></span>
            Image and Video
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torchvision_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision Object Detection Finetuning Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transfer Learning for Computer Vision Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adversarial Example Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial Transformer Networks Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/tiatoolbox_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Whole Slide Image Classification Using PyTorch and TIAToolbox
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_6" >
        
          
          <label class="md-nav__link" for="__nav_3_1_6" id="__nav_3_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Audio
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_6">
            <span class="md-nav__icon md-icon"></span>
            Audio
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_io_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio I/O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_resampling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Resampling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_data_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Data Augmentation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_feature_extractions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Extractions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_feature_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Augmentation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../audio_datasets_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Datasets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/speech_recognition_pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speech Recognition with Wav2Vec2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/text_to_speech_with_torchaudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-speech with Tacotron2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/forced_alignment_with_torchaudio_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forced Alignment with Wav2Vec2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_7" >
        
          
          <label class="md-nav__link" for="__nav_3_1_7" id="__nav_3_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_7">
            <span class="md-nav__icon md-icon"></span>
            Text
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bettertransformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fast Transformer Inference with Better Transformer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Classifying Names with a Character-Level RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Generating Names with a Character-Level RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Translation with a Sequence to Sequence Network and Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../text_sentiment_ngrams_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text classification with the torchtext library
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../translation_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Translation with nn.Transformer and torchtext
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../torchtext_custom_dataset_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocess custom text dataset using Torchtext
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_8" >
        
          
          <label class="md-nav__link" for="__nav_3_1_8" id="__nav_3_1_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Backends
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_8">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_9" >
        
          
          <label class="md-nav__link" for="__nav_3_1_9" id="__nav_3_1_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_9">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/reinforcement_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (PPO) with TorchRL Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/mario_rl_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a Mario-playing RL Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/pendulum/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pendulum: Writing your environment and transforms with TorchRL
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_10" >
        
          
          <label class="md-nav__link" for="__nav_3_1_10" id="__nav_3_1_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deploying PyTorch Models in Production
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_10">
            <span class="md-nav__icon md-icon"></span>
            Deploying PyTorch Models in Production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/flask_rest_api_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying PyTorch in Python via a REST API with Flask
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Intro_to_TorchScript_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchScript
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loading a TorchScript Model in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/super_resolution_with_onnxruntime/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/realtime_rpi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Real Time Inference on Raspberry Pi 4 (30 fps!)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_11" >
        
          
          <label class="md-nav__link" for="__nav_3_1_11" id="__nav_3_1_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Profiling PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_11">
            <span class="md-nav__icon md-icon"></span>
            Profiling PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hta_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Holistic Trace Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hta_trace_diff_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Trace Diff using Holistic Trace Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_12" >
        
          
          <label class="md-nav__link" for="__nav_3_1_12" id="__nav_3_1_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code Transforms with FX
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_12">
            <span class="md-nav__icon md-icon"></span>
            Code Transforms with FX
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/fx_conv_bn_fuser/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Convolution/Batch Norm fuser in FX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/fx_profiling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Simple CPU Performance Profiler with FX
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_13" >
        
          
          <label class="md-nav__link" for="__nav_3_1_13" id="__nav_3_1_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Frontend APIs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_13">
            <span class="md-nav__icon md-icon"></span>
            Frontend APIs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/memory_format_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Channels Last Memory Format in PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/forward_ad_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forward-mode Automatic Differentiation (Beta)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/jacobians_hessians/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Jacobians, Hessians, hvp, vhp, and more: composing function transforms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/ensembling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model ensembling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/per_sample_grads/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Per-sample-gradients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the PyTorch C++ Frontend
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/torch-script-parallelism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Parallelism in TorchScript
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/cpp_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd in C++ Frontend
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_14" >
        
          
          <label class="md-nav__link" for="__nav_3_1_14" id="__nav_3_1_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Extending PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_14">
            <span class="md-nav__icon md-icon"></span>
            Extending PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/custom_function_double_backward_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Double Backward with Custom Functions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/custom_function_conv_bn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fusing Convolution and Batch Norm using Custom Function
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/torch_script_custom_classes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Classes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Registering a Dispatched Operator in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/extend_dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending dispatcher for a new backend in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/privateuseone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Facilitating New Backend Integration by PrivateUse1
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_15" >
        
          
          <label class="md-nav__link" for="__nav_3_1_15" id="__nav_3_1_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Optimization
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_15">
            <span class="md-nav__icon md-icon"></span>
            Model Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/tensorboard_profiler_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Profiler With TensorBoard
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hyperparameter_tuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter tuning with Ray Tune
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/parametrizations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametrizations Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/pruning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pruning Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/dynamic_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on an LSTM Word Language Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/dynamic_quantization_bert_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on BERT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/quantized_transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Quantized Transfer Learning for Computer Vision Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/static_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Static Quantization with Eager Mode in PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torchserve_with_ipex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torchserve_with_ipex_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles (Part 2)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/nvfuser_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started - Accelerate Your Scripts with nvFuser
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/ax_multiobjective_nas_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Objective NAS with Ax
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torch_compile_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to torch.compile
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/inductor_debug_cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inductor CPU backend debugging and profiling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../knowledge_distillation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge Distillation Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_16" >
        
          
          <label class="md-nav__link" for="__nav_3_1_16" id="__nav_3_1_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Parallel and Distributed Training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_16">
            <span class="md-nav__icon md-icon"></span>
            Parallel and Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../distributed/home/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed and Parallel Training Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dist_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Distributed Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ddp_series_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Data Parallel in PyTorch - Video Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/model_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single-Machine Model Parallel Best Practices
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed Data Parallel
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/FSDP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Fully Sharded Data Parallel(FSDP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/FSDP_adavnced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced Model Training with Fully Sharded Data Parallel (FSDP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/TP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Large Scale Transformer model training with Tensor Parallel (TP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/process_group_cpp_extension_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Process Group Backends Using Cpp Extensions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/rpc_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/rpc_param_server_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing a Parameter Server Using Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/dist_pipeline_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Pipeline Parallelism Using RPC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/rpc_async_execution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing Batch RPC Processing Using Asynchronous Executions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/rpc_ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Combining Distributed DataParallel with Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/ddp_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Distributed Data Parallel and Pipeline Parallelism
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/generic_join/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Training with Uneven Inputs Using the Join Context Manager
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_17" >
        
          
          <label class="md-nav__link" for="__nav_3_1_17" id="__nav_3_1_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Edge with ExecuTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_17">
            <span class="md-nav__icon md-icon"></span>
            Edge with ExecuTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exporting to ExecuTorch Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/running-a-model-cpp-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Running an ExecuTorch Model in C++ Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/tutorials/sdk-integration-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the ExecuTorch SDK to Profile a Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/demo-apps-ios.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building an ExecuTorch iOS Demo App
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/demo-apps-android.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building an ExecuTorch Android Demo App
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/examples-end-to-end-to-lower-model-to-delegate.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lowering a Model as a Delegate
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_18" >
        
          
          <label class="md-nav__link" for="__nav_3_1_18" id="__nav_3_1_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Recommendation Systems
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_18">
            <span class="md-nav__icon md-icon"></span>
            Recommendation Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../intermediate/torchrec_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchRec
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced/sharding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exploring TorchRec sharding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_19" >
        
          
          <label class="md-nav__link" for="__nav_3_1_19" id="__nav_3_1_19_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Multimodality
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_19">
            <span class="md-nav__icon md-icon"></span>
            Multimodality
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../flava_finetuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchMultimodal Tutorial: Finetuning FLAVA
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/docs/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pytorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/audio/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torchaudio
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/text/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchText
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/vision/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torcharrow/beta/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchArrow
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torchrec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchRec
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/serve/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchServe
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torchx/latest/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/xla/release/2.3/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch on XLA Devices
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.7 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.4 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.0 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.4 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.3 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.2 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../contrib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贡献指南
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于我们
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/join" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加入我们
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中文资源合集
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      为什么我们需要自动微分呢？
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      一个简单的例子
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      训练中的自动微分
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      启停自动微分
    </span>
  </a>
  
    <nav class="md-nav" aria-label="启停自动微分">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      自动微分和原地操作
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      自动微分分析器
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#api" class="md-nav__link">
    <span class="md-ellipsis">
      进阶主题：更多的自动微分细节和高级 API
    </span>
  </a>
  
    <nav class="md-nav" aria-label="进阶主题：更多的自动微分细节和高级 API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#api_1" class="md-nav__link">
    <span class="md-ellipsis">
      高级 API
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/2.0/tutorials/beginner/introyt/autogradyt_tutorial.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/2.0/tutorials/beginner/introyt/autogradyt_tutorial.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="_1">自动微分的基础知识</h1>
<blockquote>
<p>译者：<a href="https://github.com/Fadegentle">Fadegentle</a></p>
<p>项目地址：<a href="https://pytorch.apachecn.org/2.0/tutorials/beginner/introyt/autogradyt_tutorial">https://pytorch.apachecn.org/2.0/tutorials/beginner/introyt/autogradyt_tutorial</a></p>
<p>原始地址：<a href="https://pytorch.org/tutorials/beginner/introyt/autogradyt_tutorial.html">https://pytorch.org/tutorials/beginner/introyt/autogradyt_tutorial.html</a></p>
</blockquote>
<p>请跟随下面的视频或在 <a href="https://www.youtube.com/watch?v=M0fX15_-xrY">youtube</a> 上观看。</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/M0fX15_-xrY" title="The Fundamentals of Autograd" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

<p>PyTorch 的自动微分( Autograd )特性使 PyTorch 在构建机器学习项目时更加灵活高效。它能快速简便地计算复杂计算中的多个偏导数(也称为梯度)。这个操作在基于反向传播的神经网络学习中起着核心作用。</p>
<p>自动微分的强大之处在于它能在运行时动态跟踪计算，这意味着，如果您的模型具有决策分支或长度直到运行时才知道的循环，计算仍能被正确跟踪，并获得正确的梯度来进行学习。再加上模型是用 Python 构建，比起依赖静态分析结构僵化的模型来计算梯度的框架，提供了更大的灵活性。</p>
<h2 id="_2">为什么我们需要自动微分呢？</h2>
<p>一个机器学习模型就是一个有输入输出的 <em>函数</em>。在探讨中，我们将输入看作元素为 <span class="arithmatex">\(x_i\)</span> 的 <em>i</em> 维向量 <span class="arithmatex">\(\vec{x}\)</span>。我们可以将模型 <span class="arithmatex">\(M\)</span> 表述为输入的向量值函数：<span class="arithmatex">\(\vec{y} = \vec{M}(\vec{x})\)</span>。(我们将 <span class="arithmatex">\(M\)</span> 的输出值看作一个向量，因为一般来说，一个模型可能有任意数量的输出。) </p>
<p>由于我们主要是在训练的背景下讨论自动微分，因此我们要关注的输出是模型的损失。<em>损失函数</em> <span class="arithmatex">\(L(\vec{y}) = L(\vec{M}(\vec{x}))\)</span> 是模型输出的单值标量函数。该函数表示模型预测与特定输入的理想输出相差多少。<em>注意：此后，我们一般会在上下文中清楚的情况下省略向量符号</em>——例如，使用 <span class="arithmatex">\(y\)</span> 而非 <span class="arithmatex">\(\vec{y}\)</span>。</p>
<p>在训练模型时，我们希望将损失降到最低。在理想化的完美模型中，这意味着调整其学习权重(即函数的可调参数)，使所有输入的损失都为零。在现实世界中，这意味着通过迭代过程，微调学习权重，直到我们看到在各种输入下获得可接受的损失。。</p>
<p>我们如何决定权重调整的大小和方向？我们希望将损失 <em>最小化</em>，也就是让损失对输入的一阶导数等于 0：<span class="arithmatex">\(\frac{\partial L}{\partial x} = 0\)</span>。</p>
<p>但请注意，损失并 <em>不是直接</em> 来自输入，而是模型输出(直接输入的函数)的函数，<span class="arithmatex">\(\frac{\partial L}{\partial x} = \frac{\partial L}{\partial y} \frac{\partial y}{\partial x}\)</span>。根据微积分的链式法则，我们有 <span class="arithmatex">\(\frac{\partial L(\vec{y})}{\partial x} = \frac{\partial L}{\partial y} \frac{\partial y}{\partial x} = \frac{\partial L}{\partial y} \frac{\partial M(x)}{\partial x}\)</span>。</p>
<p>从 <span class="arithmatex">\(\frac{\partial M(x)}{\partial x}\)</span> 开始，事情复杂了起来。如果我们再次使用链式法则展开表达式，模型输出关于其输入的偏导数，将涉及到模型中每个乘以学习权重的局部偏导数、每个激活函数以及模型中的其他数学变换。每个局部导数的完整表达式都是计算图中每条 <em>可能路径</em>(欲测量梯度的变量结束的路径)的局部梯度乘积之和。</p>
<p>特别是，我们对学习权重的梯度很感兴趣——它们告诉我们应该 <em>朝哪个方向改变每个权重</em>，才能使损失函数趋近于零。</p>
<p>由于这种局部导数(每个局部导数对应模型计算图中的一条单独路径)的数量会随着神经网络的深度呈指数级增长，因此计算它们的复杂度也会随之增加。这就是自动微分的作用所在： 它可以跟踪每次计算的历史。PyTorch 模型中的每一个计算tensor都带有输入tensor和创建函数的历史记录。再加上 PyTorch 中用于作用于tensor的函数都有计算自身导数的内置实现，这就大大加快了学习所需的局部导数的计算速度。</p>
<h2 id="_3">一个简单的例子</h2>
<p>理论有很多——但在实践中使用自动微分又如何呢？</p>
<p>让我们从一个简单的例子开始。首先，我们将导入一些库，以便绘制我们的结果：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="c1"># %matplotlib inline</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.ticker</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ticker</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
</code></pre></div>
<p>然后，我们将创建一个输入tensor，内含均匀分布在 <span class="arithmatex">\([0, 2\pi]\)</span> 的值，并指定 <code>requires_grad=True</code>。(和大多数创建tensor的函数一样，<code>torch.linspace()</code> 也能选择 <code>requires_grad</code> 。)设置此标志意味着在随后的每次计算中，自动微分都会在该次计算的输出tensor中累积计算历史。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>tensor<span class="o">([</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.2618,<span class="w"> </span><span class="m">0</span>.5236,<span class="w"> </span><span class="m">0</span>.7854,<span class="w"> </span><span class="m">1</span>.0472,<span class="w"> </span><span class="m">1</span>.3090,<span class="w"> </span><span class="m">1</span>.5708,<span class="w"> </span><span class="m">1</span>.8326,<span class="w"> </span><span class="m">2</span>.0944,
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="w">        </span><span class="m">2</span>.3562,<span class="w"> </span><span class="m">2</span>.6180,<span class="w"> </span><span class="m">2</span>.8798,<span class="w"> </span><span class="m">3</span>.1416,<span class="w"> </span><span class="m">3</span>.4034,<span class="w"> </span><span class="m">3</span>.6652,<span class="w"> </span><span class="m">3</span>.9270,<span class="w"> </span><span class="m">4</span>.1888,<span class="w"> </span><span class="m">4</span>.4506,
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="w">        </span><span class="m">4</span>.7124,<span class="w"> </span><span class="m">4</span>.9742,<span class="w"> </span><span class="m">5</span>.2360,<span class="w"> </span><span class="m">5</span>.4978,<span class="w"> </span><span class="m">5</span>.7596,<span class="w"> </span><span class="m">6</span>.0214,<span class="w"> </span><span class="m">6</span>.2832<span class="o">]</span>,
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="w">       </span><span class="nv">requires_grad</span><span class="o">=</span>True<span class="o">)</span>
</code></pre></div></p>
<p>接着，我们将进行计算，并根据输入绘制输出图：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">b</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
</code></pre></div>
<p><img alt="sphx_glr_autogradyt_tutorial_001" src="../../../../img/sphx_glr_autogradyt_tutorial_001.png" /></p>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="o">[</span>&lt;matplotlib.lines.Line2D<span class="w"> </span>object<span class="w"> </span>at<span class="w"> </span>0x7f598d0477c0&gt;<span class="o">]</span>
</code></pre></div></p>
<p>让我们仔细看看tensor <code>b</code>。当我们打印它时，我们会看到一个指示器，表明它正在跟踪其计算历史：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">0</span>.0000e+00,<span class="w">  </span><span class="m">2</span>.5882e-01,<span class="w">  </span><span class="m">5</span>.0000e-01,<span class="w">  </span><span class="m">7</span>.0711e-01,<span class="w">  </span><span class="m">8</span>.6603e-01,
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="w">         </span><span class="m">9</span>.6593e-01,<span class="w">  </span><span class="m">1</span>.0000e+00,<span class="w">  </span><span class="m">9</span>.6593e-01,<span class="w">  </span><span class="m">8</span>.6603e-01,<span class="w">  </span><span class="m">7</span>.0711e-01,
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="w">         </span><span class="m">5</span>.0000e-01,<span class="w">  </span><span class="m">2</span>.5882e-01,<span class="w"> </span>-8.7423e-08,<span class="w"> </span>-2.5882e-01,<span class="w"> </span>-5.0000e-01,
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="w">        </span>-7.0711e-01,<span class="w"> </span>-8.6603e-01,<span class="w"> </span>-9.6593e-01,<span class="w"> </span>-1.0000e+00,<span class="w"> </span>-9.6593e-01,
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="w">        </span>-8.6603e-01,<span class="w"> </span>-7.0711e-01,<span class="w"> </span>-5.0000e-01,<span class="w"> </span>-2.5882e-01,<span class="w">  </span><span class="m">1</span>.7485e-07<span class="o">]</span>,
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="w">       </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;SinBackward0&gt;<span class="o">)</span>
</code></pre></div></p>
<p>这个 <code>grad_fn</code> 告诉我们，当我们执行反向传播步骤并计算梯度时，我们要为所有tensor输入计算 <span class="arithmatex">\(\sin(x)\)</span> 的导数。</p>
<p>让我们再进行一些计算：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="n">c</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">b</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="n">d</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">1</span>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">0</span>.0000e+00,<span class="w">  </span><span class="m">5</span>.1764e-01,<span class="w">  </span><span class="m">1</span>.0000e+00,<span class="w">  </span><span class="m">1</span>.4142e+00,<span class="w">  </span><span class="m">1</span>.7321e+00,
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="w">         </span><span class="m">1</span>.9319e+00,<span class="w">  </span><span class="m">2</span>.0000e+00,<span class="w">  </span><span class="m">1</span>.9319e+00,<span class="w">  </span><span class="m">1</span>.7321e+00,<span class="w">  </span><span class="m">1</span>.4142e+00,
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="w">         </span><span class="m">1</span>.0000e+00,<span class="w">  </span><span class="m">5</span>.1764e-01,<span class="w"> </span>-1.7485e-07,<span class="w"> </span>-5.1764e-01,<span class="w"> </span>-1.0000e+00,
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="w">        </span>-1.4142e+00,<span class="w"> </span>-1.7321e+00,<span class="w"> </span>-1.9319e+00,<span class="w"> </span>-2.0000e+00,<span class="w"> </span>-1.9319e+00,
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="w">        </span>-1.7321e+00,<span class="w"> </span>-1.4142e+00,<span class="w"> </span>-1.0000e+00,<span class="w"> </span>-5.1764e-01,<span class="w">  </span><span class="m">3</span>.4969e-07<span class="o">]</span>,
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="w">       </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;MulBackward0&gt;<span class="o">)</span>
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">1</span>.0000e+00,<span class="w">  </span><span class="m">1</span>.5176e+00,<span class="w">  </span><span class="m">2</span>.0000e+00,<span class="w">  </span><span class="m">2</span>.4142e+00,<span class="w">  </span><span class="m">2</span>.7321e+00,
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a><span class="w">         </span><span class="m">2</span>.9319e+00,<span class="w">  </span><span class="m">3</span>.0000e+00,<span class="w">  </span><span class="m">2</span>.9319e+00,<span class="w">  </span><span class="m">2</span>.7321e+00,<span class="w">  </span><span class="m">2</span>.4142e+00,
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a><span class="w">         </span><span class="m">2</span>.0000e+00,<span class="w">  </span><span class="m">1</span>.5176e+00,<span class="w">  </span><span class="m">1</span>.0000e+00,<span class="w">  </span><span class="m">4</span>.8236e-01,<span class="w"> </span>-3.5763e-07,
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a><span class="w">        </span>-4.1421e-01,<span class="w"> </span>-7.3205e-01,<span class="w"> </span>-9.3185e-01,<span class="w"> </span>-1.0000e+00,<span class="w"> </span>-9.3185e-01,
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a><span class="w">        </span>-7.3205e-01,<span class="w"> </span>-4.1421e-01,<span class="w">  </span><span class="m">4</span>.7684e-07,<span class="w">  </span><span class="m">4</span>.8236e-01,<span class="w">  </span><span class="m">1</span>.0000e+00<span class="o">]</span>,
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a><span class="w">       </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;AddBackward0&gt;<span class="o">)</span>
</code></pre></div></p>
<p>最后，我们来计算单元素输出。在没有参数的tensor上调用 <code>.backward()</code> 时，它希望调用的tensor只包含一个元素，计算损失函数时就是这种情况。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="n">out</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="n">tensor</span><span class="p">(</span><span class="mf">25.</span><span class="p">,</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">SumBackward0</span><span class="o">&gt;</span><span class="p">)</span>
</code></pre></div>
<p>每个存储在tensor中的 <code>grad_fn</code> 都可以通过 <code>next_functions</code> 属性追溯计算路径，直至输入。可以在下面看到，深入研究 <code>d</code> 的这一属性后，我们能看到之前所有tensor的梯度函数。请注意，<code>a.grad_fn</code> 被报告为 <code>None</code>，表示这是一个没有自身历史记录的函数输入。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;d:&#39;</span><span class="p">)</span>
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">)</span>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="n">next_functions</span><span class="p">)</span>
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">next_functions</span><span class="p">)</span>
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">next_functions</span><span class="p">)</span>
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">next_functions</span><span class="p">)</span>
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">c:&#39;</span><span class="p">)</span>
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">)</span>
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">b:&#39;</span><span class="p">)</span>
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">)</span>
<a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">a:&#39;</span><span class="p">)</span>
<a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>d:
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>&lt;AddBackward0<span class="w"> </span>object<span class="w"> </span>at<span class="w"> </span>0x7f598d4ad360&gt;
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="o">((</span>&lt;MulBackward0<span class="w"> </span>object<span class="w"> </span>at<span class="w"> </span>0x7f598d4ad450&gt;,<span class="w"> </span><span class="m">0</span><span class="o">)</span>,<span class="w"> </span><span class="o">(</span>None,<span class="w"> </span><span class="m">0</span><span class="o">))</span>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="o">((</span>&lt;SinBackward0<span class="w"> </span>object<span class="w"> </span>at<span class="w"> </span>0x7f598d4ad450&gt;,<span class="w"> </span><span class="m">0</span><span class="o">)</span>,<span class="w"> </span><span class="o">(</span>None,<span class="w"> </span><span class="m">0</span><span class="o">))</span>
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="o">((</span>&lt;AccumulateGrad<span class="w"> </span>object<span class="w"> </span>at<span class="w"> </span>0x7f598d4ad360&gt;,<span class="w"> </span><span class="m">0</span><span class="o">)</span>,<span class="o">)</span>
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a><span class="o">()</span>
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>c:
<a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>&lt;MulBackward0<span class="w"> </span>object<span class="w"> </span>at<span class="w"> </span>0x7f598d4ad450&gt;
<a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>
<a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>b:
<a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>&lt;SinBackward0<span class="w"> </span>object<span class="w"> </span>at<span class="w"> </span>0x7f598d4ad450&gt;
<a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>
<a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>a:
<a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>None
</code></pre></div></p>
<p>有了这些机制，我们如何获得导数呢？您可以在输出上调用 <code>backward()</code> 方法，并检查输入的 <code>grad</code> 属性来查看梯度：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">a</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
</code></pre></div>
<p><img alt="sphx_glr_autogradyt_tutorial_002" src="../../../../img/sphx_glr_autogradyt_tutorial_002.png" /></p>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">2</span>.0000e+00,<span class="w">  </span><span class="m">1</span>.9319e+00,<span class="w">  </span><span class="m">1</span>.7321e+00,<span class="w">  </span><span class="m">1</span>.4142e+00,<span class="w">  </span><span class="m">1</span>.0000e+00,
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="w">         </span><span class="m">5</span>.1764e-01,<span class="w"> </span>-8.7423e-08,<span class="w"> </span>-5.1764e-01,<span class="w"> </span>-1.0000e+00,<span class="w"> </span>-1.4142e+00,
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="w">        </span>-1.7321e+00,<span class="w"> </span>-1.9319e+00,<span class="w"> </span>-2.0000e+00,<span class="w"> </span>-1.9319e+00,<span class="w"> </span>-1.7321e+00,
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="w">        </span>-1.4142e+00,<span class="w"> </span>-1.0000e+00,<span class="w"> </span>-5.1764e-01,<span class="w">  </span><span class="m">2</span>.3850e-08,<span class="w">  </span><span class="m">5</span>.1764e-01,
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a><span class="w">         </span><span class="m">1</span>.0000e+00,<span class="w">  </span><span class="m">1</span>.4142e+00,<span class="w">  </span><span class="m">1</span>.7321e+00,<span class="w">  </span><span class="m">1</span>.9319e+00,<span class="w">  </span><span class="m">2</span>.0000e+00<span class="o">])</span>
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a><span class="o">[</span>&lt;matplotlib.lines.Line2D<span class="w"> </span>object<span class="w"> </span>at<span class="w"> </span>0x7f598d487070&gt;<span class="o">]</span>
</code></pre></div></p>
<p>回想一下，我们到这里的计算步骤：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a><span class="n">c</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">b</span>
<a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="n">d</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">1</span>
<a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a><span class="n">out</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div>
<p>在计算 <code>d</code> 时加入一个常数，并不会改变导数。因此，<span class="arithmatex">\(c=2∗b=2∗\sin(a)\)</span>，其导数应为 <span class="arithmatex">\(2∗\cos(a)\)</span>。观察上图，我们就会发现这一点。</p>
<p>请注意，只有计算的叶节点才会被计算梯度。举例来说，如果您尝试 <code>print(c.grad)</code>，得到的结果将是 <code>None</code>。在这个简单的例子中，只有输入是叶节点，因此只有它才会被计算梯度。</p>
<h2 id="_4">训练中的自动微分</h2>
<p>我们已经简单了解了自动微分的工作原理，但使用时能如我们所愿吗？让我们定义一个小模型，看看它在一次训练后会发生怎样的变化。首先，定义几个常量、模型以及一些输入和输出的替代品：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">16</span>
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="n">DIM_IN</span> <span class="o">=</span> <span class="mi">1000</span>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a><span class="n">HIDDEN_SIZE</span> <span class="o">=</span> <span class="mi">100</span>
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a><span class="n">DIM_OUT</span> <span class="o">=</span> <span class="mi">10</span>
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a><span class="k">class</span><span class="w"> </span><span class="nc">TinyModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>
<a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">TinyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a>
<a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<a id="__codelineno-15-13" name="__codelineno-15-13" href="#__codelineno-15-13"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<a id="__codelineno-15-14" name="__codelineno-15-14" href="#__codelineno-15-14"></a>
<a id="__codelineno-15-15" name="__codelineno-15-15" href="#__codelineno-15-15"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-15-16" name="__codelineno-15-16" href="#__codelineno-15-16"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-15-17" name="__codelineno-15-17" href="#__codelineno-15-17"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-15-18" name="__codelineno-15-18" href="#__codelineno-15-18"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-15-19" name="__codelineno-15-19" href="#__codelineno-15-19"></a>        <span class="k">return</span> <span class="n">x</span>
<a id="__codelineno-15-20" name="__codelineno-15-20" href="#__codelineno-15-20"></a>
<a id="__codelineno-15-21" name="__codelineno-15-21" href="#__codelineno-15-21"></a><span class="n">some_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">DIM_IN</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-15-22" name="__codelineno-15-22" href="#__codelineno-15-22"></a><span class="n">ideal_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">DIM_OUT</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-15-23" name="__codelineno-15-23" href="#__codelineno-15-23"></a>
<a id="__codelineno-15-24" name="__codelineno-15-24" href="#__codelineno-15-24"></a><span class="n">model</span> <span class="o">=</span> <span class="n">TinyModel</span><span class="p">()</span>
</code></pre></div>
<p>有件事情您可能注意到了，我们从来没有为模型的层指定 <code>requires_grad=True</code>。在 <code>torch.nn.Module</code> 的子类中，假设我们想要跟踪层的权重梯度以进行学习。</p>
<p>如果我们查看模型各层，便能检查权重的值，并验证尚未计算出梯度：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span> <span class="c1"># just a small slice</span>
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">0</span>.0920,<span class="w">  </span><span class="m">0</span>.0916,<span class="w">  </span><span class="m">0</span>.0121,<span class="w">  </span><span class="m">0</span>.0083,<span class="w"> </span>-0.0055,<span class="w">  </span><span class="m">0</span>.0367,<span class="w">  </span><span class="m">0</span>.0221,<span class="w"> </span>-0.0276,
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a><span class="w">        </span>-0.0086,<span class="w">  </span><span class="m">0</span>.0157<span class="o">]</span>,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;SliceBackward0&gt;<span class="o">)</span>
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>None
</code></pre></div></p>
<p>让我们看看运行一个训练批次时会发生什么。对于损失函数，我们将使用 <code>prediction</code> 和 <code>ideal_output</code> 之间欧氏距离的平方，并使用基本的随机梯度下降优化器。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a><span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">some_input</span><span class="p">)</span>
<a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a>
<a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a><span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">ideal_output</span> <span class="o">-</span> <span class="n">prediction</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>tensor<span class="o">(</span><span class="m">211</span>.2634,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;SumBackward0&gt;<span class="o">)</span>
</code></pre></div></p>
<p>现在，让我们调用 <code>loss.backward()</code>，看看会发生什么：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">0</span>.0920,<span class="w">  </span><span class="m">0</span>.0916,<span class="w">  </span><span class="m">0</span>.0121,<span class="w">  </span><span class="m">0</span>.0083,<span class="w"> </span>-0.0055,<span class="w">  </span><span class="m">0</span>.0367,<span class="w">  </span><span class="m">0</span>.0221,<span class="w"> </span>-0.0276,
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="w">        </span>-0.0086,<span class="w">  </span><span class="m">0</span>.0157<span class="o">]</span>,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;SliceBackward0&gt;<span class="o">)</span>
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>tensor<span class="o">([</span><span class="m">12</span>.8997,<span class="w">  </span><span class="m">2</span>.9572,<span class="w">  </span><span class="m">2</span>.3021,<span class="w">  </span><span class="m">1</span>.8887,<span class="w">  </span><span class="m">5</span>.0710,<span class="w">  </span><span class="m">7</span>.3192,<span class="w">  </span><span class="m">3</span>.5169,<span class="w">  </span><span class="m">2</span>.4319,
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a><span class="w">         </span><span class="m">0</span>.1732,<span class="w"> </span>-5.3835<span class="o">])</span>
</code></pre></div></p>
<p>我们可以看到，每个学习权重的梯度已经计算出来，但权重保持不变，因为我们还没有运行优化器。优化器负责根据计算出的梯度更新模型权重。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">0</span>.0791,<span class="w">  </span><span class="m">0</span>.0886,<span class="w">  </span><span class="m">0</span>.0098,<span class="w">  </span><span class="m">0</span>.0064,<span class="w"> </span>-0.0106,<span class="w">  </span><span class="m">0</span>.0293,<span class="w">  </span><span class="m">0</span>.0186,<span class="w"> </span>-0.0300,
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="w">        </span>-0.0088,<span class="w">  </span><span class="m">0</span>.0211<span class="o">]</span>,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;SliceBackward0&gt;<span class="o">)</span>
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a>tensor<span class="o">([</span><span class="m">12</span>.8997,<span class="w">  </span><span class="m">2</span>.9572,<span class="w">  </span><span class="m">2</span>.3021,<span class="w">  </span><span class="m">1</span>.8887,<span class="w">  </span><span class="m">5</span>.0710,<span class="w">  </span><span class="m">7</span>.3192,<span class="w">  </span><span class="m">3</span>.5169,<span class="w">  </span><span class="m">2</span>.4319,
<a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a><span class="w">         </span><span class="m">0</span>.1732,<span class="w"> </span>-5.3835<span class="o">])</span>
</code></pre></div></p>
<p>您应该看到 <code>layer2</code> 的权重已经改变了。</p>
<p>这个过程中有一点很重要： 调用 <code>optimizer.step()</code> 后，需要调用 <code>optimizer.zero_grad()</code>，否则每次运行 <code>loss.backward()</code>，学习权重的梯度都会累积：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">some_input</span><span class="p">)</span>
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a>    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">ideal_output</span> <span class="o">-</span> <span class="n">prediction</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a>
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a>
<a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a>
<a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>tensor<span class="o">([</span><span class="m">12</span>.8997,<span class="w">  </span><span class="m">2</span>.9572,<span class="w">  </span><span class="m">2</span>.3021,<span class="w">  </span><span class="m">1</span>.8887,<span class="w">  </span><span class="m">5</span>.0710,<span class="w">  </span><span class="m">7</span>.3192,<span class="w">  </span><span class="m">3</span>.5169,<span class="w">  </span><span class="m">2</span>.4319,
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a><span class="w">         </span><span class="m">0</span>.1732,<span class="w"> </span>-5.3835<span class="o">])</span>
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a>tensor<span class="o">([</span><span class="w"> </span><span class="m">19</span>.2095,<span class="w"> </span>-15.9459,<span class="w">   </span><span class="m">8</span>.3306,<span class="w">  </span><span class="m">11</span>.5096,<span class="w">   </span><span class="m">9</span>.5471,<span class="w">   </span><span class="m">0</span>.5391,<span class="w">  </span>-0.3370,
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a><span class="w">          </span><span class="m">8</span>.6386,<span class="w">  </span>-2.5141,<span class="w"> </span>-30.1419<span class="o">])</span>
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a>tensor<span class="o">([</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">])</span>
</code></pre></div></p>
<p>运行上面单元格后，您会发现在多次运行 <code>loss.backward()</code> 后，多数梯度都会变大很多。如果下一批训练之前没有将梯度归零，就会让梯度这样膨胀，从而造成不正确和不可预测的学习结果。</p>
<h2 id="_5">启停自动微分</h2>
<p>有时，您需要对是否启用自动微分进行细粒度控制。根据情况，有多种方法可以做到这一点。</p>
<p>最简单的方法是直接在tensor上更改 <code>requires_grad</code> 标志：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>
<a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a><span class="n">b1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">a</span>
<a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span>
<a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a>
<a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a><span class="n">b2</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">a</span>
<a id="__codelineno-26-9" name="__codelineno-26-9" href="#__codelineno-26-9"></a><span class="nb">print</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>tensor<span class="o">([[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]</span>,
<a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a><span class="w">        </span><span class="o">[</span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.,<span class="w"> </span><span class="m">1</span>.<span class="o">]]</span>,<span class="w"> </span><span class="nv">requires_grad</span><span class="o">=</span>True<span class="o">)</span>
<a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>tensor<span class="o">([[</span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.<span class="o">]</span>,
<a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a><span class="w">        </span><span class="o">[</span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.<span class="o">]]</span>,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;MulBackward0&gt;<span class="o">)</span>
<a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>tensor<span class="o">([[</span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.<span class="o">]</span>,
<a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a><span class="w">        </span><span class="o">[</span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.,<span class="w"> </span><span class="m">2</span>.<span class="o">]])</span>
</code></pre></div></p>
<p>在上面的单元格中，我们看到 <code>b1</code> 有一个 <code>grad_fn</code>(即跟踪计算历史)，这正是我们所期望的，因为它是由tensor <code>a</code> 派生的，而tensor <code>a</code> 已开启自动微分。当我们使用 <code>a.requires_grad = False</code> 显式地关闭自动微分时，计算历史将不再被跟踪，正如我们在计算 <code>b2</code> 时所看到的那样。</p>
<p>如果您只需要暂时关闭自动微分，更好的方法是使用 <code>torch.no_grad()</code>：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">3</span>
<a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a>
<a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a><span class="n">c1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
<a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">c1</span><span class="p">)</span>
<a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a>
<a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a>    <span class="n">c2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
<a id="__codelineno-28-9" name="__codelineno-28-9" href="#__codelineno-28-9"></a>
<a id="__codelineno-28-10" name="__codelineno-28-10" href="#__codelineno-28-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span>
<a id="__codelineno-28-11" name="__codelineno-28-11" href="#__codelineno-28-11"></a>
<a id="__codelineno-28-12" name="__codelineno-28-12" href="#__codelineno-28-12"></a><span class="n">c3</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>
<a id="__codelineno-28-13" name="__codelineno-28-13" href="#__codelineno-28-13"></a><span class="nb">print</span><span class="p">(</span><span class="n">c3</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>tensor<span class="o">([[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]</span>,
<a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a><span class="w">        </span><span class="o">[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]]</span>,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;AddBackward0&gt;<span class="o">)</span>
<a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a>tensor<span class="o">([[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]</span>,
<a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a><span class="w">        </span><span class="o">[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]])</span>
<a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a>tensor<span class="o">([[</span><span class="m">6</span>.,<span class="w"> </span><span class="m">6</span>.,<span class="w"> </span><span class="m">6</span>.<span class="o">]</span>,
<a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a><span class="w">        </span><span class="o">[</span><span class="m">6</span>.,<span class="w"> </span><span class="m">6</span>.,<span class="w"> </span><span class="m">6</span>.<span class="o">]]</span>,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;MulBackward0&gt;<span class="o">)</span>
</code></pre></div></p>
<p><code>torch.no_grad()</code> 也可以用作函数或方法装饰器：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">add_tensors1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a>    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a>
<a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a><span class="k">def</span><span class="w"> </span><span class="nf">add_tensors2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a>    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a>
<a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a>
<a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">3</span>
<a id="__codelineno-30-11" name="__codelineno-30-11" href="#__codelineno-30-11"></a>
<a id="__codelineno-30-12" name="__codelineno-30-12" href="#__codelineno-30-12"></a><span class="n">c1</span> <span class="o">=</span> <span class="n">add_tensors1</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<a id="__codelineno-30-13" name="__codelineno-30-13" href="#__codelineno-30-13"></a><span class="nb">print</span><span class="p">(</span><span class="n">c1</span><span class="p">)</span>
<a id="__codelineno-30-14" name="__codelineno-30-14" href="#__codelineno-30-14"></a>
<a id="__codelineno-30-15" name="__codelineno-30-15" href="#__codelineno-30-15"></a><span class="n">c2</span> <span class="o">=</span> <span class="n">add_tensors2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<a id="__codelineno-30-16" name="__codelineno-30-16" href="#__codelineno-30-16"></a><span class="nb">print</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a>tensor<span class="o">([[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]</span>,
<a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a><span class="w">        </span><span class="o">[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]]</span>,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;AddBackward0&gt;<span class="o">)</span>
<a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a>tensor<span class="o">([[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]</span>,
<a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a><span class="w">        </span><span class="o">[</span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.,<span class="w"> </span><span class="m">5</span>.<span class="o">]])</span>
</code></pre></div></p>
<p>有一个相似的上下文管理器 <code>torch.enable_grad()</code>，用于在自动微分尚未开启时开启自动微分。它也可以用作装饰器。</p>
<p>最后，您可能有一个需要梯度跟踪的tensor，但是您想要一个不需要梯度跟踪的副本。为此，我们可以使用 <code>Tensor</code> 的 <code>detach()</code> 方法——它会创建一个从计算历史中分离出来的tensor副本：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a>
<a id="__codelineno-32-4" name="__codelineno-32-4" href="#__codelineno-32-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-32-5" name="__codelineno-32-5" href="#__codelineno-32-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a>tensor<span class="o">([</span><span class="m">0</span>.0670,<span class="w"> </span><span class="m">0</span>.3890,<span class="w"> </span><span class="m">0</span>.7264,<span class="w"> </span><span class="m">0</span>.3559,<span class="w"> </span><span class="m">0</span>.6584<span class="o">]</span>,<span class="w"> </span><span class="nv">requires_grad</span><span class="o">=</span>True<span class="o">)</span>
<a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a>tensor<span class="o">([</span><span class="m">0</span>.0670,<span class="w"> </span><span class="m">0</span>.3890,<span class="w"> </span><span class="m">0</span>.7264,<span class="w"> </span><span class="m">0</span>.3559,<span class="w"> </span><span class="m">0</span>.6584<span class="o">])</span>
</code></pre></div></p>
<p>当我们想要画些tensor时，我们就这样做了。这是因为 <code>matplotlib</code> 期望一个 NumPy 数组作为输入，而 PyTorch tensor到 NumPy 数组的隐式转换对于 requires_grad=True 的tensor是不可用的。创建一个分离的副本能让我们继续前进。</p>
<h3 id="_6">自动微分和原地操作</h3>
<p>在本笔记本迄今为止的每个例子中，我们都使用变量来捕获计算的中间值。自动微分需要这些中间值计算梯度。<em>因此，在使用自动微分时，必须谨慎使用原地操作</em>。这样做可能会破坏您在 <code>backward()</code> 调用中计算导数所需的信息。如果您试图对需要自动微分的叶子变量进行就地操作，PyTorch 甚至会阻止您，如下所示。</p>
<div class="admonition note">
<p class="admonition-title">注意</p>
<p>能预料到，下面的代码单元格会抛出一个运行时错误。</p>
</div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a><span class="n">torch</span><span class="o">.</span><span class="n">sin_</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</code></pre></div>
<h2 id="_7">自动微分分析器</h2>
<p>自动微分可以详细跟踪每步计算，这样的计算历史记录与时序信息相结合，将成为一个方便的分析器，而自动微分已经内置了这一功能。下面是一个快速使用示例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a><span class="n">run_on_gpu</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
<a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<a id="__codelineno-35-5" name="__codelineno-35-5" href="#__codelineno-35-5"></a>    <span class="n">run_on_gpu</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-35-6" name="__codelineno-35-6" href="#__codelineno-35-6"></a>
<a id="__codelineno-35-7" name="__codelineno-35-7" href="#__codelineno-35-7"></a><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-35-8" name="__codelineno-35-8" href="#__codelineno-35-8"></a><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-35-9" name="__codelineno-35-9" href="#__codelineno-35-9"></a><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-35-10" name="__codelineno-35-10" href="#__codelineno-35-10"></a>
<a id="__codelineno-35-11" name="__codelineno-35-11" href="#__codelineno-35-11"></a><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">use_cuda</span><span class="o">=</span><span class="n">run_on_gpu</span><span class="p">)</span> <span class="k">as</span> <span class="n">prf</span><span class="p">:</span>
<a id="__codelineno-35-12" name="__codelineno-35-12" href="#__codelineno-35-12"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
<a id="__codelineno-35-13" name="__codelineno-35-13" href="#__codelineno-35-13"></a>        <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span> <span class="o">/</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span>
<a id="__codelineno-35-14" name="__codelineno-35-14" href="#__codelineno-35-14"></a>
<a id="__codelineno-35-15" name="__codelineno-35-15" href="#__codelineno-35-15"></a><span class="nb">print</span><span class="p">(</span><span class="n">prf</span><span class="o">.</span><span class="n">key_averages</span><span class="p">()</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">sort_by</span><span class="o">=</span><span class="s1">&#39;self_cpu_time_total&#39;</span><span class="p">))</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a>-------------------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------
<a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a><span class="w">                     </span>Name<span class="w">    </span>Self<span class="w"> </span>CPU<span class="w"> </span>%<span class="w">      </span>Self<span class="w"> </span>CPU<span class="w">   </span>CPU<span class="w"> </span>total<span class="w"> </span>%<span class="w">     </span>CPU<span class="w"> </span>total<span class="w">  </span>CPU<span class="w"> </span><span class="nb">time</span><span class="w"> </span>avg<span class="w">     </span>Self<span class="w"> </span>CUDA<span class="w">   </span>Self<span class="w"> </span>CUDA<span class="w"> </span>%<span class="w">    </span>CUDA<span class="w"> </span>total<span class="w">  </span>CUDA<span class="w"> </span><span class="nb">time</span><span class="w"> </span>avg<span class="w">    </span><span class="c1"># of Calls</span>
<a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a>-------------------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------
<a id="__codelineno-36-4" name="__codelineno-36-4" href="#__codelineno-36-4"></a><span class="w">                </span>aten::div<span class="w">        </span><span class="m">51</span>.16%<span class="w">       </span><span class="m">6</span>.308ms<span class="w">        </span><span class="m">51</span>.16%<span class="w">       </span><span class="m">6</span>.308ms<span class="w">       </span><span class="m">6</span>.308us<span class="w">      </span><span class="m">16</span>.511ms<span class="w">        </span><span class="m">50</span>.67%<span class="w">      </span><span class="m">16</span>.511ms<span class="w">      </span><span class="m">16</span>.511us<span class="w">          </span><span class="m">1000</span>
<a id="__codelineno-36-5" name="__codelineno-36-5" href="#__codelineno-36-5"></a><span class="w">                </span>aten::mul<span class="w">        </span><span class="m">48</span>.67%<span class="w">       </span><span class="m">6</span>.001ms<span class="w">        </span><span class="m">48</span>.67%<span class="w">       </span><span class="m">6</span>.001ms<span class="w">       </span><span class="m">6</span>.001us<span class="w">      </span><span class="m">16</span>.072ms<span class="w">        </span><span class="m">49</span>.33%<span class="w">      </span><span class="m">16</span>.072ms<span class="w">      </span><span class="m">16</span>.072us<span class="w">          </span><span class="m">1000</span>
<a id="__codelineno-36-6" name="__codelineno-36-6" href="#__codelineno-36-6"></a><span class="w">    </span>cudaDeviceSynchronize<span class="w">         </span><span class="m">0</span>.18%<span class="w">      </span><span class="m">22</span>.000us<span class="w">         </span><span class="m">0</span>.18%<span class="w">      </span><span class="m">22</span>.000us<span class="w">      </span><span class="m">22</span>.000us<span class="w">       </span><span class="m">0</span>.000us<span class="w">         </span><span class="m">0</span>.00%<span class="w">       </span><span class="m">0</span>.000us<span class="w">       </span><span class="m">0</span>.000us<span class="w">             </span><span class="m">1</span>
<a id="__codelineno-36-7" name="__codelineno-36-7" href="#__codelineno-36-7"></a>-------------------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------<span class="w">  </span>------------
<a id="__codelineno-36-8" name="__codelineno-36-8" href="#__codelineno-36-8"></a>Self<span class="w"> </span>CPU<span class="w"> </span><span class="nb">time</span><span class="w"> </span>total:<span class="w"> </span><span class="m">12</span>.331ms
<a id="__codelineno-36-9" name="__codelineno-36-9" href="#__codelineno-36-9"></a>Self<span class="w"> </span>CUDA<span class="w"> </span><span class="nb">time</span><span class="w"> </span>total:<span class="w"> </span><span class="m">32</span>.583ms
</code></pre></div></p>
<p>分析器还可以标注代码的各个子块，按输入tensor形状细分数据，并将数据导出为 Chrome 浏览器跟踪工具文件。有关 API 的详细信息，请参阅<a href="https://pytorch.org/docs/stable/autograd.html#profiler">文档</a>。</p>
<h2 id="api">进阶主题：更多的自动微分细节和高级 API</h2>
<p>如果您有一个 <code>n</code> 维输入和 <code>m</code> 维输出的函数，<span class="arithmatex">\(\vec{y}=f(\vec{x})\)</span>，完整梯度是各输出关于各输入的导数矩阵，称为 Jacobian：</p>
<div class="arithmatex">\[
J=\begin{pmatrix}
    \frac{\partial y_1}{\partial x_1} &amp; \cdots &amp; \frac{\partial y_1}{\partial x_n} \\
    \vdots &amp; \ddots &amp; \vdots \\
    \frac{\partial y_m}{\partial x_1} &amp;  \cdots &amp; \frac{\partial y_m}{\partial x_n}
\end{pmatrix}
\]</div>
<p>如果您有第二个函数，<span class="arithmatex">\(l=g(\vec{y})\)</span>，它接受 <code>m</code> 维输入(即与上述输出维度相同)并返回标量输出，那么您可以用列向量 <span class="arithmatex">\(v=\begin{pmatrix}\frac{\partial l}{\partial y_1} &amp; \cdots &amp; \frac{\partial l}{\partial y_m}\end{pmatrix}^T\)</span> 来表示它相对于 <span class="arithmatex">\(\vec{y}\)</span> 的梯度——这实际上只是一个单列 Jacobian 。</p>
<p>更具体地说，想象一下，第一个函数是您的 PyTorch 模型(可能有许多输入输出)，第二个函数是一个损失函数(模型的输出作为输入，损失值作为标量输出)。</p>
<p>如果将第一个函数的 Jacobian 矩阵乘以第二个函数的梯度，然后应用链式法则，就可以得到：</p>
<div class="arithmatex">\[
J^T \cdot b=\begin{pmatrix}
    \frac{\partial y_1}{\partial x_1} &amp; \cdots &amp; \frac{\partial y_m}{\partial x_1} \\
    \vdots &amp; \ddots &amp; \vdots \\
    \frac{\partial y_1}{\partial x_n} &amp;  \cdots &amp; \frac{\partial y_m}{\partial x_n}
\end{pmatrix} \begin{pmatrix}
    \frac{\partial l}{\partial y_1} \\
    \vdots \\
    \frac{\partial l}{\partial y_m} \\
\end{pmatrix} = \begin{pmatrix}
    \frac{\partial l}{\partial x_1} \\
    \vdots \\
    \frac{\partial l}{\partial x_n} \\
\end{pmatrix}
\]</div>
<p>请注意，您也能使用等效的操作 <span class="arithmatex">\(v^T \cdot J\)</span>，然后得到一个行向量。</p>
<p>由此得到的列向量就是 <em>第二个函数相对于第一个函数输入的梯度</em>——或者说，在我们的模型和损失函数中，损失相对于模型输入的梯度。</p>
<p><strong><code>torch.autograd</code> 是计算这些乘积的引擎</strong>，我们就是这样在后向传递过程中累积学习权重的梯度的。</p>
<p>因此，<code>backward()</code> 调用也可以接受一个可选的向量输入。该向量代表一组tensor上的梯度，并与前面自动微分跟踪tensor的 Jacobian 相乘。让我们用一个小向量举个具体例子：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-37-2" name="__codelineno-37-2" href="#__codelineno-37-2"></a>
<a id="__codelineno-37-3" name="__codelineno-37-3" href="#__codelineno-37-3"></a><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>
<a id="__codelineno-37-4" name="__codelineno-37-4" href="#__codelineno-37-4"></a><span class="k">while</span> <span class="n">y</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>
<a id="__codelineno-37-5" name="__codelineno-37-5" href="#__codelineno-37-5"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="mi">2</span>
<a id="__codelineno-37-6" name="__codelineno-37-6" href="#__codelineno-37-6"></a>
<a id="__codelineno-37-7" name="__codelineno-37-7" href="#__codelineno-37-7"></a><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a>tensor<span class="o">([</span><span class="w">  </span><span class="m">299</span>.4868,<span class="w">   </span><span class="m">425</span>.4009,<span class="w"> </span>-1082.9885<span class="o">]</span>,<span class="w"> </span><span class="nv">grad_fn</span><span class="o">=</span>&lt;MulBackward0&gt;<span class="o">)</span>
</code></pre></div></p>
<p>如果我们现在尝试调用 <code>y.backward()</code>，会出现运行时错误，并提示只能对标量输出 <em>隐式</em> 计算梯度。对于多维输出，自动微分希望我们提供这三个输出的梯度，以便能与 Jacobian 相乘：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span> <span class="c1"># stand-in for gradients</span>
<a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a>
<a id="__codelineno-39-4" name="__codelineno-39-4" href="#__codelineno-39-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a>tensor<span class="o">([</span><span class="m">1</span>.0240e+02,<span class="w"> </span><span class="m">1</span>.0240e+03,<span class="w"> </span><span class="m">1</span>.0240e-01<span class="o">])</span>
</code></pre></div></p>
<p>(请注意，输出梯度都与 2 的幂次有关——这与重复的倍增操作是一致的。)</p>
<h3 id="api_1">高级 API</h3>
<p>自动微分有一个 API 能让您直接访问重要的微分矩阵和向量操作。特别是，它允许您计算特定输入的特定函数的 Jacobian 矩阵和 <em>Hessian</em> 矩阵。( Hessian 矩阵与 Jacobian 矩阵类似，但表达的是所有部分 <em>二阶</em> 导数)。它还提供了与这些矩阵进行向量乘积的方法。</p>
<p>让我们以一个简单函数的 Jacobian 为例，对 2 个单元素输入进行评估：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">exp_adder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<a id="__codelineno-41-2" name="__codelineno-41-2" href="#__codelineno-41-2"></a>    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">y</span>
<a id="__codelineno-41-3" name="__codelineno-41-3" href="#__codelineno-41-3"></a>
<a id="__codelineno-41-4" name="__codelineno-41-4" href="#__codelineno-41-4"></a><span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># arguments for the function</span>
<a id="__codelineno-41-5" name="__codelineno-41-5" href="#__codelineno-41-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<a id="__codelineno-41-6" name="__codelineno-41-6" href="#__codelineno-41-6"></a><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">jacobian</span><span class="p">(</span><span class="n">exp_adder</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a><span class="o">(</span>tensor<span class="o">([</span><span class="m">0</span>.7212<span class="o">])</span>,<span class="w"> </span>tensor<span class="o">([</span><span class="m">0</span>.2079<span class="o">]))</span>
<a id="__codelineno-42-2" name="__codelineno-42-2" href="#__codelineno-42-2"></a>
<a id="__codelineno-42-3" name="__codelineno-42-3" href="#__codelineno-42-3"></a><span class="o">(</span>tensor<span class="o">([[</span><span class="m">4</span>.1137<span class="o">]])</span>,<span class="w"> </span>tensor<span class="o">([[</span><span class="m">3</span>.<span class="o">]]))</span>
</code></pre></div></p>
<p>如果您仔细看，第一个输出应该等于 <span class="arithmatex">\(2e^x\)</span>(因为 <span class="arithmatex">\(e^x\)</span> 的导数是 <span class="arithmatex">\(e^x\)</span>)，第二个值应该是 3。</p>
<p>当然，您也可以用高阶tensor来实现这一点：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a><span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span> <span class="c1"># arguments for the function</span>
<a id="__codelineno-43-2" name="__codelineno-43-2" href="#__codelineno-43-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<a id="__codelineno-43-3" name="__codelineno-43-3" href="#__codelineno-43-3"></a><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">jacobian</span><span class="p">(</span><span class="n">exp_adder</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a><span class="o">(</span>tensor<span class="o">([</span><span class="m">0</span>.2080,<span class="w"> </span><span class="m">0</span>.2604,<span class="w"> </span><span class="m">0</span>.4415<span class="o">])</span>,<span class="w"> </span>tensor<span class="o">([</span><span class="m">0</span>.5220,<span class="w"> </span><span class="m">0</span>.9867,<span class="w"> </span><span class="m">0</span>.4288<span class="o">]))</span>
<a id="__codelineno-44-2" name="__codelineno-44-2" href="#__codelineno-44-2"></a>
<a id="__codelineno-44-3" name="__codelineno-44-3" href="#__codelineno-44-3"></a><span class="o">(</span>tensor<span class="o">([[</span><span class="m">2</span>.4623,<span class="w"> </span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.0000<span class="o">]</span>,
<a id="__codelineno-44-4" name="__codelineno-44-4" href="#__codelineno-44-4"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">2</span>.5950,<span class="w"> </span><span class="m">0</span>.0000<span class="o">]</span>,
<a id="__codelineno-44-5" name="__codelineno-44-5" href="#__codelineno-44-5"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">0</span>.0000,<span class="w"> </span><span class="m">3</span>.1102<span class="o">]])</span>,<span class="w"> </span>tensor<span class="o">([[</span><span class="m">3</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>,
<a id="__codelineno-44-6" name="__codelineno-44-6" href="#__codelineno-44-6"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">3</span>.,<span class="w"> </span><span class="m">0</span>.<span class="o">]</span>,
<a id="__codelineno-44-7" name="__codelineno-44-7" href="#__codelineno-44-7"></a><span class="w">        </span><span class="o">[</span><span class="m">0</span>.,<span class="w"> </span><span class="m">0</span>.,<span class="w"> </span><span class="m">3</span>.<span class="o">]]))</span>
</code></pre></div></p>
<p><code>torch.autograd.functional.hessian()</code>方法的工作原理与此相同(假设函数是二次微分的)，但返回的是所有二阶导数的矩阵。</p>
<p>如果您提供向量，还有一个函数可以直接计算向量与 Jacobian 的积：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">do_some_doubling</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<a id="__codelineno-45-2" name="__codelineno-45-2" href="#__codelineno-45-2"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>
<a id="__codelineno-45-3" name="__codelineno-45-3" href="#__codelineno-45-3"></a>    <span class="k">while</span> <span class="n">y</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>
<a id="__codelineno-45-4" name="__codelineno-45-4" href="#__codelineno-45-4"></a>        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="mi">2</span>
<a id="__codelineno-45-5" name="__codelineno-45-5" href="#__codelineno-45-5"></a>    <span class="k">return</span> <span class="n">y</span>
<a id="__codelineno-45-6" name="__codelineno-45-6" href="#__codelineno-45-6"></a>
<a id="__codelineno-45-7" name="__codelineno-45-7" href="#__codelineno-45-7"></a><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-45-8" name="__codelineno-45-8" href="#__codelineno-45-8"></a><span class="n">my_gradients</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">])</span>
<a id="__codelineno-45-9" name="__codelineno-45-9" href="#__codelineno-45-9"></a><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">vjp</span><span class="p">(</span><span class="n">do_some_doubling</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">my_gradients</span><span class="p">)</span>
</code></pre></div>
<p>输出：
<div class="highlight"><pre><span></span><code><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a><span class="o">(</span>tensor<span class="o">([</span>-665.7186,<span class="w"> </span>-866.7054,<span class="w">  </span>-58.4194<span class="o">])</span>,<span class="w"> </span>tensor<span class="o">([</span><span class="m">1</span>.0240e+02,<span class="w"> </span><span class="m">1</span>.0240e+03,<span class="w"> </span><span class="m">1</span>.0240e-01<span class="o">]))</span>
</code></pre></div></p>
<p><code>torch.autograd.functional.jvp()</code> 方法执行与 <code>vjp()</code> 相同的矩阵乘法，但操作数相反。<code>vhp()</code> 和 <code>hvp()</code> 方法也是对向量和 Hessian 乘积执行相同的操作。</p>
<p>更多相关信息，请参阅<a href="https://pytorch.org/docs/stable/autograd.html#functional-higher-level-api">功能 API 文档</a>。</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../tensors_deeper_tutorial/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Introduction to PyTorch Tensors">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Introduction to PyTorch Tensors
              </div>
            </div>
          </a>
        
        
          
          <a href="../modelsyt_tutorial/" class="md-footer__link md-footer__link--next" aria-label="Next: Building Models with PyTorch">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Building Models with PyTorch
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>