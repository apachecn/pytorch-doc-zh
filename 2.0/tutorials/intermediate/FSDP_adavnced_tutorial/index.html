
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/2.0/tutorials/intermediate/FSDP_adavnced_tutorial/">
      
      
        <link rel="prev" href="../FSDP_tutorial/">
      
      
        <link rel="next" href="../TP_tutorial/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>Advanced Model Training with Fully Sharded Data Parallel (FSDP) - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.d7758b05.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.75 1.75 0 0 1 1 7.775m1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2"/></svg>');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.5 1.75v11.5c0 .138.112.25.25.25h3.17a.75.75 0 0 1 0 1.5H2.75A1.75 1.75 0 0 1 1 13.25V1.75C1 .784 1.784 0 2.75 0h8.5C12.216 0 13 .784 13 1.75v7.736a.75.75 0 0 1-1.5 0V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25m13.274 9.537zl-4.557 4.45a.75.75 0 0 1-1.055-.008l-1.943-1.95a.75.75 0 0 1 1.062-1.058l1.419 1.425 4.026-3.932a.75.75 0 1 1 1.048 1.074M4.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5M4 7.75A.75.75 0 0 1 4.75 7h2a.75.75 0 0 1 0 1.5h-2A.75.75 0 0 1 4 7.75"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75M8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2"/></svg>');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M3.499.75a.75.75 0 0 1 1.5 0v.996C5.9 2.903 6.793 3.65 7.662 4.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873 10.794-.045 12.622.26 14.408.558 16 1.94 16 4.25c0 1.278-.954 2.575-2.44 2.734l.146.508.065.22c.203.701.412 1.455.476 2.226.142 1.707-.4 3.03-1.487 3.898C11.714 14.671 10.27 15 8.75 15h-6a.75.75 0 0 1 0-1.5h1.376a4.5 4.5 0 0 1-.563-1.191 3.84 3.84 0 0 1-.05-2.063 4.65 4.65 0 0 1-2.025-.293.75.75 0 0 1 .525-1.406c1.357.507 2.376-.006 2.698-.318l.009-.01a.747.747 0 0 1 1.06 0 .75.75 0 0 1-.012 1.074c-.912.92-.992 1.835-.768 2.586.221.74.745 1.337 1.196 1.621H8.75c1.343 0 2.398-.296 3.074-.836.635-.507 1.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4 2.4 0 0 1-.507-.441 3.1 3.1 0 0 1-.633-1.248.75.75 0 0 1 1.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738 0 1.25-.615 1.25-1.25 0-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706 1.345-.46.92-.27 1.774.019 3.062l.042.19.01.05c.348.443.666.949.94 1.553a.75.75 0 1 1-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7 5.527c-.814-.68-1.75-1.462-2.692-2.619a3.7 3.7 0 0 0-1.023.88c-.406.495-.663 1.036-.722 1.508.116.122.306.21.591.239.388.038.797-.06 1.032-.19a.75.75 0 0 1 .728 1.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75 5.677V5.5c0-.984.48-1.94 1.077-2.664.46-.559 1.05-1.055 1.673-1.353z"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0"/></svg>');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.92 6.085h.001a.749.749 0 1 1-1.342-.67c.169-.339.436-.701.849-.977C6.845 4.16 7.369 4 8 4a2.76 2.76 0 0 1 1.637.525c.503.377.863.965.863 1.725 0 .448-.115.83-.329 1.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6 6 0 0 0-.26.16 1 1 0 0 0-.276.245.75.75 0 0 1-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1 1 0 0 0 .277-.245C8.96 6.514 9 6.427 9 6.25a.61.61 0 0 0-.262-.525A1.27 1.27 0 0 0 8 5.5c-.369 0-.595.09-.74.187a1 1 0 0 0-.34.398M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.344 2.343za8 8 0 0 1 11.314 11.314A8.002 8.002 0 0 1 .234 10.089a8 8 0 0 1 2.11-7.746m1.06 10.253a6.5 6.5 0 1 0 9.108-9.275 6.5 6.5 0 0 0-9.108 9.275M6.03 4.97 8 6.94l1.97-1.97a.749.749 0 0 1 1.275.326.75.75 0 0 1-.215.734L9.06 8l1.97 1.97a.749.749 0 0 1-.326 1.275.75.75 0 0 1-.734-.215L8 9.06l-1.97 1.97a.749.749 0 0 1-1.275-.326.75.75 0 0 1 .215-.734L6.94 8 4.97 6.03a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018"/></svg>');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M9.504.43a1.516 1.516 0 0 1 2.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 0 1-.871.354h-.302a1.25 1.25 0 0 1-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004zm1.047 1.074L3.286 8.571A.25.25 0 0 0 3.462 9H6.75a.75.75 0 0 1 .694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0 0 12.538 7H9.25a.75.75 0 0 1-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005 0-.009.004"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M5 5.782V2.5h-.25a.75.75 0 0 1 0-1.5h6.5a.75.75 0 0 1 0 1.5H11v3.282l3.666 5.76C15.619 13.04 14.543 15 12.767 15H3.233c-1.776 0-2.852-1.96-1.899-3.458Zm-2.4 6.565a.75.75 0 0 0 .633 1.153h9.534a.75.75 0 0 0 .633-1.153L12.225 10.5h-8.45ZM9.5 2.5h-3V6c0 .143-.04.283-.117.403L4.73 9h6.54L9.617 6.403A.75.75 0 0 1 9.5 6Z"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 2.5h10.5a.75.75 0 0 1 0 1.5H1.75a.75.75 0 0 1 0-1.5m4 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5m0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5M2.5 7.75v6a.75.75 0 0 1-1.5 0v-6a.75.75 0 0 1 1.5 0"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#fsdp" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.dafeiyang.cn/images/logo/logo_green.webp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Advanced Model Training with Fully Sharded Data Parallel (FSDP)
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.dafeiyang.cn/images/logo/logo_green.webp" alt="logo">

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 新特性
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 新特性
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.13
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.12
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.11
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.10
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.8
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.7
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 2.x 中文文档 & 教程
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 2.x 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch Recipes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch Recipes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../recipes/recipes_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Recipes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prototype/prototype_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Prototype Recipes
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learn the Basics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/quickstart_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/tensorqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/data_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets & DataLoaders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/transforms_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transforms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/buildmodel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build the Neural Network
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/autogradqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Differentiation with torch.autograd
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/optimization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Model Parameters
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/basics/saveloadrun_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Save and Load the Model
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" >
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch on YouTube
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch on YouTube
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch - YouTube Series
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/introyt1_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/tensors_deeper_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch Tensors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/autogradyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Fundamentals of Autograd
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/modelsyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Models with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/tensorboardyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch TensorBoard Support
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/trainingyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/introyt/captumyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Understanding with Captum
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_4" >
        
          
          <label class="md-nav__link" for="__nav_3_1_4" id="__nav_3_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Learning PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_4">
            <span class="md-nav__icon md-icon"></span>
            Learning PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning with PyTorch: A 60 Minute Blitz
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning PyTorch with Examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorboard_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualizing Models, Data, and Training with TensorBoard
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_5" >
        
          
          <label class="md-nav__link" for="__nav_3_1_5" id="__nav_3_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Image and Video
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_5">
            <span class="md-nav__icon md-icon"></span>
            Image and Video
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision Object Detection Finetuning Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transfer Learning for Computer Vision Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adversarial Example Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial Transformer Networks Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tiatoolbox_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Whole Slide Image Classification Using PyTorch and TIAToolbox
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_6" >
        
          
          <label class="md-nav__link" for="__nav_3_1_6" id="__nav_3_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Audio
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_6">
            <span class="md-nav__icon md-icon"></span>
            Audio
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_io_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio I/O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_resampling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Resampling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_data_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Data Augmentation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_feature_extractions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Extractions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_feature_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Augmentation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/audio_datasets_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Datasets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speech_recognition_pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speech Recognition with Wav2Vec2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../text_to_speech_with_torchaudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-speech with Tacotron2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../forced_alignment_with_torchaudio_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forced Alignment with Wav2Vec2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_7" >
        
          
          <label class="md-nav__link" for="__nav_3_1_7" id="__nav_3_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_7">
            <span class="md-nav__icon md-icon"></span>
            Text
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/bettertransformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fast Transformer Inference with Better Transformer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Classifying Names with a Character-Level RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Generating Names with a Character-Level RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Translation with a Sequence to Sequence Network and Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/text_sentiment_ngrams_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text classification with the torchtext library
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/translation_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Translation with nn.Transformer and torchtext
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/torchtext_custom_dataset_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocess custom text dataset using Torchtext
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_8" >
        
          
          <label class="md-nav__link" for="__nav_3_1_8" id="__nav_3_1_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Backends
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_8">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_9" >
        
          
          <label class="md-nav__link" for="__nav_3_1_9" id="__nav_3_1_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_9">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reinforcement_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (PPO) with TorchRL Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mario_rl_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a Mario-playing RL Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/pendulum/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pendulum: Writing your environment and transforms with TorchRL
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_10" >
        
          
          <label class="md-nav__link" for="__nav_3_1_10" id="__nav_3_1_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deploying PyTorch Models in Production
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_10">
            <span class="md-nav__icon md-icon"></span>
            Deploying PyTorch Models in Production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../flask_rest_api_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying PyTorch in Python via a REST API with Flask
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/Intro_to_TorchScript_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchScript
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loading a TorchScript Model in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/super_resolution_with_onnxruntime/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../realtime_rpi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Real Time Inference on Raspberry Pi 4 (30 fps!)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_11" >
        
          
          <label class="md-nav__link" for="__nav_3_1_11" id="__nav_3_1_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Profiling PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_11">
            <span class="md-nav__icon md-icon"></span>
            Profiling PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/hta_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Holistic Trace Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/hta_trace_diff_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Trace Diff using Holistic Trace Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_12" >
        
          
          <label class="md-nav__link" for="__nav_3_1_12" id="__nav_3_1_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code Transforms with FX
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_12">
            <span class="md-nav__icon md-icon"></span>
            Code Transforms with FX
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fx_conv_bn_fuser/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Convolution/Batch Norm fuser in FX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fx_profiling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Simple CPU Performance Profiler with FX
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_13" >
        
          
          <label class="md-nav__link" for="__nav_3_1_13" id="__nav_3_1_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Frontend APIs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_13">
            <span class="md-nav__icon md-icon"></span>
            Frontend APIs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../memory_format_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Channels Last Memory Format in PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../forward_ad_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forward-mode Automatic Differentiation (Beta)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jacobians_hessians/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Jacobians, Hessians, hvp, vhp, and more: composing function transforms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ensembling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model ensembling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../per_sample_grads/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Per-sample-gradients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the PyTorch C++ Frontend
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/torch-script-parallelism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Parallelism in TorchScript
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/cpp_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd in C++ Frontend
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_14" >
        
          
          <label class="md-nav__link" for="__nav_3_1_14" id="__nav_3_1_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Extending PyTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_14">
            <span class="md-nav__icon md-icon"></span>
            Extending PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../custom_function_double_backward_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Double Backward with Custom Functions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../custom_function_conv_bn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fusing Convolution and Batch Norm using Custom Function
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/torch_script_custom_classes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Classes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Registering a Dispatched Operator in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/extend_dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending dispatcher for a new backend in C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/privateuseone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Facilitating New Backend Integration by PrivateUse1
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_15" >
        
          
          <label class="md-nav__link" for="__nav_3_1_15" id="__nav_3_1_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Optimization
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_15">
            <span class="md-nav__icon md-icon"></span>
            Model Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorboard_profiler_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Profiler With TensorBoard
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/hyperparameter_tuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter tuning with Ray Tune
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../parametrizations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametrizations Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pruning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pruning Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/dynamic_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on an LSTM Word Language Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamic_quantization_bert_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on BERT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quantized_transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Quantized Transfer Learning for Computer Vision Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/static_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Static Quantization with Eager Mode in PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchserve_with_ipex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchserve_with_ipex_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles (Part 2)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nvfuser_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started - Accelerate Your Scripts with nvFuser
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ax_multiobjective_nas_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Objective NAS with Ax
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_compile_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to torch.compile
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inductor_debug_cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inductor CPU backend debugging and profiling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/knowledge_distillation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge Distillation Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_16" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1_16" id="__nav_3_1_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Parallel and Distributed Training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_16_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_16">
            <span class="md-nav__icon md-icon"></span>
            Parallel and Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributed/home/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed and Parallel Training Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/dist_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Distributed Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/ddp_series_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Data Parallel in PyTorch - Video Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single-Machine Model Parallel Best Practices
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed Data Parallel
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../FSDP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Fully Sharded Data Parallel(FSDP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Advanced Model Training with Fully Sharded Data Parallel (FSDP)
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Advanced Model Training with Fully Sharded Data Parallel (FSDP)
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#fsdp_1" class="md-nav__link">
    <span class="md-ellipsis">
      本教程中的 FSDP 功能 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fsdp_2" class="md-nav__link">
    <span class="md-ellipsis">
      回顾 FSDP 的工作原理 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hf-t5" class="md-nav__link">
    <span class="md-ellipsis">
      微调 HF T5 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      变压器包装政策 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      混合精度 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fsdp_3" class="md-nav__link">
    <span class="md-ellipsis">
      正在设备上初始化 FSDP 模型 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      分片策略 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      向后预取 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rank0-cpu" class="md-nav__link">
    <span class="md-ellipsis">
      模型检查点保存，通过流式传输到 Rank0 CPU ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      摘要 ¶
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../TP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Large Scale Transformer model training with Tensor Parallel (TP)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../process_group_cpp_extension_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Process Group Backends Using Cpp Extensions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rpc_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rpc_param_server_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing a Parameter Server Using Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dist_pipeline_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Pipeline Parallelism Using RPC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rpc_async_execution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing Batch RPC Processing Using Asynchronous Executions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/rpc_ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Combining Distributed DataParallel with Distributed RPC Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/ddp_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Distributed Data Parallel and Pipeline Parallelism
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/generic_join/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Training with Uneven Inputs Using the Join Context Manager
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_17" >
        
          
          <label class="md-nav__link" for="__nav_3_1_17" id="__nav_3_1_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Edge with ExecuTorch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_17">
            <span class="md-nav__icon md-icon"></span>
            Edge with ExecuTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exporting to ExecuTorch Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/running-a-model-cpp-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Running an ExecuTorch Model in C++ Tutorial
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/tutorials/sdk-integration-tutorial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the ExecuTorch SDK to Profile a Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/demo-apps-ios.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building an ExecuTorch iOS Demo App
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/demo-apps-android.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building an ExecuTorch Android Demo App
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/executorch/stable/examples-end-to-end-to-lower-model-to-delegate.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lowering a Model as a Delegate
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_18" >
        
          
          <label class="md-nav__link" for="__nav_3_1_18" id="__nav_3_1_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Recommendation Systems
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_18">
            <span class="md-nav__icon md-icon"></span>
            Recommendation Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchrec_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchRec
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../advanced/sharding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exploring TorchRec sharding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_19" >
        
          
          <label class="md-nav__link" for="__nav_3_1_19" id="__nav_3_1_19_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Multimodality
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_19">
            <span class="md-nav__icon md-icon"></span>
            Multimodality
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../beginner/flava_finetuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchMultimodal Tutorial: Finetuning FLAVA
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/docs/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pytorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/audio/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torchaudio
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/text/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchText
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/vision/stable/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torcharrow/beta/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchArrow
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torchrec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchRec
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/serve/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchServe
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/torchx/latest/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch.org/xla/release/2.3/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch on XLA Devices
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.7 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.4 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.0 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.4 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.3 中文文档 & 教程
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.2 中文文档
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../contrib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贡献指南
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于我们
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/join" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加入我们
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中文资源合集
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#fsdp_1" class="md-nav__link">
    <span class="md-ellipsis">
      本教程中的 FSDP 功能 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fsdp_2" class="md-nav__link">
    <span class="md-ellipsis">
      回顾 FSDP 的工作原理 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hf-t5" class="md-nav__link">
    <span class="md-ellipsis">
      微调 HF T5 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      变压器包装政策 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      混合精度 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fsdp_3" class="md-nav__link">
    <span class="md-ellipsis">
      正在设备上初始化 FSDP 模型 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      分片策略 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      向后预取 ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rank0-cpu" class="md-nav__link">
    <span class="md-ellipsis">
      模型检查点保存，通过流式传输到 Rank0 CPU ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      摘要 ¶
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/2.0/tutorials/intermediate/FSDP_adavnced_tutorial.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/2.0/tutorials/intermediate/FSDP_adavnced_tutorial.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="fsdp">使用完全分片数据并行 (FSDP) 进行高级模型训练 <a href="#advanced-model-training-with-complete-sharded-data-parallel-fsdp" title="此标题的永久链接">¶</a></h1>
<blockquote>
<p>译者：<a href="https://github.com/jiangzhonglian">片刻小哥哥</a></p>
<p>项目地址：<a href="https://pytorch.apachecn.org/2.0/tutorials/intermediate/FSDP_adavnced_tutorial">https://pytorch.apachecn.org/2.0/tutorials/intermediate/FSDP_adavnced_tutorial</a></p>
<p>原始地址：<a href="https://pytorch.org/tutorials/intermediate/FSDP_adavnced_tutorial.html">https://pytorch.org/tutorials/intermediate/FSDP_adavnced_tutorial.html</a></p>
</blockquote>
<p><strong>作者</strong> 
 :
 <a href="https://github.com/HamidShojanazeri">Hamid Shojanazeri</a> 
 ,
 <a href="https://github.com/lessw2020">Less
Wright</a> 
 ,
 <a href="https://github.com/rohan-varma/">Rohan Varma</a> 
 ,
 <a href="https://github.com/zhaojuanmao">赵艳丽</a></p>
<p>本教程介绍了作为 PyTorch 1.12 版本一部分的完全分片数据并行 (FSDP) 的更多高级功能。要熟悉 FSDP，请参阅
<a href="https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html">FSDP 入门教程</a>
 。</p>
<p>在本教程中，我们将使用 FSDP 微调 HuggingFace (HF) T5 模型以进行文本
摘要作为工作示例。</p>
<p>该示例使用 Wikihow，为简单起见，我们将展示在具有 8 个 A100 GPU 的单节点 P4dn 实例上的训练。我们很快就会发布一篇关于多节点集群上的大规模 FSDP 训练的博文，请继续关注 PyTorch 媒体频道。</p>
<p>FSDP 是一个生产就绪的软件包，重点关注易用性、性能和
长期支持。 FSDP 的主要优点之一是减少每个 GPU 上的内存
占用空间。与 DDP 相比，这使得能够以较低的总内存来训练较大的模型，并利用计算和通信的重叠来高效地训练模型。
这种减少的内存压力可用于训练较大的模型或
增加批量大小，从而可能有助于整体训练吞吐量。您可以
在<a href="https://pytorch.org/blog/introducing-pytorch-filled-sharded-data-parallel-api/">此处</a>了解有关 PyTorch FSDP 的更多信息
 。</p>
<h2 id="fsdp_1">本教程中的 FSDP 功能 <a href="#fsdp-features-in-this-tutorial" title="永久链接到此标题">¶</a></h2>
<ul>
<li>变压器自动换行策略</li>
<li>混合精度</li>
<li>在设备上初始化 FSDP 模型</li>
<li>分片策略</li>
<li>向后预取</li>
<li>通过流式传输到 CPU 保存模型检查点</li>
</ul>
<h2 id="fsdp_2">回顾 FSDP 的工作原理 <a href="#recap-on-how-fsdp-works" title="永久链接到此标题">¶</a></h2>
<p>在高层 FDSP 的工作原理如下：</p>
<p><em>在构造函数中</em></p>
<ul>
<li>分片模型参数，每个等级只保留自己的分片</li>
</ul>
<p><em>前向传递</em></p>
<ul>
<li>运行</li>
</ul>
<p>all_gather</p>
<p>从所有级别收集所有分片，以恢复此 FSDP 单元的完整
参数 运行前向计算
* 丢弃它刚刚收集到的非拥有参数分片空闲内存</p>
<p><em>向后传递</em></p>
<ul>
<li>运行</li>
</ul>
<p>all_gather</p>
<p>以收集所有等级的所有分片，以恢复此 FSDP 单元中的完整参数
运行反向计算
* 丢弃非拥有的参数以释放内存。
 * 运行reduce_scatter来同步梯度</p>
<h2 id="hf-t5">微调 HF T5 <a href="#fine-tuning-hf-t5" title="固定链接到此标题">¶</a></h2>
<p>HF T5 预训练模型有四种不同的尺寸，从具有 6000 万个参数的小型模型到具有 110 亿个参数的 XXL 模型。在本教程中，我们演示了使用 WikiHow 数据集对带有 FSDP 的 T5 3B 进行微调以进行文本摘要。本教程的主要重点是
强调 FSDP 中的不同可用功能，这些功能有助于训练
超过 3B 参数的大型模型。此外，我们还介绍了基于 Transformer 的模型的特定功能。本教程的代码可在
 <a href="https://github.com/pytorch/examples/tree/main/distributed/FSDP/">Pytorch
示例</a> 中找到
 。</p>
<p><em>设置</em></p>
<p>1.1 安装 PyTorch Nightlies</p>
<p>我们将安装 PyTorch nightlies，因为一些功能(如激活
检查点)在 nightlies 中可用，并将在 1.12 之后的下一个 PyTorch
版本中添加。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>pip3 install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html
</code></pre></div>
<p>1.2 数据集设置</p>
<p>请创建</p>
<p>data</p>
<p>文件夹，从 <a href="https://ucsb.app.box.com/s/ap23l8gafpezf4tq3wapr6u8241zz358">wikihowAll.csv</a> 下载 WikiHow 数据集
 和
 <a href="https://ucsb.app.box.com/s/7yq601ijl1lzvlfu4rjdbbxforzd2oag">wikihowSep.cs</a> 
 ，
并将它们放在</p>
<p>data</p>
<p>文件夹中。我们将使用来自
 <a href="https://github.com/pytorch/examples/blob/main/distributed/FSDP/summarization_dataset.py">summarization_dataset</a>的wikihow数据集
。</p>
<p>接下来，我们将以下代码片段添加到 Python 脚本 “T5_training.py” 中。</p>
<p>注意</p>
<p>本教程的完整源代码可在 <a href="https://github.com/pytorch/examples/tree/main/distributed/FSDP/">PyTorch 示例</a> 中找到
 。</p>
<p>1.3 导入必要的包：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>import os
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>import argparse
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>import torch
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>import torch.nn as nn
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>import torch.nn.functional as F
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>import torch.optim as optim
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>from transformers import AutoTokenizer, GPT2TokenizerFast
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>from transformers import T5Tokenizer, T5ForConditionalGeneration
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>import functools
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>from torch.optim.lr_scheduler import StepLR
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>import torch.nn.functional as F
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>import torch.distributed as dist
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>import torch.multiprocessing as mp
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>from torch.nn.parallel import DistributedDataParallel as DDP
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>from torch.utils.data.distributed import DistributedSampler
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>from transformers.models.t5.modeling_t5 import T5Block
<a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>
<a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>from torch.distributed.algorithms._checkpoint.checkpoint_wrapper import (
<a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a> checkpoint_wrapper,
<a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a> CheckpointImpl,
<a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a> apply_activation_checkpointing_wrapper)
<a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>
<a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>from torch.distributed.fsdp import (
<a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>    FullyShardedDataParallel as FSDP,
<a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>    MixedPrecision,
<a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>    BackwardPrefetch,
<a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a>    ShardingStrategy,
<a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a>    FullStateDictConfig,
<a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a>    StateDictType,
<a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a>)
<a id="__codelineno-1-31" name="__codelineno-1-31" href="#__codelineno-1-31"></a>from torch.distributed.fsdp.wrap import (
<a id="__codelineno-1-32" name="__codelineno-1-32" href="#__codelineno-1-32"></a>    transformer_auto_wrap_policy,
<a id="__codelineno-1-33" name="__codelineno-1-33" href="#__codelineno-1-33"></a>    enable_wrap,
<a id="__codelineno-1-34" name="__codelineno-1-34" href="#__codelineno-1-34"></a>    wrap,
<a id="__codelineno-1-35" name="__codelineno-1-35" href="#__codelineno-1-35"></a>)
<a id="__codelineno-1-36" name="__codelineno-1-36" href="#__codelineno-1-36"></a>from functools import partial
<a id="__codelineno-1-37" name="__codelineno-1-37" href="#__codelineno-1-37"></a>from torch.utils.data import DataLoader
<a id="__codelineno-1-38" name="__codelineno-1-38" href="#__codelineno-1-38"></a>from pathlib import Path
<a id="__codelineno-1-39" name="__codelineno-1-39" href="#__codelineno-1-39"></a>from summarization_dataset import *
<a id="__codelineno-1-40" name="__codelineno-1-40" href="#__codelineno-1-40"></a>from transformers.models.t5.modeling_t5 import T5Block
<a id="__codelineno-1-41" name="__codelineno-1-41" href="#__codelineno-1-41"></a>from typing import Type
<a id="__codelineno-1-42" name="__codelineno-1-42" href="#__codelineno-1-42"></a>import time
<a id="__codelineno-1-43" name="__codelineno-1-43" href="#__codelineno-1-43"></a>import tqdm
<a id="__codelineno-1-44" name="__codelineno-1-44" href="#__codelineno-1-44"></a>from datetime import datetime
</code></pre></div>
<p>1.4 分布式训练设置。
这里我们使用两个辅助函数来初始化分布式
训练过程，然后在训练完成后进行清理。在本教程中，我们将使用 torch elastic，使用 <a href="https://pytorch.org/docs/stable/elastic/run.html">torchrun</a> 
 ，这将设置 
worker
 \ n 自动排名</p>
<p>和</p>
<p>WORLD_SIZE</p>
<p>。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>def setup():
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>    # initialize the process group
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>    dist.init_process_group(&quot;nccl&quot;)
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>def cleanup():
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    dist.destroy_process_group()
</code></pre></div>
<p>2.1 设置 HuggingFace T5 模型：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>def setup_model(model_name):
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>    model = T5ForConditionalGeneration.from_pretrained(model_name)
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>    tokenizer =  T5Tokenizer.from_pretrained(model_name)
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>    return model, tokenizer
</code></pre></div>
<p>我们还在此处添加了几个用于日期和格式化内存
指标的辅助函数。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>def get_date_of_run():
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a> &quot;&quot;&quot;create date and time for file save uniqueness
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a> example: 2022-05-07-08:31:12_PM&#39;
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a> &quot;&quot;&quot;
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>    date_of_run = datetime.now().strftime(&quot;%Y-%m-%d-%I:%M:%S_%p&quot;)
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>    print(f&quot;--&gt; current date and time of run = {date_of_run}&quot;)
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>    return date_of_run
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>def format_metrics_to_gb(item):
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a> &quot;&quot;&quot;quick function to format numbers to gigabyte and round to 4 digit precision&quot;&quot;&quot;
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>    metric_num = item / g_gigabyte
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>    metric_num = round(metric_num, ndigits=4)
<a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>    return metric_num
</code></pre></div>
<p>2.2 定义训练函数:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>def train(args, model, rank, world_size, train_loader, optimizer, epoch, sampler=None):
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>    model.train()
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>    local_rank = int(os.environ[&#39;LOCAL_RANK&#39;])
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>    fsdp_loss = torch.zeros(2).to(local_rank)
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>    if sampler:
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>        sampler.set_epoch(epoch)
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    if rank==0:
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>        inner_pbar = tqdm.tqdm(
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>            range(len(train_loader)), colour=&quot;blue&quot;, desc=&quot;r0 Training Epoch&quot;
<a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>        )
<a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>    for batch in train_loader:
<a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>        for key in batch.keys():
<a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>            batch[key] = batch[key].to(local_rank)
<a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>        optimizer.zero_grad()
<a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>        output = model(input_ids=batch[&quot;source_ids&quot;],attention_mask=batch[&quot;source_mask&quot;],labels=batch[&quot;target_ids&quot;] )
<a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a>        loss = output[&quot;loss&quot;]
<a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>        loss.backward()
<a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a>        optimizer.step()
<a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a>        fsdp_loss[0] += loss.item()
<a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a>        fsdp_loss[1] += len(batch)
<a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a>        if rank==0:
<a id="__codelineno-5-23" name="__codelineno-5-23" href="#__codelineno-5-23"></a>            inner_pbar.update(1)
<a id="__codelineno-5-24" name="__codelineno-5-24" href="#__codelineno-5-24"></a>
<a id="__codelineno-5-25" name="__codelineno-5-25" href="#__codelineno-5-25"></a>    dist.all_reduce(fsdp_loss, op=dist.ReduceOp.SUM)
<a id="__codelineno-5-26" name="__codelineno-5-26" href="#__codelineno-5-26"></a>    train_accuracy = fsdp_loss[0] / fsdp_loss[1]
<a id="__codelineno-5-27" name="__codelineno-5-27" href="#__codelineno-5-27"></a>
<a id="__codelineno-5-28" name="__codelineno-5-28" href="#__codelineno-5-28"></a>
<a id="__codelineno-5-29" name="__codelineno-5-29" href="#__codelineno-5-29"></a>    if rank == 0:
<a id="__codelineno-5-30" name="__codelineno-5-30" href="#__codelineno-5-30"></a>        inner_pbar.close()
<a id="__codelineno-5-31" name="__codelineno-5-31" href="#__codelineno-5-31"></a>        print(
<a id="__codelineno-5-32" name="__codelineno-5-32" href="#__codelineno-5-32"></a>                f&quot;Train Epoch: \t{epoch}, Loss: \t{train_accuracy:.4f}&quot;
<a id="__codelineno-5-33" name="__codelineno-5-33" href="#__codelineno-5-33"></a>            )
<a id="__codelineno-5-34" name="__codelineno-5-34" href="#__codelineno-5-34"></a>    return train_accuracy
</code></pre></div>
<p>2.3 定义验证函数:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>def validation(model, rank, world_size, val_loader):
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>    model.eval()
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>    correct = 0
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>    local_rank = int(os.environ[&#39;LOCAL_RANK&#39;])
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>    fsdp_loss = torch.zeros(3).to(local_rank)
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>    if rank == 0:
<a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>        inner_pbar = tqdm.tqdm(
<a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>            range(len(val_loader)), colour=&quot;green&quot;, desc=&quot;Validation Epoch&quot;
<a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>        )
<a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>    with torch.no_grad():
<a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>        for batch in val_loader:
<a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>            for key in batch.keys():
<a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>                batch[key] = batch[key].to(local_rank)
<a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a>            output = model(input_ids=batch[&quot;source_ids&quot;],attention_mask=batch[&quot;source_mask&quot;],labels=batch[&quot;target_ids&quot;])
<a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a>            fsdp_loss[0] += output[&quot;loss&quot;].item()  # sum up batch loss
<a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a>            fsdp_loss[1] += len(batch)
<a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a>
<a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a>            if rank==0:
<a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a>                inner_pbar.update(1)
<a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a>
<a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a>    dist.all_reduce(fsdp_loss, op=dist.ReduceOp.SUM)
<a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a>    val_loss = fsdp_loss[0] / fsdp_loss[1]
<a id="__codelineno-6-23" name="__codelineno-6-23" href="#__codelineno-6-23"></a>    if rank == 0:
<a id="__codelineno-6-24" name="__codelineno-6-24" href="#__codelineno-6-24"></a>        inner_pbar.close()
<a id="__codelineno-6-25" name="__codelineno-6-25" href="#__codelineno-6-25"></a>        print(f&quot;Validation Loss: {val_loss:.4f}&quot;)
<a id="__codelineno-6-26" name="__codelineno-6-26" href="#__codelineno-6-26"></a>    return val_loss
</code></pre></div>
<p>2.4 定义一个将模型包装在 FSDP 中的分布式训练函数：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>def fsdp_main(args):
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>    model, tokenizer = setup_model(&quot;t5-base&quot;)
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>    local_rank = int(os.environ[&#39;LOCAL_RANK&#39;])
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>    rank = int(os.environ[&#39;RANK&#39;])
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>    world_size = int(os.environ[&#39;WORLD_SIZE&#39;])
<a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>
<a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>
<a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a> dataset = load_dataset(&#39;wikihow&#39;, &#39;all&#39;, data_dir=&#39;data/&#39;)
<a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a> print(dataset.keys())
<a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a> print(&quot;训练数据集的大小: &quot;, dataset[&#39;train&#39;].shape)
<a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a> print(&quot;验证数据集大小: &quot;, dataset[&#39;validation&#39;].shape)
<a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a>
<a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a>
<a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a> #wikihow(tokenizer, type_path, num_samples, input_length, output_length, print_text=False)
<a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a> train_dataset = wikihow(tokenizer, &#39;train&#39;, 1500, 512 , 150, False)
<a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a> val_dataset = wikihow(tokenizer, &#39;validation&#39;, 300, 512, 150, False)
<a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a>
<a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a> Sampler1 = DistributedSampler(train_dataset,rank=rank, num_replicas= world_size，shuffle=True)
<a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a> Sampler2 = DistributedSampler(val_dataset，rank=rank，num_replicas=world_size)
<a id="__codelineno-7-22" name="__codelineno-7-22" href="#__codelineno-7-22"></a>
<a id="__codelineno-7-23" name="__codelineno-7-23" href="#__codelineno-7-23"></a> setup()
<a id="__codelineno-7-24" name="__codelineno-7-24" href="#__codelineno-7-24"></a>
<a id="__codelineno-7-25" name="__codelineno-7-25" href="#__codelineno-7-25"></a>
<a id="__codelineno-7-26" name="__codelineno-7-26" href="#__codelineno-7-26"></a> train_kwargs = {&#39;batch_size&#39;：args.batch_size，&#39;sampler&#39;：sampler1}
<a id="__codelineno-7-27" name="__codelineno-7-27" href="#__codelineno-7-27"></a> test_kwargs = {&#39;batch_size&#39;：args.test_batch_size , &#39;sampler&#39;:sampler2}
<a id="__codelineno-7-28" name="__codelineno-7-28" href="#__codelineno-7-28"></a> cuda_kwargs = {&#39;num_workers&#39;: 2,
<a id="__codelineno-7-29" name="__codelineno-7-29" href="#__codelineno-7-29"></a> &#39;pin_memory&#39;: True,
<a id="__codelineno-7-30" name="__codelineno-7-30" href="#__codelineno-7-30"></a> &#39;shuffle&#39;: False}
<a id="__codelineno-7-31" name="__codelineno-7-31" href="#__codelineno-7-31"></a> train_kwargs.更新(cuda_kwargs)
<a id="__codelineno-7-32" name="__codelineno-7-32" href="#__codelineno-7-32"></a> 测试_kwargs.update(cuda_kwargs)
<a id="__codelineno-7-33" name="__codelineno-7-33" href="#__codelineno-7-33"></a>
<a id="__codelineno-7-34" name="__codelineno-7-34" href="#__codelineno-7-34"></a> train_loader = torch.utils.data.DataLoader(train_dataset,**train _kwargs)
<a id="__codelineno-7-35" name="__codelineno-7-35" href="#__codelineno-7-35"></a> val_loader = torch.utils.data.DataLoader(val_dataset, **test_kwargs)
<a id="__codelineno-7-36" name="__codelineno-7-36" href="#__codelineno-7-36"></a>
<a id="__codelineno-7-37" name="__codelineno-7-37" href="#__codelineno-7-37"></a> t5_auto_wrap_policy = functools.partial(
<a id="__codelineno-7-38" name="__codelineno-7-38" href="#__codelineno-7-38"></a> Transformer_auto_wrap_policy,
<a id="__codelineno-7-39" name="__codelineno-7-39" href="#__codelineno-7-39"></a> Transformer_layer_cls={
<a id="__codelineno-7-40" name="__codelineno-7-40" href="#__codelineno-7-40"></a> T5Block,
<a id="__codelineno-7-41" name="__codelineno-7-41" href="#__codelineno-7-41"></a> },
<a id="__codelineno-7-42" name="__codelineno-7-42" href="#__codelineno-7-42"></a> )
<a id="__codelineno-7-43" name="__codelineno-7-43" href="#__codelineno-7-43"></a> sharding_strategy: ShardingStrategy = ShardingStrategy. SHARD_GRAD_OP #for Zero2 和 FULL_SHARD for Zero3
<a id="__codelineno-7-44" name="__codelineno-7-44" href="#__codelineno-7-44"></a> torch.cuda.set_device(local_rank)
<a id="__codelineno-7-45" name="__codelineno-7-45" href="#__codelineno-7-45"></a>
<a id="__codelineno-7-46" name="__codelineno-7-46" href="#__codelineno-7-46"></a>
<a id="__codelineno-7-47" name="__codelineno-7-47" href="#__codelineno-7-47"></a> #init_start_event = torch.cuda.Event(enable_timing=True)
<a id="__codelineno-7-48" name="__codelineno-7-48" href="#__codelineno-7-48"></a> #init_end_event = torch.cuda.Event(enable_timing=True)
<a id="__codelineno-7-49" name="__codelineno-7-49" href="#__codelineno-7-49"></a>
<a id="__codelineno-7-50" name="__codelineno-7-50" href="#__codelineno-7-50"></a> #init_start_event.record()
<a id="__codelineno-7-51" name="__codelineno-7-51" href="#__codelineno-7-51"></a>
<a id="__codelineno-7-52" name="__codelineno-7-52" href="#__codelineno-7-52"></a> bf16_ready = (
<a id="__codelineno-7-53" name="__codelineno-7-53" href="#__codelineno-7-53"></a> torch.version.cuda
<a id="__codelineno-7-54" name="__codelineno-7-54" href="#__codelineno-7-54"></a> 和 torch.cuda.is_bf16_supported()
<a id="__codelineno-7-55" name="__codelineno-7-55" href="#__codelineno-7-55"></a> 和 LooseVersion( torch.version.cuda) &gt;= &quot;11.0&quot;
<a id="__codelineno-7-56" name="__codelineno-7-56" href="#__codelineno-7-56"></a> 和 dist.is_nccl_available()
<a id="__codelineno-7-57" name="__codelineno-7-57" href="#__codelineno-7-57"></a> 和 nccl.version() &gt;= (2, 10)
<a id="__codelineno-7-58" name="__codelineno-7-58" href="#__codelineno-7-58"></a> )
<a id="__codelineno-7-59" name="__codelineno-7-59" href="#__codelineno-7-59"></a>
<a id="__codelineno-7-60" name="__codelineno-7-60" href="#__codelineno-7-60"></a> 如果 bf16\ \_ready:
<a id="__codelineno-7-61" name="__codelineno-7-61" href="#__codelineno-7-61"></a> mp_policy = bfSixteen
<a id="__codelineno-7-62" name="__codelineno-7-62" href="#__codelineno-7-62"></a> else:
<a id="__codelineno-7-63" name="__codelineno-7-63" href="#__codelineno-7-63"></a> mp_policy = None # 默认为 fp32
<a id="__codelineno-7-64" name="__codelineno-7-64" href="#__codelineno-7-64"></a>
<a id="__codelineno-7-65" name="__codelineno-7-65" href="#__codelineno-7-65"></a> # 在输入 FSDP 之前模型已在 CPU 上
<a id="__codelineno-7-66" name="__codelineno-7-66" href="#__codelineno-7-66"></a> model = FSDP(model,
<a id="__codelineno-7-67" name="__codelineno-7-67" href="#__codelineno-7-67"></a> auto_wrap_policy=t5_auto_wrap_policy，
<a id="__codelineno-7-68" name="__codelineno-7-68" href="#__codelineno-7-68"></a> mix_ precision=mp_policy，
<a id="__codelineno-7-69" name="__codelineno-7-69" href="#__codelineno-7-69"></a> #sharding_strategy=sharding_strategy，
<a id="__codelineno-7-70" name="__codelineno-7-70" href="#__codelineno-7-70"></a> device_id =torch.cuda.current_device())
<a id="__codelineno-7-71" name="__codelineno-7-71" href="#__codelineno-7-71"></a>
<a id="__codelineno-7-72" name="__codelineno-7-72" href="#__codelineno-7-72"></a> 优化器 = optim.AdamW(model.parameters(), lr=args.lr)
<a id="__codelineno-7-73" name="__codelineno-7-73" href="#__codelineno-7-73"></a>
<a id="__codelineno-7-74" name="__codelineno-7-74" href="#__codelineno-7-74"></a> 调度程序 = StepLR(optimizer, step_size=1 , gamma=args.gamma)
<a id="__codelineno-7-75" name="__codelineno-7-75" href="#__codelineno-7-75"></a> best_val_loss = float(&quot;inf&quot;)
<a id="__codelineno-7-76" name="__codelineno-7-76" href="#__codelineno-7-76"></a> curr_val_loss = float(&quot;inf&quot;)
<a id="__codelineno-7-77" name="__codelineno-7-77" href="#__codelineno-7-77"></a> file_save_name = &quot; T5-模型-&quot;
<a id="__codelineno-7-78" name="__codelineno-7-78" href="#__codelineno-7-78"></a>
<a id="__codelineno-7-79" name="__codelineno-7-79" href="#__codelineno-7-79"></a> 如果rank == 0:
<a id="__codelineno-7-80" name="__codelineno-7-80" href="#__codelineno-7-80"></a> time_of_run = get_date_of_run()
<a id="__codelineno-7-81" name="__codelineno-7-81" href="#__codelineno-7-81"></a> dur = []
<a id="__codelineno-7-82" name="__codelineno-7-82" href="#__codelineno-7-82"></a> train_acc\ \_tracking = []
<a id="__codelineno-7-83" name="__codelineno-7-83" href="#__codelineno-7-83"></a> val_acc_tracking = []
<a id="__codelineno-7-84" name="__codelineno-7-84" href="#__codelineno-7-84"></a> Training_start_time = time.time()
<a id="__codelineno-7-85" name="__codelineno-7-85" href="#__codelineno-7-85"></a>
<a id="__codelineno-7-86" name="__codelineno-7-86" href="#__codelineno-7-86"></a> 如果rank == 0 且args.track_memory:\ n mem_alloc_tracker = []
<a id="__codelineno-7-87" name="__codelineno-7-87" href="#__codelineno-7-87"></a> mem_reserved_tracker = []
<a id="__codelineno-7-88" name="__codelineno-7-88" href="#__codelineno-7-88"></a>
<a id="__codelineno-7-89" name="__codelineno-7-89" href="#__codelineno-7-89"></a> for epoch in range(1, args.epochs + 1):
<a id="__codelineno-7-90" name="__codelineno-7-90" href="#__codelineno-7-90"></a> t0 = time.time() 
<a id="__codelineno-7-91" name="__codelineno-7-91" href="#__codelineno-7-91"></a> train_accuracy = train(args、model、rank、world_size、train_loader、optimizer、epoch、sampler=sampler1)
<a id="__codelineno-7-92" name="__codelineno-7-92" href="#__codelineno-7-92"></a> if args.run_validation:
<a id="__codelineno-7-93" name="__codelineno-7-93" href="#__codelineno-7-93"></a> curr_val\ \_loss = 验证(模型、排名、世界大小、val\_loader)
<a id="__codelineno-7-94" name="__codelineno-7-94" href="#__codelineno-7-94"></a> Scheduler.step()
<a id="__codelineno-7-95" name="__codelineno-7-95" href="#__codelineno-7-95"></a>
<a id="__codelineno-7-96" name="__codelineno-7-96" href="#__codelineno-7-96"></a> 如果排名 == 0:
<a id="__codelineno-7-97" name="__codelineno-7-97" href="#__codelineno-7-97"></a>
<a id="__codelineno-7-98" name="__codelineno-7-98" href="#__codelineno-7-98"></a> print(f&quot;--&gt; epoch {epoch } 已完成...进入保存和统计区域&quot;)
<a id="__codelineno-7-99" name="__codelineno-7-99" href="#__codelineno-7-99"></a>
<a id="__codelineno-7-100" name="__codelineno-7-100" href="#__codelineno-7-100"></a> dur.append(time.time() - t0)
<a id="__codelineno-7-101" name="__codelineno-7-101" href="#__codelineno-7-101"></a> train_acc_tracking.append(train_accuracy.item())\ n
<a id="__codelineno-7-102" name="__codelineno-7-102" href="#__codelineno-7-102"></a> if args.run_validation:
<a id="__codelineno-7-103" name="__codelineno-7-103" href="#__codelineno-7-103"></a> val_acc_tracking.append(curr_val_loss.item())
<a id="__codelineno-7-104" name="__codelineno-7-104" href="#__codelineno-7-104"></a>
<a id="__codelineno-7-105" name="__codelineno-7-105" href="#__codelineno-7-105"></a> if args.track_memory:
<a id="__codelineno-7-106" name="__codelineno-7-106" href="#__codelineno-7-106"></a> mem _alloc_tracker.append(
<a id="__codelineno-7-107" name="__codelineno-7-107" href="#__codelineno-7-107"></a> format_metrics_to_gb(torch.cuda.memory_allocated())
<a id="__codelineno-7-108" name="__codelineno-7-108" href="#__codelineno-7-108"></a> )
<a id="__codelineno-7-109" name="__codelineno-7-109" href="#__codelineno-7-109"></a> mem_reserved_tracker.append(
<a id="__codelineno-7-110" name="__codelineno-7-110" href="#__codelineno-7-110"></a> format_metrics_to_gb(torch.cuda.memory_reserved())
<a id="__codelineno-7-111" name="__codelineno-7-111" href="#__codelineno-7-111"></a> )
<a id="__codelineno-7-112" name="__codelineno-7-112" href="#__codelineno-7-112"></a> print(f&quot;已完成保存和统计区域...&quot;)
<a id="__codelineno-7-113" name="__codelineno-7-113" href="#__codelineno-7-113"></a>
<a id="__codelineno-7-114" name="__codelineno-7-114" href="#__codelineno-7-114"></a> if args.save\ \_model 和 curr_val_loss &lt; best_val_loss:
<a id="__codelineno-7-115" name="__codelineno-7-115" href="#__codelineno-7-115"></a>
<a id="__codelineno-7-116" name="__codelineno-7-116" href="#__codelineno-7-116"></a> # save
<a id="__codelineno-7-117" name="__codelineno-7-117" href="#__codelineno-7-117"></a> ifrank == 0:
<a id="__codelineno-7-118" name="__codelineno-7-118" href="#__codelineno-7-118"></a> print(f&quot;--&gt; 进入保存模型状态&quot;)
<a id="__codelineno-7-119" name="__codelineno-7-119" href="#__codelineno-7-119"></a>
<a id="__codelineno-7-120" name="__codelineno-7-120" href="#__codelineno-7-120"></a> save_policy = FullStateDictConfig(offload_to_cpu=True,rank0_only=True)
<a id="__codelineno-7-121" name="__codelineno-7-121" href="#__codelineno-7-121"></a> with FSDP.state_dict_type(
<a id="__codelineno-7-122" name="__codelineno-7-122" href="#__codelineno-7-122"></a> model, StateDictType.FULL_STATE\ \_DICT, save_policy
<a id="__codelineno-7-123" name="__codelineno-7-123" href="#__codelineno-7-123"></a> ):
<a id="__codelineno-7-124" name="__codelineno-7-124" href="#__codelineno-7-124"></a> cpu_state = model.state_dict()
<a id="__codelineno-7-125" name="__codelineno-7-125" href="#__codelineno-7-125"></a> #print(f&quot;保存过程：rank {rank} 完成 w state_dict&quot;)
<a id="__codelineno-7-126" name="__codelineno-7-126" href="#__codelineno-7-126"></a>
<a id="__codelineno-7-127" name="__codelineno-7-127" href="#__codelineno-7-127"></a>
<a id="__codelineno-7-128" name="__codelineno-7-128" href="#__codelineno-7-128"></a>            if rank == 0:
<a id="__codelineno-7-129" name="__codelineno-7-129" href="#__codelineno-7-129"></a>                print(f&quot;--&gt; saving model ...&quot;)
<a id="__codelineno-7-130" name="__codelineno-7-130" href="#__codelineno-7-130"></a>                currEpoch = (
<a id="__codelineno-7-131" name="__codelineno-7-131" href="#__codelineno-7-131"></a>                    &quot;-&quot; + str(epoch) + &quot;-&quot; + str(round(curr_val_loss.item(), 4)) + &quot;.pt&quot;
<a id="__codelineno-7-132" name="__codelineno-7-132" href="#__codelineno-7-132"></a>                )
<a id="__codelineno-7-133" name="__codelineno-7-133" href="#__codelineno-7-133"></a>                print(f&quot;--&gt; attempting to save model prefix {currEpoch}&quot;)
<a id="__codelineno-7-134" name="__codelineno-7-134" href="#__codelineno-7-134"></a>                save_name = file_save_name + &quot;-&quot; + time_of_run + &quot;-&quot; + currEpoch
<a id="__codelineno-7-135" name="__codelineno-7-135" href="#__codelineno-7-135"></a>                print(f&quot;--&gt; saving as model name {save_name}&quot;)
<a id="__codelineno-7-136" name="__codelineno-7-136" href="#__codelineno-7-136"></a>
<a id="__codelineno-7-137" name="__codelineno-7-137" href="#__codelineno-7-137"></a>                torch.save(cpu_state, save_name)
<a id="__codelineno-7-138" name="__codelineno-7-138" href="#__codelineno-7-138"></a>
<a id="__codelineno-7-139" name="__codelineno-7-139" href="#__codelineno-7-139"></a>        if curr_val_loss &lt; best_val_loss:
<a id="__codelineno-7-140" name="__codelineno-7-140" href="#__codelineno-7-140"></a>
<a id="__codelineno-7-141" name="__codelineno-7-141" href="#__codelineno-7-141"></a>            best_val_loss = curr_val_loss
<a id="__codelineno-7-142" name="__codelineno-7-142" href="#__codelineno-7-142"></a>            if rank==0:
<a id="__codelineno-7-143" name="__codelineno-7-143" href="#__codelineno-7-143"></a>                print(f&quot;--&gt;&gt;&gt;&gt; New Val Loss Record: {best_val_loss}&quot;)
<a id="__codelineno-7-144" name="__codelineno-7-144" href="#__codelineno-7-144"></a>
<a id="__codelineno-7-145" name="__codelineno-7-145" href="#__codelineno-7-145"></a>    dist.barrier()
<a id="__codelineno-7-146" name="__codelineno-7-146" href="#__codelineno-7-146"></a>    cleanup()
</code></pre></div>
<p>2.5 解析参数并设置main函数:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>if __name__ == &#39;__main__&#39;:
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>    # Training settings
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>    parser = argparse.ArgumentParser(description=&#39;PyTorch T5 FSDP Example&#39;)
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>    parser.add_argument(&#39;--batch-size&#39;, type=int, default=4, metavar=&#39;N&#39;,
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>                        help=&#39;input batch size for training (default: 64)&#39;)
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>    parser.add_argument(&#39;--test-batch-size&#39;, type=int, default=4, metavar=&#39;N&#39;,
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>                        help=&#39;input batch size for testing (default: 1000)&#39;)
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>    parser.add_argument(&#39;--epochs&#39;, type=int, default=2, metavar=&#39;N&#39;,
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>                        help=&#39;number of epochs to train (default: 3)&#39;)
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>    parser.add_argument(&#39;--lr&#39;, type=float, default=.002, metavar=&#39;LR&#39;,
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>                        help=&#39;learning rate (default: .002)&#39;)
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>    parser.add_argument(&#39;--gamma&#39;, type=float, default=0.7, metavar=&#39;M&#39;,
<a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>                        help=&#39;Learning rate step gamma (default: 0.7)&#39;)
<a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>    parser.add_argument(&#39;--no-cuda&#39;, action=&#39;store_true&#39;, default=False,
<a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>                        help=&#39;disables CUDA training&#39;)
<a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>    parser.add_argument(&#39;--seed&#39;, type=int, default=1, metavar=&#39;S&#39;,
<a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>                        help=&#39;random seed (default: 1)&#39;)
<a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>    parser.add_argument(&#39;--track_memory&#39;, action=&#39;store_false&#39;, default=True,
<a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>                        help=&#39;track the gpu memory&#39;)
<a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a>    parser.add_argument(&#39;--run_validation&#39;, action=&#39;store_false&#39;, default=True,
<a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a>                        help=&#39;running the validation&#39;)
<a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>    parser.add_argument(&#39;--save-model&#39;, action=&#39;store_false&#39;, default=True,
<a id="__codelineno-8-23" name="__codelineno-8-23" href="#__codelineno-8-23"></a>                        help=&#39;For Saving the current Model&#39;)
<a id="__codelineno-8-24" name="__codelineno-8-24" href="#__codelineno-8-24"></a>    args = parser.parse_args()
<a id="__codelineno-8-25" name="__codelineno-8-25" href="#__codelineno-8-25"></a>
<a id="__codelineno-8-26" name="__codelineno-8-26" href="#__codelineno-8-26"></a>    torch.manual_seed(args.seed)
<a id="__codelineno-8-27" name="__codelineno-8-27" href="#__codelineno-8-27"></a>
<a id="__codelineno-8-28" name="__codelineno-8-28" href="#__codelineno-8-28"></a>    fsdp_main(args)
</code></pre></div>
<p>要使用 torchrun 运行训练：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>torchrun --nnodes 1 --nproc_per_node 4 T5_training.py
</code></pre></div>
<h2 id="_1">变压器包装政策 <a href="#transformer-wrapping-policy" title="永久链接到此标题">¶</a></h2>
<p>正如在
 <a href="https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html">上一篇教程</a> 中所讨论的，
auto_wrap_policy 是 FSDP 功能之一，可以轻松实现这一点自动对给定模型进行分片，并将模型、优化器和梯度分片放入不同的 FSDP 单元中。</p>
<p>对于某些架构(例如 Transformer 编码器-解码器)，模型的某些部分(例如嵌入表)与编码器和解码器共享。在这种情况下，我们需要将嵌入表放置在外部 FSDP 单元中，以便可以从编码器和解码器访问。此外，通过注册变压器的层类，可以使分片计划的通信效率更高。在 PyTorch 1.12 中，FSDP 添加了此支持，现在我们
为转换器提供了包装策略。</p>
<p>可以按如下方式创建，其中 T5Block 代表 T5 转换器
层类(包含 MHSA 和 FFN)。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>t5_auto_wrap_policy = functools.partial(
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>        transformer_auto_wrap_policy,
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>        transformer_layer_cls={
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>            T5Block,
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>        },
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>    )
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>torch.cuda.set_device(local_rank)
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>model = FSDP(model,
<a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>    fsdp_auto_wrap_policy=t5_auto_wrap_policy)
</code></pre></div>
<p>要查看包装的模型，您可以轻松打印模型并目视检查
分片和 FSDP 单元。</p>
<h2 id="_2">混合精度 <a href="#mixed- precision" title="永久链接到此标题">¶</a></h2>
<p>FSDP 支持灵活的混合精度训练，允许任意降低精度类型(例如 fp16 或 bfloat16)。目前BFloat16仅适用于Ampere GPU，因此在使用之前需要确认本机支持。例如，在 V100 上，BFloat16 仍然可以运行，但由于它非本机运行，
可能会导致速度显着降低。</p>
<p>要检查 BFloat16 是否原生支持，您可以使用以下命令:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>bf16_ready = (
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>    torch.version.cuda
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>    and torch.cuda.is_bf16_supported()
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>    and LooseVersion(torch.version.cuda) &gt;= &quot;11.0&quot;
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>    and dist.is_nccl_available()
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>    and nccl.version() &gt;= (2, 10)
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>)
</code></pre></div>
<p>FSDP 中混合精度的优点之一是为参数、梯度和缓冲区提供
不同精度级别的粒度控制，
如下所示：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>fpSixteen = MixedPrecision(
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>    param_dtype=torch.float16,
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>    # Gradient communication precision.
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>    reduce_dtype=torch.float16,
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>    # Buffer precision.
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>    buffer_dtype=torch.float16,
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>)
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>
<a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>bfSixteen = MixedPrecision(
<a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>    param_dtype=torch.bfloat16,
<a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>    # Gradient communication precision.
<a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>    reduce_dtype=torch.bfloat16,
<a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>    # Buffer precision.
<a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>    buffer_dtype=torch.bfloat16,
<a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>)
<a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>
<a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>fp32_policy = MixedPrecision(
<a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>    param_dtype=torch.float32,
<a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a>    # Gradient communication precision.
<a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>    reduce_dtype=torch.float32,
<a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>    # Buffer precision.
<a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a>    buffer_dtype=torch.float32,
<a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a>)
</code></pre></div>
<p>请注意，如果未指定某种类型(参数、reduce、buffer)，则它们根本不会被强制转换。</p>
<p>这种灵活性允许用户进行细粒度控制，例如仅设置梯度通信以降低的精度进行，并且所有参数/缓冲区计算都以全精度完成。在节点内通信是主要瓶颈并且参数缓冲区必须完全精确以避免准确性问题的情况下，这可能很有用。这可以通过
以下策略来完成:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>grad_bf16 = MixedPrecision(reduce_dtype=torch.bfloat16)
</code></pre></div>
<p>在 2.4 中，我们只是将相关的混合精度策略添加到 FSDP 包装器中：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>model = FSDP(model,
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>       auto_wrap_policy=t5_auto_wrap_policy,
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>       mixed_precision=bfSixteen)
</code></pre></div>
<p>在我们的实验中，我们观察到，通过使用 BFloat16 进行训练，速度提高了 4 倍，并且在某些可用于增加批量大小的实验中
内存减少了约 30%。</p>
<h2 id="fsdp_3">正在设备上初始化 FSDP 模型 <a href="#intializing-fsdp-model-on-device" title="永久链接到此标题">¶</a></h2>
<p>在 1.12 中，FSDP 支持 </p>
<p>device_id</p>
<p>参数，用于初始化由 </p>
<p>device_id</p>
<p>给定的设备上的输入 CPU
模块。当整个模型不适合单个 GPU，但适合主机’s CPU 内存时，这非常有用。当指定</p>
<p>device_id</p>
<p>时，FSDP 将以每个 FSDP
单元为基础将模型移动到指定设备，避免 GPU OOM 问题，同时初始化速度比基于 CPU 的初始化快几倍： </p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>torch.cuda.set_device(local_rank)
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a> model = FSDP(model,
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>        auto_wrap_policy=t5_auto_wrap_policy,
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>        mixed_precision=bfSixteen,
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>        device_id=torch.cuda.current_device())
</code></pre></div>
<h2 id="_3">分片策略 <a href="#sharding-strategy" title="固定链接到此标题">¶</a></h2>
<p>FSDP 分片策略默认设置为完全分片模型参数，
梯度和优化器状态在所有等级上进行分片。 (也称为 Zero3
s 分片)。如果您对 Zero2 分片策略感兴趣，
仅对优化器状态和梯度进行分片，FSDP 通过使用 \xe2\x80\x9cShardingStrategy.SHARD_GRAD_OP\xe2 传递分片策略来支持此功能\x80\x9d，\而不是 \xe2\x80\x9cShardingStrategy.FULL_SHARD\xe2\x80\x9d 到 FSDP 初始化，如下所示：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>torch.cuda.set_device(local_rank)
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a> model = FSDP(model,
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>        auto_wrap_policy=t5_auto_wrap_policy,
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>        mixed_precision=bfSixteen,
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>        device_id=torch.cuda.current_device(),
<a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a>        sharding_strategy=ShardingStrategy.SHARD_GRAD_OP # ZERO2)
</code></pre></div>
<p>这将减少 FSDP 中的通信开销，在这种情况下，它在前向传递和后向传递之后保留完整
参数。</p>
<p>这可以在向后过程中保存 all_gather，因此可以减少通信，但
代价是增加内存占用。请注意，完整的模型参数在向后传递结束时被释放，并且 all_gather 将在下一次向前传递时发生。</p>
<h2 id="_4">向后预取 <a href="#backward-prefetch" title="永久链接到此标题">¶</a></h2>
<p>向后预取设置控制应请求下一个 FSDP 单元’s
参数的时间。通过将其设置为</p>
<p>BACKWARD_PRE</p>
<p>，可以开始请求下一个
FSDP’s 单元参数，并在当前单元的计算开始之前更快到达
。这与</p>
<p>all _gather</p>
<p>通信和梯度计算重叠，可以提高训练速度，以换取稍高的内存消耗。它可以在 2.4 中的 FSDP
wrapper 中使用，如下所示：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>torch.cuda.set_device(local_rank)
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a> model = FSDP(model,
<a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a>        auto_wrap_policy=t5_auto_wrap_policy,
<a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>        mixed_precision=bfSixteen,
<a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a>        device_id=torch.cuda.current_device(),
<a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a>        backward_prefetch = BackwardPrefetch.BACKWARD_PRE)
</code></pre></div>
<p>backward_prefetch</p>
<p>有两种模式，</p>
<p>BACKWARD_PRE</p>
<p>和</p>
<p>BACKWARD_POST</p>
<p>。</p>
<p>BACKWARD_POST</p>
<p>意味着在当前 FSDP 单元处理完成之前，不会请求下一个 FSDP 单元’s 参数，从而最大限度地减少内存
开销。在某些情况下，使用</p>
<p>BACKWARD_PRE</p>
<p>可以将模型训练速度
提高高达 2-10%，对于较大的模型，速度改进甚至更高。</p>
<h2 id="rank0-cpu">模型检查点保存，通过流式传输到 Rank0 CPU <a href="#model-checkpoint- saving-by-streaming-to-the-rank0-cpu" title="永久链接到此标题">¶</a></h2>
<p>为了使用 FULL_STATE_DICT 保存(以与本地模型相同的方式保存模型)来保存模型检查点，PyTorch 1.12 提供了一些实用程序来支持
较大模型的保存。</p>
<p>首先，可以指定 FullStateDictConfig，允许 state_dict 只
填充到 0 级并卸载到 CPU。</p>
<p>使用此配置时，FSDP 将全部收集模型参数，将它们一一卸载到 CPU，仅在 Rank 0 上。当 state_dict 最终
保存时，它将仅在Rank 0 上填充并包含 CPUtensor。这可以避免
大于单个 GPU 内存的模型可能出现 OOM，并允许用户
检查大小大致等于
用户’s 计算机上的可用 CPU RAM 的模型。</p>
<p>此功能可以按如下方式运行:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>save_policy = FullStateDictConfig(offload_to_cpu=True, rank0_only=True)
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>with FSDP.state_dict_type(
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>            model, StateDictType.FULL_STATE_DICT, save_policy
<a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a>        ):
<a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>            cpu_state = model.state_dict()
<a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a>if rank == 0:
<a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a> save_name = file_save_name + &quot;-&quot; + time_of_run + &quot;-&quot; + currEpoch
<a id="__codelineno-18-8" name="__codelineno-18-8" href="#__codelineno-18-8"></a> torch.save(cpu_state, save_name)
</code></pre></div>
<h2 id="_5">摘要 <a href="#summary" title="此标题的永久链接">¶</a></h2>
<p>在本教程中，我们介绍了 Pytorch 1.12 中提供的许多 FSDP 新功能，并使用 HF T5 作为运行示例。使用正确的包装策略，特别是对于变压器模型，以及混合精度和向后预取，应该可以加快您的训练运行速度。此外，
在设备上初始化模型以及通过流式传输到 CPU 保存检查点等功能
应有助于避免处理大型模型时出现 OOM 错误。</p>
<p>我们正在积极努力为下一个版本的 FSDP 添加新功能。如果您有反馈、功能请求、疑问或在使用 FSDP 时遇到问题，请随时通过在 <a href="https://github.com/pytorch/pytorch">PyTorch Github 存储库</a> 中提出问题来与我们联系
.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../FSDP_tutorial/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Getting Started with Fully Sharded Data Parallel(FSDP)">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Getting Started with Fully Sharded Data Parallel(FSDP)
              </div>
            </div>
          </a>
        
        
          
          <a href="../TP_tutorial/" class="md-footer__link md-footer__link--next" aria-label="Next: Large Scale Transformer model training with Tensor Parallel (TP)">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Large Scale Transformer model training with Tensor Parallel (TP)
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>