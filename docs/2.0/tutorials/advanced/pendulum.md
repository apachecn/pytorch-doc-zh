# PyTorch Pendulumï¼šä½¿ç”¨ TorchRL è¿›è¡Œç‰©ç†ç¯å¢ƒæ¨¡æ‹Ÿ

> è¯‘è€…ï¼š[å…ˆå¤©äºé’±åœ£ä½“](https://github.com/sanxincao)
>
> é¡¹ç›®åœ°å€ï¼š<https://pytorch.apachecn.org/2.0/tutorials/advanced/pendulum>
>
> åŸå§‹åœ°å€ï¼š<https://pytorch.org/tutorials//advanced/pendulum.html>


åˆ›å»ºç¯å¢ƒï¼ˆæ¨¡æ‹Ÿå™¨æˆ–ç‰©ç†æ§åˆ¶ç³»ç»Ÿçš„æ¥å£ï¼‰æ˜¯å¼ºåŒ–å­¦ä¹ å’Œæ§åˆ¶å·¥ç¨‹çš„é›†æˆéƒ¨åˆ†ã€‚  

TorchRL æä¾›äº†ä¸€ç»„å·¥å…·æ¥åœ¨æ‰§è¡Œæ­¤æ“ä½œã€‚æœ¬æ•™ç¨‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ PyTorch å’Œ TorchRL ä»å¤´å¼€å§‹â€‹â€‹ç¼–å†™é’Ÿæ‘†æ¨¡æ‹Ÿå™¨ã€‚ å®ƒçš„çµæ„Ÿæ¥è‡ª[OpenAI-Gym/Farama-Gymnasium](https://github.com/Farama-Foundation/Gymnasium) æ§åˆ¶åº“çš„ Pendulum-v1 å®ç°ã€‚

### ä¸»è¦å­¦ä¹ å†…å®¹ï¼š 

* å¦‚ä½•åœ¨ TorchRL ä¸­è®¾è®¡ç¯å¢ƒæ¨¡æ‹Ÿï¼š - ç¼–å†™è§„åˆ™ï¼ˆè¾“å…¥ã€è§‚å¯Ÿå’Œå¥–åŠ±ï¼‰ï¼› - å®ç°è¡Œä¸ºï¼šåˆå§‹åŒ–ã€é‡ç½®å’Œæ­¥è¿›ã€‚ 
* è½¬æ¢æ‚¨çš„ç¯å¢ƒè¾“å…¥å’Œè¾“å‡ºï¼Œå¹¶ç¼–å†™æ‚¨è‡ªå·±çš„è½¬æ¢ã€‚
* å¦‚ä½•ä½¿ç”¨TensorDictæ¥æºå¸¦ä»»ä½•ç»“æ„çš„æ•°æ®é€šè¿‡codebaseï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ¥è§¦ TorchRL çš„ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼š
* [ç¯å¢ƒ](https://pytorch.org/rl/reference/envs.html) 
* [è½¬æ¢](https://pytorch.org/rl/reference/transforms.html) 
* [ç­–ç•¥](https://pytorch.org/rl/reference/modules.html) (ç­–ç•¥å’Œä»·å€¼å‡½æ•°) 

ä¸ºäº†äº†è§£ TorchRL ç¯å¢ƒå¯ä»¥å®ç°çš„ç›®æ ‡ï¼Œæˆ‘ä»¬å°†è®¾è®¡ä¸€ä¸ªæ— çŠ¶æ€ç¯å¢ƒã€‚æœ‰çŠ¶æ€ç¯å¢ƒä¼šè·Ÿè¸ªé‡åˆ°çš„æœ€æ–°ç‰©ç†çŠ¶æ€å¹¶ä¾é å®ƒæ¥æ¨¡æ‹ŸçŠ¶æ€åˆ°çŠ¶æ€çš„è½¬æ¢ï¼Œè€Œæ— çŠ¶æ€ç¯å¢ƒåˆ™å¸Œæœ›åœ¨æ¯ä¸ªæ­¥éª¤ä¸­å‘å®ƒä»¬æä¾›å½“å‰çŠ¶æ€ä»¥åŠæ‰€é‡‡å–çš„æ“ä½œã€‚ï¼ˆæƒ³åæ§½ï¼‰TorchRL æ”¯æŒè¿™ä¸¤ç§ç±»å‹çš„ç¯å¢ƒï¼Œä½†æ— çŠ¶æ€ç¯å¢ƒæ›´é€šç”¨ï¼Œå› æ­¤æ¶µç›–äº† TorchRL ä¸­æ›´å¹¿æ³›çš„åŠŸèƒ½çš„ç¯å¢ƒ APIã€‚ 

å¯¹æ— çŠ¶æ€ç¯å¢ƒè¿›è¡Œå»ºæ¨¡ä½¿ç”¨æˆ·å¯ä»¥å®Œå…¨æ§åˆ¶æ¨¡æ‹Ÿå™¨çš„è¾“å…¥å’Œè¾“å‡ºï¼šå¯ä»¥åœ¨ä»»ä½•é˜¶æ®µé‡ç½®å®éªŒæˆ–ä¸»åŠ¨ä»å¤–éƒ¨ä¿®æ”¹åŠ¨æ€ã€‚ç„¶è€Œï¼Œå®ƒå‡è®¾æˆ‘ä»¬å¯ä»¥å®Œå…¨æ§åˆ¶ä»»åŠ¡ï¼Œæˆ–è€…å¯ä»¥æœ‰æå¼ºçš„æ§åˆ¶èƒ½åŠ›ã€‚ä½†æƒ…å†µå¯èƒ½å¹¶éæ€»æ˜¯å¦‚æ­¤ï¼šè§£å†³æˆ‘ä»¬æ— æ³•æ§åˆ¶å½“å‰çŠ¶æ€çš„é—®é¢˜æ›´å…·æŒ‘æˆ˜æ€§ï¼Œè€Œä¸”å…·æœ‰æ›´å¹¿æ³›çš„åº”ç”¨èŒƒå›´ã€‚  

æ— çŠ¶æ€ç¯å¢ƒçš„å¦ä¸€ä¸ªä¼˜ç‚¹æ˜¯å®ƒä»¬å¯ä»¥æ‰¹é‡æ‰§è¡Œè½¬æ¢æ¨¡æ‹Ÿã€‚å¦‚æœåç«¯å’Œå®ç°å…è®¸ï¼Œå¯ä»¥åœ¨æ ‡é‡ã€å‘é‡æˆ–å¼ é‡ä¸Šæ— ç¼æ‰§è¡Œä»£æ•°è¿ç®—ã€‚æœ¬æ•™ç¨‹ç»™å‡ºäº†è¿™æ ·çš„ä¾‹å­ã€‚

æœ¬æ•™ç¨‹çš„ç»“æ„å¦‚ä¸‹ï¼š
* æˆ‘ä»¬é¦–å…ˆè¦ç†Ÿæ‚‰ç¯å¢ƒå±æ€§ï¼šå®ƒçš„å½¢çŠ¶ï¼ˆbatch_sizeï¼‰ï¼Œå®ƒçš„æ–¹æ³•ï¼ˆä¸»è¦æ˜¯step()ï¼Œ reset()å’Œset_seed()ï¼‰ï¼Œæœ€åæ˜¯å®ƒçš„è§„åˆ™ã€‚ 
* å†™å¥½æ¨¡æ‹Ÿå™¨åï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•åœ¨è½¬æ¢è®­ç»ƒæœŸé—´ä½¿ç”¨å®ƒã€‚
* æˆ‘ä»¬å°†æ¢ç´¢ TorchRL API çš„æ–°é€”å¾„ï¼ŒåŒ…æ‹¬ï¼šè½¬æ¢è¾“å…¥çš„å¯èƒ½æ€§ã€æ¨¡æ‹Ÿçš„çŸ¢é‡åŒ–æ‰§è¡Œä»¥åŠé€šè¿‡æ¨¡æ‹Ÿå›¾åå‘ä¼ æ’­çš„å¯èƒ½æ€§ã€‚
* æœ€åï¼Œæˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªç®€å•çš„ç­–ç•¥æ¥è§£å†³æˆ‘ä»¬å®ç°çš„ç³»ç»Ÿã€‚

```
from collections import defaultdict
from typing import Optional

import numpy as np
import torch
import tqdm
from tensordict import TensorDict, TensorDictBase
from tensordict.nn import TensorDictModule
from torch import nn

from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec
from torchrl.envs import (
    CatTensors,
    EnvBase,
    Transform,
    TransformedEnv,
    UnsqueezeTransform,
)
from torchrl.envs.transforms.transforms import _apply_to_composite
from torchrl.envs.utils import check_env_specs, step_mdp

DEFAULT_X = np.pi
DEFAULT_Y = 1.0
```
è®¾è®¡æ–°ç¯å¢ƒç±»æ—¶å¿…é¡»æ³¨æ„å››ä»¶äº‹ï¼š 
* EnvBase._reset()ï¼Œè¯¥ä»£ç ç”¨äºå°†æ¨¡æ‹Ÿå™¨é‡ç½®ä¸ºï¼ˆå¯èƒ½æ˜¯éšæœºçš„ï¼‰åˆå§‹çŠ¶æ€ï¼›
* EnvBase._step()çŠ¶æ€è½¬æ¢åŠ¨æ€ä»£ç ï¼›
* EnvBase._set_seed`()å®æ–½ç§å­æœºåˆ¶ï¼›
* ç¯å¢ƒè§„åˆ™ 

è®©æˆ‘ä»¬é¦–å…ˆæè¿°å½“å‰çš„é—®é¢˜ï¼šæˆ‘ä»¬æƒ³è¦æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„é’Ÿæ‘†ï¼Œé€šè¿‡å®ƒæˆ‘ä»¬å¯ä»¥æ§åˆ¶æ–½åŠ åœ¨å…¶å›ºå®šç‚¹ä¸Šçš„æ‰­çŸ©ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†æ‘†é”¤ç½®äºå‘ä¸Šä½ç½®ï¼ˆæŒ‰ç…§æƒ¯ä¾‹ï¼Œè§’åº¦ä½ç½®ä¸º 0ï¼‰å¹¶ä½¿å…¶é™æ­¢åœ¨è¯¥ä½ç½®ã€‚ä¸ºäº†è®¾è®¡æˆ‘ä»¬çš„åŠ¨æ€ç³»ç»Ÿï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸¤ä¸ªæ–¹ç¨‹ï¼šåŠ¨ä½œï¼ˆæ–½åŠ çš„æ‰­çŸ©ï¼‰åçš„è¿åŠ¨æ–¹ç¨‹å’Œæ„æˆæˆ‘ä»¬ç›®æ ‡å‡½æ•°çš„å¥–åŠ±æ–¹ç¨‹ã€‚

å¯¹äºè¿åŠ¨æ–¹ç¨‹ï¼Œæˆ‘ä»¬å°†æ›´æ–°è§’é€Ÿåº¦å¦‚ä¸‹ï¼š
$$
\dot{\theta}_{t+1} = \dot{\theta}_t + dt \left( \frac{G}{L} \sin(\theta) + \frac{u}{mL^2} \right)
$$
å…¬å¼ä¸­ğœƒç‚¹æ˜¯ä»¥ rad/sec ä¸ºå•ä½çš„è§’é€Ÿåº¦ï¼Œğºæ˜¯å¼•åŠ›ï¼Œğ¿æ˜¯æ‘†çš„é•¿åº¦ï¼Œmæ˜¯å®ƒçš„è´¨é‡ï¼Œ ğœƒæ˜¯å®ƒçš„è§’ä½ç½®å¹¶ä¸”
uæ˜¯æ‰­çŸ©ã€‚ç„¶åæ ¹æ®ä»¥ä¸‹å…¬å¼æ›´æ–°è§’ä½ç½®ï¼š
$$
\theta_{t+1} = \theta + dt \cdot \dot{\theta}_{t+1}
$$  
(ä¸ä¼šå†™ä¸‹æ ‡ï¼Œå‡‘æ´»çœ‹)

å®šä¹‰å¥–åŠ±æ–¹ç¨‹ï¼š
$$
r = -({\theta}^2+0.1*\dot{\theta}^2+0.001*u^2)
$$

å½“è§’åº¦æ¥è¿‘ 0ï¼ˆæ‘†å¤„äºå‘ä¸Šä½ç½®ï¼‰ã€è§’é€Ÿåº¦æ¥è¿‘ 0ï¼ˆæ— è¿åŠ¨ï¼‰ä¸”æ‰­çŸ©ä¹Ÿä¸º 0 æ—¶ï¼Œè¯¥å€¼å°†æœ€å¤§åŒ–ã€‚

## å¯¹åŠ¨ä½œçš„æ•ˆæœè¿›è¡Œç¼–ç ï¼š_step()
æ­¥è¿›çš„æ–¹æ³•æ˜¯é¦–è¦è€ƒè™‘çš„äº‹ï¼Œå› ä¸ºä»–æ˜¯å¯¹æˆ‘ä»¬æ„Ÿå…´è¶£äº‹åŠ¡çš„ç¼–ç ã€‚åœ¨ TorchRL ä¸­ï¼Œ EnvBaseè¯¥ç±»æœ‰ä¸€ä¸ªEnvBase.step() æ–¹æ³•ï¼Œç”¨äºæ¥æ”¶ä¸€ä¸ªtensordict.TensorDict å®ä¾‹ï¼Œè¯¥"action"å®ä¾‹å¸¦æœ‰ä¸€ä¸ªæŒ‡ç¤ºè¦é‡‡å–ä»€ä¹ˆæ“ä½œçš„æ¡ç›®ã€‚  

ä¸ºäº†åœ¨tensordictä¸­æ–¹ä¾¿è¯»å–å’Œå†™å…¥ï¼Œç¡®ä¿å¯†é’¥ä¸åº“æ‰€æœŸæœ›çš„ä¸€è‡´ï¼Œæ¨¡æ‹Ÿéƒ¨åˆ†å·²å§”æ‰˜ç»™ä¸€ä¸ªç§æœ‰æŠ½è±¡æ–¹æ³•_step()ï¼Œ è¯¥æ–¹æ³•ä»ä¸€ä¸ªtensordict è¯»å–è¾“å…¥æ•°æ®ï¼Œå¹¶ä½¿ç”¨è¾“å‡ºæ•°æ®å†™å…¥æ–°çš„ tensordictæ•°æ®ã€‚  

è¯¥_step()æ–¹æ³•åº”è¯¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
* è¯»å–è¾“å…¥æŒ‰é”®ï¼ˆå¦‚"action"ï¼‰å¹¶æ®æ­¤æ‰§è¡Œæ¨¡æ‹Ÿ 
* æ£€ç´¢è§‚å¯Ÿç»“æœã€å®ŒæˆçŠ¶æ€å’Œå¥–åŠ±
* å°†è§‚å¯Ÿå€¼é›†ä»¥åŠå¥–åŠ±å’Œå®ŒæˆçŠ¶æ€å†™å…¥æ–°çš„ç›¸å…³TensorDictä¸­  

æ¥ä¸‹æ¥step()æ–¹æ³•å°†åˆå¹¶tensordictçš„è¾“å…¥ä¸step()çš„è¾“å‡ºï¼Œç¡®ä¿è¾“å…¥è¾“å‡ºçš„ä¸€è‡´æ€§ã€‚  
é€šå¸¸ï¼Œå¯¹äºæœ‰çŠ¶æ€ç¯å¢ƒï¼Œè¿™å°†å¦‚ä¸‹æ‰€ç¤ºï¼š 
```
>>> policy(env.reset())
>>> print(tensordict)
TensorDict(
    fields={
        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        observation: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
>>> env.step(tensordict)
>>> print(tensordict)
TensorDict(
    fields={
        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        next: TensorDict(
            fields={
                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
                observation: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),
                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},
            batch_size=torch.Size([]),
            device=cpu,
            is_shared=False),
        observation: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
``` 
è¯·æ³¨æ„ï¼Œæ ¹tensordictæ²¡æœ‰å˜åŒ–,å”¯ä¸€çš„ä¿®æ”¹æ˜¯å‡ºç°äº†ä¸€ä¸ªæ–°çš„â€˜nextâ€™æ¡ç›®ï¼Œå…¶ä¸­åŒ…å«äº†æ–°ä¿¡æ¯ã€‚  
åœ¨é’Ÿæ‘†ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬çš„_step()æ–¹æ³•å°†ä»è¾“å…¥ä¸­è¯»å–ç›¸å…³æ¡ç›®ï¼Œå¹¶åœ¨å°†æŒ‰é”®ç¼–ç ï¼ˆ"action" key è¡Œä¸ºæŒ‰é”®ï¼‰çš„åŠ›æ–½åŠ åˆ°é’Ÿæ‘†ä¸Štensordictåè®¡ç®—é’Ÿæ‘†çš„ä½ç½®å’Œé€Ÿåº¦ã€‚æˆ‘ä»¬å°†æ‘†é”¤çš„æ–°è§’ä½ç½®è®¡ç®— ä¸ºå…ˆå‰ä½ç½®åŠ ä¸Šä¸€æ®µæ—¶é—´é—´éš”å†…çš„æ–°é€Ÿåº¦"new_th"çš„ç»“æœã€‚ 

ç”±äºæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†é’Ÿæ‘†å‘ä¸Šè½¬åŠ¨å¹¶å°†å…¶ä¿æŒåœ¨è¯¥ä½ç½®ï¼Œå› æ­¤costå¯¹äºæ¥è¿‘ç›®æ ‡çš„ä½ç½®å’Œä½é€Ÿï¼Œæˆ‘ä»¬çš„ï¼ˆè´Ÿå¥–åŠ±ï¼‰å‡½æ•°è¾ƒä½ã€‚äº‹å®ä¸Šï¼Œæˆ‘ä»¬å¸Œæœ›é˜»æ­¢è¿œç¦»â€œå‘ä¸Šâ€çš„ä½ç½®å’Œ/æˆ–è¿œç¦» 0 çš„é€Ÿåº¦ã€‚

åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼ŒEnvBase._step()ç”±äºæˆ‘ä»¬çš„ç¯å¢ƒæ˜¯æ— çŠ¶æ€çš„ï¼Œå› æ­¤è¢«ç¼–ç ä¸ºé™æ€æ–¹æ³•ã€‚åœ¨æœ‰çŠ¶æ€è®¾ç½®ä¸­ï¼Œselféœ€è¦è¯¥å‚æ•°ï¼Œå› ä¸ºéœ€è¦ä»ç¯å¢ƒä¸­è¯»å–çŠ¶æ€ã€‚
```
def _step(tensordict):
    th, thdot = tensordict["th"], tensordict["thdot"]  # th := theta

    g_force = tensordict["params", "g"]
    mass = tensordict["params", "m"]
    length = tensordict["params", "l"]
    dt = tensordict["params", "dt"]
    u = tensordict["action"].squeeze(-1)
    u = u.clamp(-tensordict["params", "max_torque"], tensordict["params", "max_torque"])
    costs = angle_normalize(th) ** 2 + 0.1 * thdot**2 + 0.001 * (u**2)

    new_thdot = (
        thdot
        + (3 * g_force / (2 * length) * th.sin() + 3.0 / (mass * length**2) * u) * dt
    )
    new_thdot = new_thdot.clamp(
        -tensordict["params", "max_speed"], tensordict["params", "max_speed"]
    )
    new_th = th + new_thdot * dt
    reward = -costs.view(*tensordict.shape, 1)
    done = torch.zeros_like(reward, dtype=torch.bool)
    out = TensorDict(
        {
            "th": new_th,
            "thdot": new_thdot,
            "params": tensordict["params"],
            "reward": reward,
            "done": done,
        },
        tensordict.shape,
    )
    return out


def angle_normalize(x):
    return ((x + torch.pi) % (2 * torch.pi)) - torch.pi
```
## é‡ç½®æ¨¡æ‹Ÿå™¨ï¼š_reset()
æˆ‘ä»¬éœ€è¦å…³å¿ƒçš„ç¬¬äºŒä¸ªæ–¹æ³•æ˜¯ _reset()æ–¹æ³•ã€‚å°±åƒ _step()ï¼Œå®ƒåº”è¯¥åœ¨å®ƒçš„è¾“å‡ºä¸­å†™å…¥è§‚å¯Ÿæ¡ç›®å’Œå¯èƒ½çš„å®ŒæˆçŠ¶æ€ï¼ˆå¦‚æœçœç•¥å®ŒæˆçŠ¶æ€ï¼Œå®ƒå°†ç”±çˆ¶æ–¹æ³• tensordictå¡«å……å¤±è´¥ï¼‰ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œresetæ–¹æ³•éœ€è¦ä»è°ƒç”¨å®ƒçš„å‡½æ•°æ¥æ”¶å‘½ä»¤ï¼ˆä¾‹å¦‚ï¼Œåœ¨å¤šæ™ºèƒ½ä½“è®¾ç½®ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦æŒ‡æ˜å“ªäº›æ™ºèƒ½ä½“éœ€è¦è¢«é‡ç½®ï¼‰ã€‚ è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆ_resetåŒæ ·éœ€è¦ä¸€ä¸ªtensordictä½œä¸ºè¾“å…¥å‚æ•°ã€‚ï¼Œå°½ç®¡å®ƒå¯èƒ½å®Œå…¨ä¸ºç©ºã€‚  
çˆ¶çº§EnvBase.reset()ä¼šåƒEnvBase.step()ä¸€æ ·æ‰§è¡Œä¸€äº›ç®€å•çš„æ£€æŸ¥ ï¼Œä¾‹å¦‚ç¡®ä¿"done"è¾“å‡ºä¸­è¿”å›çŠ¶æ€tensordictä»¥åŠå½¢çŠ¶ä¸è§„åˆ™ä¸­çš„é¢„æœŸç›¸åŒ¹é…ã€‚   
å¯¹äºæˆ‘ä»¬æ¥è¯´ï¼Œå”¯ä¸€éœ€è¦è€ƒè™‘çš„é‡è¦äº‹æƒ…æ˜¯æ˜¯å¦ EnvBase._reset()åŒ…å«æ‰€æœ‰é¢„æœŸçš„è§‚å¯Ÿç»“æœã€‚ç”±äºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨æ— çŠ¶æ€ç¯å¢ƒï¼Œå› æ­¤æˆ‘ä»¬å°†é’Ÿæ‘†çš„é…ç½®ä¼ é€’åˆ°åµŒå¥—çš„tensordictåä¸º"params".   
åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ä¼ é€’å®ŒæˆçŠ¶æ€ï¼Œå› ä¸ºè¿™ä¸æ˜¯å¼ºåˆ¶æ€§çš„ï¼Œ_reset()è€Œä¸”æˆ‘ä»¬çš„ç¯å¢ƒæ˜¯éç»ˆæ­¢çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬æ€»æ˜¯æœŸæœ›å®ƒæ˜¯Falseã€‚
```
def _reset(self, tensordict):
    if tensordict is None or tensordict.is_empty():
        # if no ``tensordict`` is passed, we generate a single set of hyperparameters
        # Otherwise, we assume that the input ``tensordict`` contains all the relevant
        # parameters to get started.
        tensordict = self.gen_params(batch_size=self.batch_size)

    high_th = torch.tensor(DEFAULT_X, device=self.device)
    high_thdot = torch.tensor(DEFAULT_Y, device=self.device)
    low_th = -high_th
    low_thdot = -high_thdot

    # for non batch-locked environments, the input ``tensordict`` shape dictates the number
    # of simulators run simultaneously. In other contexts, the initial
    # random state's shape will depend upon the environment batch-size instead.
    th = (
        torch.rand(tensordict.shape, generator=self.rng, device=self.device)
        * (high_th - low_th)
        + low_th
    )
    thdot = (
        torch.rand(tensordict.shape, generator=self.rng, device=self.device)
        * (high_thdot - low_thdot)
        + low_thdot
    )
    out = TensorDict(
        {
            "th": th,
            "thdot": thdot,
            "params": tensordict["params"],
        },
        batch_size=tensordict.shape,
    )
    return out
```  
## ç¯å¢ƒå…ƒæ•°æ® env.*_spec
è§„åˆ™å®šä¹‰äº†ç¯å¢ƒçš„è¾“å…¥å’Œè¾“å‡ºåŸŸã€‚è§„åˆ™å‡†ç¡®å®šä¹‰å°†åœ¨è¿è¡Œæ—¶æ¥æ”¶çš„å¼ é‡éå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸ç”¨äºæºå¸¦æœ‰å…³å¤šå¤„ç†å’Œå¤šè¿›ç¨‹ä¸­çš„ç¯å¢ƒçš„ä¿¡æ¯ã€‚å®ƒä»¬è¿˜å¯ä»¥ç”¨äºå®ä¾‹åŒ–å»¶è¿Ÿå®šä¹‰çš„ç¥ç»ç½‘ç»œå’Œæµ‹è¯•è„šæœ¬ï¼Œè€Œæ— éœ€å®é™…æŸ¥è¯¢ç¯å¢ƒï¼ˆä¾‹å¦‚ï¼Œå¯¹äºç°å®ä¸–ç•Œçš„ç‰©ç†ç³»ç»Ÿæ¥è¯´ï¼Œè¿™å¯èƒ½æˆæœ¬é«˜æ˜‚ï¼‰ã€‚  
æˆ‘ä»¬å¿…é¡»åœ¨æˆ‘ä»¬çš„ç¯å¢ƒä¸­ç¼–å†™å››ä¸ªè§„èŒƒï¼š
* EnvBase.observation_spec: è¿™å°†æ˜¯ä¸€ä¸ªCompositeSpec å®ä¾‹ï¼Œå…¶ä¸­æ¯ä¸ªé”®éƒ½æ˜¯ä¸€ä¸ªè§‚å¯Ÿå€¼ï¼ˆCompositeSpecå¯ä»¥è¢«è§†ä¸ºè§„åˆ™å­—å…¸ï¼‰ã€‚
* EnvBase.action_spec: å¯ä»¥æ˜¯ä»»æ„ç±»å‹çš„specï¼Œä½†è¦æ±‚ä¸"action"inputä¸­çš„æ¡ç›®å¯¹åº”tensordictï¼›
* EnvBase.reward_spec:æä¾›æœ‰å…³å¥–åŠ±ç©ºé—´çš„ä¿¡æ¯ï¼›
* EnvBase.done_spec:æä¾›æœ‰å…³å®ŒæˆçŠ¶æ€çš„ä¿¡æ¯ã€‚
TorchRL è§„åˆ™è¢«ç»„ç»‡åœ¨ä¸¤ä¸ªé€šç”¨å®¹å™¨ä¸­ï¼šinput_specå…¶ä¸­åŒ…å«æ­¥éª¤å‡½æ•°è¯»å–çš„ä¿¡æ¯è§„åˆ™ï¼ˆåˆ†ä¸ºaction_specåŒ…å«æ“ä½œå’Œstate_specåŒ…å«æ‰€æœ‰å…¶ä½™å†…å®¹ï¼‰ã€‚ä»¥åŠoutput_specå¯¹æ­¥éª¤è¾“å‡ºçš„è§„åˆ™è¿›è¡Œç¼–ç ï¼ˆobservation_specã€reward_specå’Œdone_specï¼‰ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæ‚¨ä¸åº”è¯¥ç›´æ¥ä¸output_specå’Œ input_specçš„äº¤äº’ï¼Œè€Œæ˜¯åº”è¯¥å’Œä»–ä»¬çš„å†…å®¹äº¤äº’: observation_spec, reward_spec, done_spec, action_spec and state_specã€‚åŸå› æ˜¯è§„åˆ™å¯èƒ½æ˜¯ä»¥éæ­£å¸¸æ–¹å¼æ„å»ºçš„ï¼Œoutput_spec and input_specéƒ½ä¸åº”è¯¥è¢«ç›´æ¥ä¿®æ”¹ã€‚  

æ¢å¥è¯è¯´ï¼Œobservation_specå’Œç›¸å…³å±æ€§æ˜¯è¾“å‡ºå’Œè¾“å…¥è§„èŒƒå®¹å™¨å†…å®¹çš„ä¾¿æ·å¿«æ·æ–¹å¼ã€‚  
TorchRL æä¾›å¤šä¸ªTensorSpec å­ç±»æ¥ç¼–ç ç¯å¢ƒçš„è¾“å…¥å’Œè¾“å‡ºç‰¹å¾ã€‚  

## Specs shape
ç¯å¢ƒè§„åˆ™ä¸»è¦å°ºå¯¸å¿…é¡»ä¸ç¯å¢ƒæ‰¹é‡å¤§å°ç›¸åŒ¹é…ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å¼ºåˆ¶ç¯å¢ƒçš„æ¯ä¸ªç»„ä»¶ï¼ˆåŒ…æ‹¬å…¶è½¬æ¢ï¼‰éƒ½èƒ½å¤Ÿå‡†ç¡®è¡¨ç¤ºé¢„æœŸçš„è¾“å…¥å’Œè¾“å‡ºå½¢çŠ¶ã€‚è¿™æ˜¯åº”è¯¥åœ¨æœ‰çŠ¶æ€è®¾ç½®ä¸­å‡†ç¡®ç¼–ç çš„å†…å®¹ã€‚  

å¯¹äºéæ‰¹é‡é”å®šç¯å¢ƒï¼Œä¾‹å¦‚æˆ‘ä»¬ç¤ºä¾‹ä¸­çš„ç¯å¢ƒï¼ˆè§ä¸‹æ–‡ï¼‰ï¼Œè¿™æ˜¯æ— å…³ç´§è¦çš„ï¼Œå› ä¸ºç¯å¢ƒæ‰¹é‡å¤§å°å¾ˆå¯èƒ½ä¸ºç©ºã€‚
```
def _make_spec(self, td_params):
    # Under the hood, this will populate self.output_spec["observation"]
    self.observation_spec = CompositeSpec(
        th=BoundedTensorSpec(
            low=-torch.pi,
            high=torch.pi,
            shape=(),
            dtype=torch.float32,
        ),
        thdot=BoundedTensorSpec(
            low=-td_params["params", "max_speed"],
            high=td_params["params", "max_speed"],
            shape=(),
            dtype=torch.float32,
        ),
        # we need to add the ``params`` to the observation specs, as we want
        # to pass it at each step during a rollout
        params=make_composite_from_td(td_params["params"]),
        shape=(),
    )
    # since the environment is stateless, we expect the previous output as input.
    # For this, ``EnvBase`` expects some state_spec to be available
    self.state_spec = self.observation_spec.clone()
    # action-spec will be automatically wrapped in input_spec when
    # `self.action_spec = spec` will be called supported
    self.action_spec = BoundedTensorSpec(
        low=-td_params["params", "max_torque"],
        high=td_params["params", "max_torque"],
        shape=(1,),
        dtype=torch.float32,
    )
    self.reward_spec = UnboundedContinuousTensorSpec(shape=(*td_params.shape, 1))


def make_composite_from_td(td):
    # custom function to convert a ``tensordict`` in a similar spec structure
    # of unbounded values.
    composite = CompositeSpec(
        {
            key: make_composite_from_td(tensor)
            if isinstance(tensor, TensorDictBase)
            else UnboundedContinuousTensorSpec(
                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape
            )
            for key, tensor in td.items()
        },
        shape=td.shape,
    )
    return composite
```
## å¯é‡å¤çš„å®éªŒï¼šæ’­ç§  
åˆå§‹åŒ–ç¯å¢ƒæ—¶æ’­ç§ç¯å¢ƒæ˜¯ä¸€é¡¹å¸¸è§æ“ä½œã€‚å”¯ä¸€çš„ç›®æ ‡EnvBase._set_seed()æ˜¯è®¾ç½®æ‰€åŒ…å«æ¨¡æ‹Ÿå™¨çš„ç§å­ã€‚å¦‚æœå¯èƒ½ï¼Œæ­¤æ“ä½œä¸åº”è°ƒç”¨ç¯å¢ƒæ‰§è¡Œreset()æˆ–ä¸ç¯å¢ƒæ‰§è¡Œäº¤äº’ã€‚çˆ¶EnvBase.set_seed()æ–¹æ³•é‡‡ç”¨äº†ä¸€ç§æœºåˆ¶ï¼Œå…è®¸ä½¿ç”¨ä¸åŒçš„ä¼ªéšæœºä¸”å¯é‡ç°çš„ç§å­æ’­ç§å¤šä¸ªç¯å¢ƒã€‚  
```
def _set_seed(self, seed: Optional[int]):
    rng = torch.manual_seed(seed)
    self.rng = rng
```

## å°†äº‹ç‰©åŒ…è£…åœ¨ä¸€èµ·ï¼šEnvBaseç±» 

æˆ‘ä»¬ç»ˆäºå¯ä»¥å°†å„ä¸ªéƒ¨åˆ†ç»„åˆåœ¨ä¸€èµ·å¹¶è®¾è®¡æˆ‘ä»¬çš„ç¯å¢ƒç±»ã€‚ç¯å¢ƒæ„å»ºè¿‡ç¨‹ä¸­éœ€è¦è¿›è¡Œspecsåˆå§‹åŒ–ï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»æ³¨æ„_make_spec()è°ƒç”¨PendulumEnv.__init__().

æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªé™æ€æ–¹æ³•PendulumEnv.gen_params()ï¼Œå®ƒç¡®å®šæ€§åœ°ç”Ÿæˆä¸€ç»„åœ¨æ‰§è¡ŒæœŸé—´ä½¿ç”¨çš„è¶…å‚æ•°ï¼š 
```
def gen_params(g=10.0, batch_size=None) -> TensorDictBase:
    """Returns a ``tensordict`` containing the physical parameters such as gravitational force and torque or speed limits."""
    if batch_size is None:
        batch_size = []
    td = TensorDict(
        {
            "params": TensorDict(
                {
                    "max_speed": 8,
                    "max_torque": 2.0,
                    "dt": 0.05,
                    "g": g,
                    "m": 1.0,
                    "l": 1.0,
                },
                [],
            )
        },
        [],
    )
    if batch_size:
        td = td.expand(batch_size).contiguous()
    return td
```
batch_lockedæˆ‘ä»¬é€šè¿‡å°†homonymous å±æ€§è½¬æ¢ä¸º æ¥å°†ç¯å¢ƒå®šä¹‰ä¸ºéFalseã€‚è¿™æ„å‘³ç€æˆ‘ä»¬ä¸ä¼šå¼ºåˆ¶è¾“å…¥ tensordictä¸batch-sizeç¯å¢ƒç›¸åŒ¹é…ã€‚

ä¸‹é¢çš„ä»£ç å°†æŠŠæˆ‘ä»¬ä¸Šé¢ç¼–ç çš„éƒ¨åˆ†ç»„åˆåœ¨ä¸€èµ·ã€‚  
```
class PendulumEnv(EnvBase):
    metadata = {
        "render_modes": ["human", "rgb_array"],
        "render_fps": 30,
    }
    batch_locked = False

    def __init__(self, td_params=None, seed=None, device="cpu"):
        if td_params is None:
            td_params = self.gen_params()

        super().__init__(device=device, batch_size=[])
        self._make_spec(td_params)
        if seed is None:
            seed = torch.empty((), dtype=torch.int64).random_().item()
        self.set_seed(seed)

    # Helpers: _make_step and gen_params
    gen_params = staticmethod(gen_params)
    _make_spec = _make_spec

    # Mandatory methods: _step, _reset and _set_seed
    _reset = _reset
    _step = staticmethod(_step)
    _set_seed = _set_seed
```
## æµ‹è¯•æˆ‘ä»¬çš„ç¯å¢ƒ 
TorchRL æä¾›äº†ä¸€ä¸ªç®€å•çš„å‡½æ•°check_env_specs() æ¥æ£€æŸ¥ï¼ˆè½¬æ¢åçš„ï¼‰ç¯å¢ƒæ˜¯å¦å…·æœ‰ä¸å…¶è§„èŒƒè§„å®šçš„è¾“å…¥/è¾“å‡ºç»“æ„ç›¸åŒ¹é…çš„è¾“å…¥/è¾“å‡ºç»“æ„ã€‚è®©æˆ‘ä»¬å°è¯•ä¸€ä¸‹ï¼š
```
env = PendulumEnv()
check_env_specs(env)
```
æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹æˆ‘ä»¬çš„è§„èŒƒï¼Œä»¥ç›´è§‚åœ°è¡¨ç¤ºç¯å¢ƒç­¾åï¼š  
```
print("observation_spec:", env.observation_spec)
print("state_spec:", env.state_spec)
print("reward_spec:", env.reward_spec)
```
æˆ‘ä»¬ä¹Ÿå¯ä»¥æ‰§è¡Œå‡ ä¸ªå‘½ä»¤æ¥æ£€æŸ¥è¾“å‡ºç»“æ„æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚
```
td = env.reset()
print("reset tensordict", td)
```
æˆ‘ä»¬å¯ä»¥è¿è¡Œenv.rand_step()ä»åŸŸä¸­éšæœºç”Ÿæˆä¸€ä¸ªåŠ¨ä½œaction_specã€‚ç”±äºæˆ‘ä»¬çš„ç¯å¢ƒæ˜¯æ— çŠ¶æ€çš„ï¼Œå› æ­¤å¿…é¡»ä¼ é€’tensordictåŒ…å«è¶…å‚æ•°å’Œå½“å‰çŠ¶æ€çš„A ã€‚åœ¨æœ‰çŠ¶æ€çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œenv.rand_step()ä¹Ÿèƒ½å®Œç¾å·¥ä½œã€‚
```
td = env.rand_step(td)
print("random step tensordict", td)
```

## è½¬æ¢ç¯å¢ƒ
ä¸ºæ— çŠ¶æ€æ¨¡æ‹Ÿå™¨ç¼–å†™ç¯å¢ƒè½¬æ¢æ¯”æœ‰çŠ¶æ€æ¨¡æ‹Ÿå™¨ç¨å¾®å¤æ‚ä¸€äº›ï¼šè½¬æ¢éœ€è¦åœ¨ä»¥ä¸‹è¿­ä»£ä¸­è¯»å–çš„è¾“å‡ºæ¡ç›®éœ€è¦åœ¨meth.step()ä¸‹ä¸€æ­¥è°ƒç”¨ä¹‹å‰åº”ç”¨é€†å˜æ¢ã€‚è¿™æ˜¯å±•ç¤º TorchRL å˜æ¢çš„æ‰€æœ‰åŠŸèƒ½çš„ç†æƒ³åœºæ™¯ï¼ 
ä¾‹å¦‚ï¼Œåœ¨ä¸‹é¢çš„è½¬æ¢ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬çš„unsqueezeæ¡ç›® èƒ½å¤Ÿæ²¿ç€æœ€åä¸€ä¸ªç»´åº¦å †å å®ƒä»¬ã€‚ä¸€æ—¦å®ƒä»¬ä½œä¸ºä¸‹ä¸€æ¬¡è¿­ä»£çš„è¾“å…¥ä¼ é€’ï¼Œæˆ‘ä»¬è¿˜å°†å®ƒä»¬ä¼ é€’ä¸ºå°†å®ƒä»¬å‹ç¼©å›åŸå§‹å½¢çŠ¶ã€‚ 
```
env = TransformedEnv(
    env,
    # ``Unsqueeze`` the observations that we will concatenate
    UnsqueezeTransform(
        unsqueeze_dim=-1,
        in_keys=["th", "thdot"],
        in_keys_inv=["th", "thdot"],
    ),
)
```

## ç¼–å†™è‡ªå®šä¹‰è½¬æ¢
TorchRL çš„è½¬æ¢å¯èƒ½æ— æ³•æ¶µç›–ç¯å¢ƒæ‰§è¡Œåæƒ³è¦æ‰§è¡Œçš„æ‰€æœ‰æ“ä½œã€‚ç¼–å†™è½¬æ¢å¹¶ä¸éœ€è¦å¤ªå¤šåŠªåŠ›ã€‚è‡³äºç¯å¢ƒè®¾è®¡ï¼Œç¼–å†™è½¬æ¢æœ‰ä¸¤ä¸ªæ­¥éª¤ï¼š
* è·å¾—æ­£ç¡®çš„åŠ¨ä½œï¼ˆæ­£å‘å’Œåå‘ï¼‰
* èƒ½å¤Ÿé€‚åº”ç¯å¢ƒçš„è§„åˆ™  
è½¬æ¢å¯ä»¥åœ¨ä¸¤ç§è®¾ç½®ä¸­ä½¿ç”¨ï¼šå°±å…¶æœ¬èº«è€Œè¨€ï¼Œå®ƒå¯ä»¥ç”¨ä½œ Module.å®ƒä¹Ÿå¯ä»¥é™„åŠ åˆ° TransformedEnv.ç±»çš„ç»“æ„å…è®¸è‡ªå®šä¹‰ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„è¡Œä¸ºã€‚ä¸€ä¸ªTransforméª¨æ¶å¯ä»¥æ¦‚æ‹¬å¦‚ä¸‹ï¼š
```
class Transform(nn.Module):
    def forward(self, tensordict):
        ...
    def _apply_transform(self, tensordict):
        ...
    def _step(self, tensordict):
        ...
    def _call(self, tensordict):
        ...
    def inv(self, tensordict):
        ...
    def _inv_apply_transform(self, tensordict):
        ...
```
å…±æœ‰ä¸‰ä¸ªå…¥å£ç‚¹ï¼ˆforward()ã€_step()å’Œinv()ï¼‰ï¼Œå®ƒä»¬éƒ½æ¥æ”¶tensordict.TensorDictå®ä¾‹ã€‚å‰ä¸¤ä¸ªæœ€ç»ˆå°†éå†ç”± æŒ‡ç¤ºçš„é”®in_keys å¹¶è°ƒç”¨_apply_transform()å…¶ä¸­çš„æ¯ä¸€ä¸ªã€‚å¦‚æœæä¾›çš„è¯ï¼Œç»“æœå°†å†™å…¥æ‰€æŒ‡å‘çš„æ¡ç›®ä¸­Transform.out_keysï¼ˆå¦‚æœæ²¡æœ‰ï¼Œin_keyså°†ä½¿ç”¨è½¬æ¢åçš„å€¼è¿›è¡Œæ›´æ–°ï¼‰ã€‚å¦‚æœéœ€è¦æ‰§è¡Œé€†å˜æ¢ï¼Œåˆ™å°†æ‰§è¡Œç±»ä¼¼çš„æ•°æ®æµï¼Œä½†ä½¿ç”¨Transform.inv()å’Œ Transform._inv_apply_transform()æ–¹æ³•å¹¶è·¨é”®in_keys_inv å’Œout_keys_invåˆ—è¡¨ã€‚ä¸‹å›¾æ€»ç»“äº†ç¯å¢ƒå’Œé‡æ’­ç¼“å†²åŒºçš„æµç¨‹ã€‚  
(æ–‡æ¡£å¹¶æ²¡æœ‰ç»™å›¾å“¥ä»¬)  
åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè½¬æ¢ä¸ä¼šä»¥å•ä¸€æ–¹å¼å¤„ç†é”®çš„å­é›†ï¼Œè€Œæ˜¯ä¼šåœ¨çˆ¶ç¯å¢ƒä¸Šæ‰§è¡ŒæŸäº›æ“ä½œæˆ–å¤„ç†æ•´ä¸ªè¾“å…¥tensordictã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œåº”è¯¥é‡å†™_call()å’Œæ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥è·³è¿‡è¯¥æ–¹æ³•ã€‚forward()_apply_transform()

è®©æˆ‘ä»¬ç¼–å†™æ–°çš„å˜æ¢æ¥è®¡ç®—ä½ç½®è§’åº¦çš„sinå’Œcos å€¼ï¼Œå› ä¸ºè¿™äº›å€¼æ¯”åŸå§‹è§’åº¦å€¼æ›´æœ‰åŠ©äºæˆ‘ä»¬å­¦ä¹ ç­–ç•¥ã€‚
```
class SinTransform(Transform):
    def _apply_transform(self, obs: torch.Tensor) -> None:
        return obs.sin()

    # The transform must also modify the data at reset time
    def _reset(
        self, tensordict: TensorDictBase, tensordict_reset: TensorDictBase
    ) -> TensorDictBase:
        return self._call(tensordict_reset)

    # _apply_to_composite will execute the observation spec transform across all
    # in_keys/out_keys pairs and write the result in the observation_spec which
    # is of type ``Composite``
    @_apply_to_composite
    def transform_observation_spec(self, observation_spec):
        return BoundedTensorSpec(
            low=-1,
            high=1,
            shape=observation_spec.shape,
            dtype=observation_spec.dtype,
            device=observation_spec.device,
        )


class CosTransform(Transform):
    def _apply_transform(self, obs: torch.Tensor) -> None:
        return obs.cos()

    # The transform must also modify the data at reset time
    def _reset(
        self, tensordict: TensorDictBase, tensordict_reset: TensorDictBase
    ) -> TensorDictBase:
        return self._call(tensordict_reset)

    # _apply_to_composite will execute the observation spec transform across all
    # in_keys/out_keys pairs and write the result in the observation_spec which
    # is of type ``Composite``
    @_apply_to_composite
    def transform_observation_spec(self, observation_spec):
        return BoundedTensorSpec(
            low=-1,
            high=1,
            shape=observation_spec.shape,
            dtype=observation_spec.dtype,
            device=observation_spec.device,
        )


t_sin = SinTransform(in_keys=["th"], out_keys=["sin"])
t_cos = CosTransform(in_keys=["th"], out_keys=["cos"])
env.append_transform(t_sin)
env.append_transform(t_cos)
```
å°†è§‚å¯Ÿç»“æœè¿æ¥åˆ°â€œè§‚å¯Ÿâ€æ¡ç›®ã€‚ del_keys=Falseç¡®ä¿æˆ‘ä»¬ä¸ºä¸‹ä¸€æ¬¡è¿­ä»£ä¿ç•™è¿™äº›å€¼ã€‚
```
cat_transform = CatTensors(
    in_keys=["sin", "cos", "thdot"], dim=-1, out_key="observation", del_keys=False
)
env.append_transform(cat_transform)
```
è®©æˆ‘ä»¬å†æ¬¡æ£€æŸ¥æˆ‘ä»¬çš„ç¯å¢ƒè§„æ ¼æ˜¯å¦ä¸æ”¶åˆ°çš„è§„æ ¼ç›¸ç¬¦ï¼š
```
check_env_specs(env)
```
## æ‰§è¡Œ 
æ‰§è¡Œéœ€è¦å‡ ä¸ªç®€å•çš„æ­¥éª¤
* é‡ç½®ç¯å¢ƒ
* å½“æŸäº›æ¡ä»¶ä¸æ»¡è¶³æ—¶ï¼š
  * è®¡ç®—ç»™å®šç­–ç•¥çš„æ“ä½œ
  * æ‰§è¡Œç»™å®šæ­¤æ“ä½œçš„æ­¥éª¤
  * æ”¶é›†æ•°æ®
  * è¿ˆå‡ºMDPä¸€æ­¥(?)
* æ”¶é›†æ•°æ®å¹¶è¿”å›  
è¿™äº›æ“ä½œå·²æ–¹ä¾¿åœ°åŒ…è£…åœ¨rollout() æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢æä¾›äº†ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ã€‚
```
def simple_rollout(steps=100):
    # preallocate:
    data = TensorDict({}, [steps])
    # reset
    _data = env.reset()
    for i in range(steps):
        _data["action"] = env.action_spec.rand()
        _data = env.step(_data)
        data[i] = _data
        _data = step_mdp(_data, keep_other=True)
    return data


print("data from rollout:", simple_rollout(100))
```
## Batching è®¡ç®—
æˆ‘ä»¬æ•™ç¨‹çš„æœ€åä¸€ä¸ªæœªæ¢ç´¢çš„éƒ¨åˆ†æ˜¯æˆ‘ä»¬å¿…é¡»åœ¨ TorchRL ä¸­è¿›è¡Œæ‰¹é‡è®¡ç®—çš„èƒ½åŠ›ã€‚ç”±äºæˆ‘ä»¬çš„ç¯å¢ƒä¸å¯¹è¾“å…¥æ•°æ®å½¢çŠ¶åšå‡ºä»»ä½•å‡è®¾ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥åœ¨æ‰¹é‡æ•°æ®ä¸Šæ— ç¼æ‰§è¡Œå®ƒã€‚æ›´å¥½çš„æ˜¯ï¼šå¯¹äºéæ‰¹é‡é”å®šçš„ç¯å¢ƒï¼ˆä¾‹å¦‚æˆ‘ä»¬çš„ Pendulumï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åŠ¨æ€æ›´æ”¹æ‰¹é‡å¤§å°ï¼Œè€Œæ— éœ€é‡æ–°åˆ›å»ºç¯å¢ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åªéœ€ç”Ÿæˆå…·æœ‰æ‰€éœ€å½¢çŠ¶çš„å‚æ•°ã€‚  
```
batch_size = 10  # number of environments to be executed in batch
td = env.reset(env.gen_params(batch_size=[batch_size]))
print("reset (batch size of 10)", td)
td = env.rand_step(td)
print("rand step (batch size of 10)", td)
```
ä½¿ç”¨ä¸€æ‰¹æ•°æ®æ‰§è¡Œ rollout éœ€è¦æˆ‘ä»¬é‡ç½® rollout å‡½æ•°ä¸­çš„ç¯å¢ƒï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦åŠ¨æ€å®šä¹‰ batch_size è€Œè¿™ä¸å—ä»¥ä¸‹æ”¯æŒrollout()ï¼š
```
rollout = env.rollout(
    3,
    auto_reset=False,  # we're executing the reset out of the ``rollout`` call
    tensordict=env.reset(env.gen_params(batch_size=[batch_size])),
)
print("rollout of len 3 (batch size of 10):", rollout)
```

## è®­ç»ƒä¸€ä¸ªç®€å•çš„ç­–ç•¥
åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¥–åŠ±ä½œä¸ºå¯å¾®ç›®æ ‡ï¼ˆä¾‹å¦‚è´ŸæŸå¤±ï¼‰æ¥è®­ç»ƒä¸€ä¸ªç®€å•çš„ç­–ç•¥ã€‚æˆ‘ä»¬å°†åˆ©ç”¨åŠ¨æ€ç³»ç»Ÿå®Œå…¨å¯å¾®çš„äº‹å®ï¼Œé€šè¿‡è½¨è¿¹è¿”å›è¿›è¡Œåå‘ä¼ æ’­ï¼Œå¹¶è°ƒæ•´æˆ‘ä»¬çš„ç­–ç•¥æƒé‡ä»¥ç›´æ¥æœ€å¤§åŒ–è¯¥å€¼ã€‚å½“ç„¶ï¼Œåœ¨è®¸å¤šè®¾ç½®ä¸­ï¼Œæˆ‘ä»¬æ‰€åšçš„è®¸å¤šå‡è®¾éƒ½ä¸æˆç«‹ï¼Œä¾‹å¦‚å¯å¾®åˆ†ç³»ç»Ÿå’Œå¯¹åº•å±‚æœºåˆ¶çš„å®Œå…¨è®¿é—®ã€‚  

å°½ç®¡å¦‚æ­¤ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ç¤ºä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ TorchRL ä¸­çš„è‡ªå®šä¹‰ç¯å¢ƒå¯¹è®­ç»ƒå¾ªç¯è¿›è¡Œç¼–ç ã€‚

æˆ‘ä»¬å…ˆæ¥å†™ä¸€ä¸‹ç­–ç•¥ç½‘ç»œï¼š
```
torch.manual_seed(0)
env.set_seed(0)

net = nn.Sequential(
    nn.LazyLinear(64),
    nn.Tanh(),
    nn.LazyLinear(64),
    nn.Tanh(),
    nn.LazyLinear(64),
    nn.Tanh(),
    nn.LazyLinear(1),
)
policy = TensorDictModule(
    net,
    in_keys=["observation"],
    out_keys=["action"],
)
```
å’Œæˆ‘ä»¬çš„ä¼˜åŒ–å™¨ï¼š
```
optim = torch.optim.Adam(policy.parameters(), lr=2e-3)
```

## è®­ç»ƒå¾ªç¯
æˆ‘ä»¬å°†é™†ç»­ï¼š
* ç”Ÿæˆè½¨è¿¹
* æ€»ç»“å¥–åŠ±
* é€šè¿‡è¿™äº›æ“ä½œå®šä¹‰çš„å›¾è¿›è¡Œåå‘ä¼ æ’­
* è£å‰ªæ¢¯åº¦èŒƒæ•°å¹¶è¿›è¡Œä¼˜åŒ–æ­¥éª¤
* é‡å¤

åœ¨è®­ç»ƒå¾ªç¯ç»“æŸæ—¶ï¼Œæˆ‘ä»¬åº”è¯¥å¾—åˆ°æ¥è¿‘ 0 çš„æœ€ç»ˆå¥–åŠ±ï¼Œè¿™è¡¨æ˜é’Ÿæ‘†æ˜¯å‘ä¸Šçš„å¹¶ä¸”ä»ç„¶ç¬¦åˆé¢„æœŸã€‚
```
batch_size = 32
pbar = tqdm.tqdm(range(20_000 // batch_size))
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, 20_000)
logs = defaultdict(list)

for _ in pbar:
    init_td = env.reset(env.gen_params(batch_size=[batch_size]))
    rollout = env.rollout(100, policy, tensordict=init_td, auto_reset=False)
    traj_return = rollout["next", "reward"].mean()
    (-traj_return).backward()
    gn = torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)
    optim.step()
    optim.zero_grad()
    pbar.set_description(
        f"reward: {traj_return: 4.4f}, "
        f"last reward: {rollout[..., -1]['next', 'reward'].mean(): 4.4f}, gradient norm: {gn: 4.4}"
    )
    logs["return"].append(traj_return.item())
    logs["last_reward"].append(rollout[..., -1]["next", "reward"].mean().item())
    scheduler.step()


def plot():
    import matplotlib
    from matplotlib import pyplot as plt

    is_ipython = "inline" in matplotlib.get_backend()
    if is_ipython:
        from IPython import display

    with plt.ion():
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.plot(logs["return"])
        plt.title("returns")
        plt.xlabel("iteration")
        plt.subplot(1, 2, 2)
        plt.plot(logs["last_reward"])
        plt.title("last reward")
        plt.xlabel("iteration")
        if is_ipython:
            display.display(plt.gcf())
            display.clear_output(wait=True)
        plt.show()


plot()
```

<img src='https://pytorch.org/tutorials/_images/sphx_glr_pendulum_001.png' width=20% />
