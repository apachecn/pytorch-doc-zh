{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.5.1\n"
    }
   ],
   "source": [
    "import torch  # 这就是你所需要用PyTorch和TorchScript的所有。\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(tensor([[0.5902, 0.7705, 0.5580, 0.6256],\n        [0.8927, 0.7611, 0.8371, 0.4690],\n        [0.3907, 0.9546, 0.5320, 0.6729]]), tensor([[0.5902, 0.7705, 0.5580, 0.6256],\n        [0.8927, 0.7611, 0.8371, 0.4690],\n        [0.3907, 0.9546, 0.5320, 0.6729]]))\n"
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(x + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MyCell(\n  (linear): Linear(in_features=4, out_features=4, bias=True)\n)\n(tensor([[ 0.6463,  0.1571, -0.2479,  0.4087],\n        [ 0.7607,  0.6523,  0.7923,  0.3044],\n        [ 0.2479,  0.7824,  0.0745,  0.3718]], grad_fn=<TanhBackward>), tensor([[ 0.6463,  0.1571, -0.2479,  0.4087],\n        [ 0.7607,  0.6523,  0.7923,  0.3044],\n        [ 0.2479,  0.7824,  0.0745,  0.3718]], grad_fn=<TanhBackward>))\n"
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MyCell(\n  (dg): MyDecisionGate()\n  (linear): Linear(in_features=4, out_features=4, bias=True)\n)\n(tensor([[ 0.9448, -0.0326,  0.2476,  0.7876],\n        [ 0.9324,  0.7594,  0.7068,  0.5698],\n        [ 0.8284,  0.7522,  0.5473,  0.7250]], grad_fn=<TanhBackward>), tensor([[ 0.9448, -0.0326,  0.2476,  0.7876],\n        [ 0.9324,  0.7594,  0.7068,  0.5698],\n        [ 0.8284,  0.7522,  0.5473,  0.7250]], grad_fn=<TanhBackward>))\n"
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MyCell(\n  original_name=MyCell\n  (linear): Linear(original_name=Linear)\n)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[ 0.7917, -0.0382,  0.2614,  0.8160],\n         [ 0.5807,  0.6550,  0.6552,  0.9022],\n         [ 0.4418,  0.6988,  0.8347,  0.7276]], grad_fn=<TanhBackward>),\n tensor([[ 0.7917, -0.0382,  0.2614,  0.8160],\n         [ 0.5807,  0.6550,  0.6552,  0.9022],\n         [ 0.4418,  0.6988,  0.8347,  0.7276]], grad_fn=<TanhBackward>))"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell)\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "graph(%self.1 : __torch__.MyCell,\n      %input : Float(3, 4),\n      %h : Float(3, 4)):\n  %19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n  %21 : Tensor = prim::CallMethod[name=\"forward\"](%19, %input)\n  %12 : int = prim::Constant[value=1]() # <ipython-input-5-1f6e08af67d0>:7:0\n  %13 : Float(3, 4) = aten::add(%21, %h, %12) # <ipython-input-5-1f6e08af67d0>:7:0\n  %14 : Float(3, 4) = aten::tanh(%13) # <ipython-input-5-1f6e08af67d0>:7:0\n  %15 : (Float(3, 4), Float(3, 4)) = prim::TupleConstruct(%14, %14)\n  return (%15)\n\n"
    }
   ],
   "source": [
    "print(traced_cell.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "def forward(self,\n    input: Tensor,\n    h: Tensor) -> Tuple[Tensor, Tensor]:\n  _0 = torch.add((self.linear).forward(input, ), h, alpha=1)\n  _1 = torch.tanh(_0)\n  return (_1, _1)\n\n"
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(tensor([[ 0.7917, -0.0382,  0.2614,  0.8160],\n        [ 0.5807,  0.6550,  0.6552,  0.9022],\n        [ 0.4418,  0.6988,  0.8347,  0.7276]], grad_fn=<TanhBackward>), tensor([[ 0.7917, -0.0382,  0.2614,  0.8160],\n        [ 0.5807,  0.6550,  0.6552,  0.9022],\n        [ 0.4418,  0.6988,  0.8347,  0.7276]], grad_fn=<TanhBackward>))\n(tensor([[ 0.7917, -0.0382,  0.2614,  0.8160],\n        [ 0.5807,  0.6550,  0.6552,  0.9022],\n        [ 0.4418,  0.6988,  0.8347,  0.7276]], grad_fn=<TanhBackward>), tensor([[ 0.7917, -0.0382,  0.2614,  0.8160],\n        [ 0.5807,  0.6550,  0.6552,  0.9022],\n        [ 0.4418,  0.6988,  0.8347,  0.7276]], grad_fn=<TanhBackward>))\n"
    }
   ],
   "source": [
    "print(my_cell(x, h))\n",
    "print(traced_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "def forward(self,\n    input: Tensor,\n    h: Tensor) -> Tuple[Tensor, Tensor]:\n  _0 = (self.dg).forward((self.linear).forward(input, ), )\n  _1 = torch.tanh(torch.add(_0, h, alpha=1))\n  return (_1, _1)\n\n"
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "def forward(self,\n    x: Tensor,\n    h: Tensor) -> Tuple[Tensor, Tensor]:\n  _0 = (self.dg).forward((self.linear).forward(x, ), )\n  new_h = torch.tanh(torch.add(_0, h, alpha=1))\n  return (new_h, new_h)\n\n"
    }
   ],
   "source": [
    "scripted_gate = torch.jit.script(MyDecisionGate())\n",
    "\n",
    "my_cell = MyCell(scripted_gate)\n",
    "traced_cell = torch.jit.script(my_cell)\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[0.5520, 0.9338, 0.5911, 0.5728],\n         [0.8312, 0.5042, 0.6719, 0.3194],\n         [0.2192, 0.4774, 0.2456, 0.2004]], grad_fn=<TanhBackward>),\n tensor([[0.5520, 0.9338, 0.5911, 0.5728],\n         [0.8312, 0.5042, 0.6719, 0.3194],\n         [0.2192, 0.4774, 0.2456, 0.2004]], grad_fn=<TanhBackward>))"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# 新的输入\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "def forward(self,\n    xs: Tensor) -> Tuple[Tensor, Tensor]:\n  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n  y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n  y0 = y\n  h0 = h\n  for i in range(torch.size(xs, 0)):\n    _0 = (self.cell).forward(torch.select(xs, 0, i), h0, )\n    y1, h1, = _0\n    y0, h0 = y1, h1\n  return (y0, h0)\n\n"
    }
   ],
   "source": [
    "class MyRNNLoop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNNLoop, self).__init__()\n",
    "        self.cell = torch.jit.trace(MyCell(scripted_gate), (x, h))\n",
    "\n",
    "    def forward(self, xs):\n",
    "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            y, h = self.cell(xs[i], h)\n",
    "        return y, h\n",
    "\n",
    "rnn_loop = torch.jit.script(MyRNNLoop())\n",
    "print(rnn_loop.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "def forward(self,\n    argument_1: Tensor) -> Tensor:\n  _0, y, = (self.loop).forward(argument_1, )\n  return torch.relu(y)\n\n"
    }
   ],
   "source": [
    "class WrapRNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WrapRNN, self).__init__()\n",
    "        self.loop = torch.jit.script(MyRNNLoop())\n",
    "\n",
    "    def forward(self, xs):\n",
    "        y, h = self.loop(xs)\n",
    "        return torch.relu(y)\n",
    "\n",
    "traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4)))\n",
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RecursiveScriptModule(\n  original_name=WrapRNN\n  (loop): RecursiveScriptModule(\n    original_name=MyRNNLoop\n    (cell): RecursiveScriptModule(\n      original_name=MyCell\n      (dg): RecursiveScriptModule(original_name=MyDecisionGate)\n      (linear): RecursiveScriptModule(original_name=Linear)\n    )\n  )\n)\ndef forward(self,\n    argument_1: Tensor) -> Tensor:\n  _0, y, = (self.loop).forward(argument_1, )\n  return torch.relu(y)\n\n"
    }
   ],
   "source": [
    "traced.save('wrapped_rnn.zip')\n",
    "\n",
    "loaded = torch.jit.load('wrapped_rnn.zip')\n",
    "\n",
    "print(loaded)\n",
    "print(loaded.code)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitpytorchconda70fdc7f787194f4c972bb3207dd25917",
   "display_name": "Python 3.8.3 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}